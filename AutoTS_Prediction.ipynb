{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramrajv/AI_Fin/blob/main/AutoTS_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install yfinance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoQjq8U2D8fI",
        "outputId": "18592e9c-013e-43f5-8a1f-94d59066b3e1"
      },
      "id": "aoQjq8U2D8fI",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting yfinance\n",
            "  Downloading yfinance-0.1.74-py2.py3-none-any.whl (27 kB)\n",
            "Collecting requests>=2.26\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.21.6)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: lxml>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from yfinance) (4.9.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yfinance) (1.15.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.1.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2022.6.15)\n",
            "Installing collected packages: requests, yfinance\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "Successfully installed requests-2.28.1 yfinance-0.1.74\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4d8d2c41",
      "metadata": {
        "id": "4d8d2c41"
      },
      "outputs": [],
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from prophet import Prophet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "0790b4ad",
      "metadata": {
        "id": "0790b4ad"
      },
      "outputs": [],
      "source": [
        "# finaldf = pd.read_csv('predictions.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "4ba55bb8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ba55bb8",
        "outputId": "c71f4b9e-a7aa-4e03-dc35-302cf7ae1143"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        }
      ],
      "source": [
        "ticker = '^NSEBANK'\n",
        "# ^NSEI, ^NSEBANK\n",
        "df = yf.download(ticker, start = '2020-04-01')\n",
        "# ,start='2020-01-01'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "97d11a52",
      "metadata": {
        "id": "97d11a52"
      },
      "outputs": [],
      "source": [
        "df.reset_index(inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "1bcb566c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1bcb566c",
        "outputId": "9fddefd2-3ab4-4d0d-8a28-7c19e10581fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Date          Open          High           Low         Close  \\\n",
              "0 2020-04-01  19122.400391  19154.750000  18042.250000  18208.349609   \n",
              "1 2020-04-03  18325.050781  18326.099609  17143.199219  17249.300781   \n",
              "2 2020-04-07  18454.550781  19190.550781  17953.750000  19062.500000   \n",
              "3 2020-04-08  18799.400391  20324.099609  18482.900391  18946.449219   \n",
              "4 2020-04-09  19553.150391  19988.300781  19166.900391  19913.599609   \n",
              "\n",
              "      Adj Close  Volume  \n",
              "0  18208.349609  274900  \n",
              "1  17249.300781  342500  \n",
              "2  19062.500000  435400  \n",
              "3  18946.449219  508400  \n",
              "4  19913.599609  390000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0b63f86f-457d-4305-af76-b78b51d6f094\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-04-01</td>\n",
              "      <td>19122.400391</td>\n",
              "      <td>19154.750000</td>\n",
              "      <td>18042.250000</td>\n",
              "      <td>18208.349609</td>\n",
              "      <td>18208.349609</td>\n",
              "      <td>274900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-04-03</td>\n",
              "      <td>18325.050781</td>\n",
              "      <td>18326.099609</td>\n",
              "      <td>17143.199219</td>\n",
              "      <td>17249.300781</td>\n",
              "      <td>17249.300781</td>\n",
              "      <td>342500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-04-07</td>\n",
              "      <td>18454.550781</td>\n",
              "      <td>19190.550781</td>\n",
              "      <td>17953.750000</td>\n",
              "      <td>19062.500000</td>\n",
              "      <td>19062.500000</td>\n",
              "      <td>435400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-04-08</td>\n",
              "      <td>18799.400391</td>\n",
              "      <td>20324.099609</td>\n",
              "      <td>18482.900391</td>\n",
              "      <td>18946.449219</td>\n",
              "      <td>18946.449219</td>\n",
              "      <td>508400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-04-09</td>\n",
              "      <td>19553.150391</td>\n",
              "      <td>19988.300781</td>\n",
              "      <td>19166.900391</td>\n",
              "      <td>19913.599609</td>\n",
              "      <td>19913.599609</td>\n",
              "      <td>390000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0b63f86f-457d-4305-af76-b78b51d6f094')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0b63f86f-457d-4305-af76-b78b51d6f094 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0b63f86f-457d-4305-af76-b78b51d6f094');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "7f1e59b9",
      "metadata": {
        "id": "7f1e59b9"
      },
      "outputs": [],
      "source": [
        "df.sort_values('Date', inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "a115c171",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "a115c171",
        "outputId": "f41e476d-87cb-4b33-fa90-c32a9cf5c339"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Date          Open          High           Low         Close  \\\n",
              "578 2022-08-01  37594.148438  37939.601562  37407.199219  37903.199219   \n",
              "579 2022-08-02  37767.699219  38179.851562  37632.300781  38024.000000   \n",
              "580 2022-08-03  37954.550781  38068.601562  37692.949219  37989.250000   \n",
              "581 2022-08-04  38111.050781  38231.851562  37249.500000  37755.550781   \n",
              "582 2022-08-05  37868.250000  38150.449219  37779.898438  37920.601562   \n",
              "\n",
              "        Adj Close  Volume  \n",
              "578  37903.199219  346400  \n",
              "579  38024.000000  317300  \n",
              "580  37989.250000  200300  \n",
              "581  37755.550781  186300  \n",
              "582  37920.601562  175900  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f5335f42-e95b-4eb5-be72-976ed80af206\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>578</th>\n",
              "      <td>2022-08-01</td>\n",
              "      <td>37594.148438</td>\n",
              "      <td>37939.601562</td>\n",
              "      <td>37407.199219</td>\n",
              "      <td>37903.199219</td>\n",
              "      <td>37903.199219</td>\n",
              "      <td>346400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>579</th>\n",
              "      <td>2022-08-02</td>\n",
              "      <td>37767.699219</td>\n",
              "      <td>38179.851562</td>\n",
              "      <td>37632.300781</td>\n",
              "      <td>38024.000000</td>\n",
              "      <td>38024.000000</td>\n",
              "      <td>317300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>580</th>\n",
              "      <td>2022-08-03</td>\n",
              "      <td>37954.550781</td>\n",
              "      <td>38068.601562</td>\n",
              "      <td>37692.949219</td>\n",
              "      <td>37989.250000</td>\n",
              "      <td>37989.250000</td>\n",
              "      <td>200300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>581</th>\n",
              "      <td>2022-08-04</td>\n",
              "      <td>38111.050781</td>\n",
              "      <td>38231.851562</td>\n",
              "      <td>37249.500000</td>\n",
              "      <td>37755.550781</td>\n",
              "      <td>37755.550781</td>\n",
              "      <td>186300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>582</th>\n",
              "      <td>2022-08-05</td>\n",
              "      <td>37868.250000</td>\n",
              "      <td>38150.449219</td>\n",
              "      <td>37779.898438</td>\n",
              "      <td>37920.601562</td>\n",
              "      <td>37920.601562</td>\n",
              "      <td>175900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f5335f42-e95b-4eb5-be72-976ed80af206')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f5335f42-e95b-4eb5-be72-976ed80af206 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f5335f42-e95b-4eb5-be72-976ed80af206');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "8f99e334",
      "metadata": {
        "id": "8f99e334"
      },
      "outputs": [],
      "source": [
        "# Metric MAE\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Imports for creating plots\n",
        "import matplotlib.pyplot as plt\n",
        "from pylab import rcParams\n",
        "rcParams['figure.figsize'] = 18, 7\n",
        "# %matplotlib notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "5763891e",
      "metadata": {
        "id": "5763891e"
      },
      "outputs": [],
      "source": [
        "split = int(round(len(df)*0.8,0))\n",
        "train_data = df.iloc[:split]\n",
        "test_data = df.iloc[split:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "602bec32",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "602bec32",
        "outputId": "28926936-5e19-42c2-9c16-e31f15b0130c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "466"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "split"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c76f6c1",
      "metadata": {
        "id": "3c76f6c1"
      },
      "source": [
        "## Forecasting using Auto TS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "19595bc1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "19595bc1",
        "outputId": "ec94c7ec-7392-4442-fc12-a1b27624a25a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "train_data.Close.plot(figsize=(15,8), title= ticker, fontsize=14, label='Train')\n",
        "test_data.Close.plot(figsize=(15,8), title= ticker, fontsize=14, label='Test')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install autots"
      ],
      "metadata": {
        "id": "jF5AeKwFoLd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc4b8302-17b4-4d1b-bbe3-e5160878bc79"
      },
      "id": "jF5AeKwFoLd7",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: autots in /usr/local/lib/python3.7/dist-packages (0.4.2)\n",
            "Requirement already satisfied: statsmodels>=0.10.* in /usr/local/lib/python3.7/dist-packages (from autots) (0.10.2)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from autots) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.20.* in /usr/local/lib/python3.7/dist-packages (from autots) (1.0.2)\n",
            "Requirement already satisfied: pandas>=0.25.* in /usr/local/lib/python3.7/dist-packages (from autots) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.*->autots) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.*->autots) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.25.*->autots) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.*->autots) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.*->autots) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.*->autots) (3.1.0)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from statsmodels>=0.10.*->autots) (0.5.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "36cd3a87",
      "metadata": {
        "id": "36cd3a87"
      },
      "outputs": [],
      "source": [
        "from autots import AutoTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "f120cec5",
      "metadata": {
        "id": "f120cec5"
      },
      "outputs": [],
      "source": [
        "model = AutoTS(forecast_length=5, frequency='infer',  ensemble='simple', drop_data_older_than_periods=200 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "60a4acaf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60a4acaf",
        "outputId": "d8ddd269-095f-4389-f5e0-71de36d37fa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inferred frequency is: B\n",
            "Old data dropped by `drop_data_older_than_periods`.\n",
            "Model Number: 1 with model AverageValueNaive in generation 0 of 10\n",
            "Model Number: 2 with model AverageValueNaive in generation 0 of 10\n",
            "Model Number: 3 with model AverageValueNaive in generation 0 of 10\n",
            "Model Number: 4 with model DatepartRegression in generation 0 of 10\n",
            "Model Number: 5 with model DatepartRegression in generation 0 of 10\n",
            "Model Number: 6 with model DatepartRegression in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 7 with model DatepartRegression in generation 0 of 10\n",
            "Epoch 1/50\n",
            "7/7 [==============================] - 10s 6ms/step - loss: 0.3946\n",
            "Epoch 2/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3874\n",
            "Epoch 3/50\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.3847\n",
            "Epoch 4/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3829\n",
            "Epoch 5/50\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.3774\n",
            "Epoch 6/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3754\n",
            "Epoch 7/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3690\n",
            "Epoch 8/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3629\n",
            "Epoch 9/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3673\n",
            "Epoch 10/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3570\n",
            "Epoch 11/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.3466\n",
            "Epoch 12/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3428\n",
            "Epoch 13/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3440\n",
            "Epoch 14/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3388\n",
            "Epoch 15/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3321\n",
            "Epoch 16/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.3216\n",
            "Epoch 17/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3198\n",
            "Epoch 18/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3163\n",
            "Epoch 19/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.3053\n",
            "Epoch 20/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2966\n",
            "Epoch 21/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2892\n",
            "Epoch 22/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2902\n",
            "Epoch 23/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2923\n",
            "Epoch 24/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2808\n",
            "Epoch 25/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2811\n",
            "Epoch 26/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2777\n",
            "Epoch 27/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2693\n",
            "Epoch 28/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2666\n",
            "Epoch 29/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2693\n",
            "Epoch 30/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2712\n",
            "Epoch 31/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2623\n",
            "Epoch 32/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2654\n",
            "Epoch 33/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2582\n",
            "Epoch 34/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2628\n",
            "Epoch 35/50\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.2745\n",
            "Epoch 36/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2590\n",
            "Epoch 37/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2463\n",
            "Epoch 38/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2589\n",
            "Epoch 39/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2445\n",
            "Epoch 40/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2528\n",
            "Epoch 41/50\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.2445\n",
            "Epoch 42/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2503\n",
            "Epoch 43/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2573\n",
            "Epoch 44/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2476\n",
            "Epoch 45/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2494\n",
            "Epoch 46/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2451\n",
            "Epoch 47/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2379\n",
            "Epoch 48/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2571\n",
            "Epoch 49/50\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2379\n",
            "Epoch 50/50\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2400\n",
            "Model Number: 8 with model ETS in generation 0 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 9 with model ETS in generation 0 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 10 with model GLM in generation 0 of 10\n",
            "Template Eval Error: TypeError(\"ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''\") in model 10: GLM\n",
            "Model Number: 11 with model GLM in generation 0 of 10\n",
            "Model Number: 12 with model GLS in generation 0 of 10\n",
            "Model Number: 13 with model GLS in generation 0 of 10\n",
            "Model Number: 14 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 14: GluonTS\n",
            "Model Number: 15 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 15: GluonTS\n",
            "Model Number: 16 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 16: GluonTS\n",
            "Model Number: 17 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 17: GluonTS\n",
            "Model Number: 18 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 18: GluonTS\n",
            "Model Number: 19 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 20 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 21 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 22 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 23 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 24 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 25 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 26 with model UnobservedComponents in generation 0 of 10\n",
            "Template Eval Error: ValueError('Provided exogenous values are not of the appropriate shape. Required (5, 1), got (5,).') in model 26: UnobservedComponents\n",
            "Model Number: 27 with model UnobservedComponents in generation 0 of 10\n",
            "Model Number: 28 with model UnobservedComponents in generation 0 of 10\n",
            "Model Number: 29 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 29: VAR\n",
            "Model Number: 30 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 30: VAR\n",
            "Model Number: 31 with model VECM in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VECM') in model 31: VECM\n",
            "Model Number: 32 with model VECM in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VECM') in model 32: VECM\n",
            "Model Number: 33 with model WindowRegression in generation 0 of 10\n",
            "Model Number: 34 with model ConstantNaive in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "05:19:03 - cmdstanpy - INFO - Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 35 with model FBProphet in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:19:03 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 36 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 36: GluonTS\n",
            "Model Number: 37 with model MultivariateRegression in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.3s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 38 with model MultivariateRegression in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 38: MultivariateRegression\n",
            "Model Number: 39 with model DatepartRegression in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 39: DatepartRegression\n",
            "Model Number: 40 with model SeasonalNaive in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 41 with model DatepartRegression in generation 0 of 10\n",
            "Model Number: 42 with model UnobservedComponents in generation 0 of 10\n",
            "Template Eval Error: ValueError('Provided exogenous values are not of the appropriate shape. Required (5, 1), got (5,).') in model 42: UnobservedComponents\n",
            "Model Number: 43 with model UnobservedComponents in generation 0 of 10\n",
            "Template Eval Error: ValueError('Provided exogenous values are not of the appropriate shape. Required (5, 1), got (5,).') in model 43: UnobservedComponents\n",
            "Model Number: 44 with model ETS in generation 0 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 45 with model VECM in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VECM') in model 45: VECM\n",
            "Model Number: 46 with model ARDL in generation 0 of 10\n",
            "Template Eval Error: ImportError(\"cannot import name 'ARDL' from 'statsmodels.tsa.api' (/usr/local/lib/python3.7/dist-packages/statsmodels/tsa/api.py)\") in model 46: ARDL\n",
            "Model Number: 47 with model MultivariateMotif in generation 0 of 10\n",
            "Model Number: 48 with model MultivariateMotif in generation 0 of 10\n",
            "Model Number: 49 with model UnivariateMotif in generation 0 of 10\n",
            "Model Number: 50 with model UnivariateMotif in generation 0 of 10\n",
            "Model Number: 51 with model SectionalMotif in generation 0 of 10\n",
            "Model Number: 52 with model SectionalMotif in generation 0 of 10\n",
            "Model Number: 53 with model MultivariateRegression in generation 0 of 10\n",
            "Model Number: 54 with model FBProphet in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:19:07 - cmdstanpy - INFO - Chain [1] start processing\n",
            "05:19:07 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 55 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 56 with model DatepartRegression in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 57 with model NVAR in generation 0 of 10\n",
            "Model Number: 58 with model Theta in generation 0 of 10\n",
            "Template Eval Error: ModuleNotFoundError(\"No module named 'statsmodels.tsa.forecasting'\") in model 58: Theta\n",
            "Model Number: 59 with model UnivariateRegression in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"Input contains NaN, infinity or a value too large for dtype('float32').\") in model 59: UnivariateRegression\n",
            "Model Number: 60 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 61 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 62 with model AverageValueNaive in generation 0 of 10\n",
            "Model Number: 63 with model GLS in generation 0 of 10\n",
            "Model Number: 64 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 65 with model GLM in generation 0 of 10\n",
            "Template Eval Error: ValueError('regression_type=user and no future_regressor passed') in model 65: GLM\n",
            "Model Number: 66 with model ETS in generation 0 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 67 with model FBProphet in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:19:10 - cmdstanpy - INFO - Chain [1] start processing\n",
            "05:19:10 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 68 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 68: GluonTS\n",
            "Model Number: 69 with model UnobservedComponents in generation 0 of 10\n",
            "Model Number: 70 with model VAR in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer STLFilter failed on fit') in model 70: VAR\n",
            "Model Number: 71 with model VECM in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VECM') in model 71: VECM\n",
            "Model Number: 72 with model WindowRegression in generation 0 of 10\n",
            "Template Eval Error: LightGBMError('[tweedie]: at least one target label is negative') in model 72: WindowRegression\n",
            "Model Number: 73 with model DatepartRegression in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 73: DatepartRegression\n",
            "Model Number: 74 with model UnivariateRegression in generation 0 of 10\n",
            "Model Number: 75 with model MultivariateRegression in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 75: MultivariateRegression\n",
            "Model Number: 76 with model UnivariateMotif in generation 0 of 10\n",
            "Model Number: 77 with model MultivariateMotif in generation 0 of 10\n",
            "Model Number: 78 with model SectionalMotif in generation 0 of 10\n",
            "Model Number: 79 with model NVAR in generation 0 of 10\n",
            "Model Number: 80 with model Theta in generation 0 of 10\n",
            "Template Eval Error: ModuleNotFoundError(\"No module named 'statsmodels.tsa.forecasting'\") in model 80: Theta\n",
            "Model Number: 81 with model ARDL in generation 0 of 10\n",
            "Template Eval Error: ImportError(\"cannot import name 'ARDL' from 'statsmodels.tsa.api' (/usr/local/lib/python3.7/dist-packages/statsmodels/tsa/api.py)\") in model 81: ARDL\n",
            "Model Number: 82 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 82: VAR\n",
            "Model Number: 83 with model WindowRegression in generation 0 of 10\n",
            "Model Number: 84 with model GLM in generation 0 of 10\n",
            "Template Eval Error: TypeError(\"ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''\") in model 84: GLM\n",
            "Model Number: 85 with model NVAR in generation 0 of 10\n",
            "Model Number: 86 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 87 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 88 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 89 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 90 with model UnivariateMotif in generation 0 of 10\n",
            "Model Number: 91 with model GLM in generation 0 of 10\n",
            "Template Eval Error: TypeError(\"ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''\") in model 91: GLM\n",
            "Model Number: 92 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 93 with model GLM in generation 0 of 10\n",
            "Template Eval Error: TypeError(\"ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''\") in model 93: GLM\n",
            "Model Number: 94 with model MultivariateMotif in generation 0 of 10\n",
            "Model Number: 95 with model LastValueNaive in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer STLFilter failed on fit') in model 95: LastValueNaive\n",
            "Model Number: 96 with model GLS in generation 0 of 10\n",
            "Model Number: 97 with model UnobservedComponents in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 97: UnobservedComponents\n",
            "Model Number: 98 with model ETS in generation 0 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 99 with model UnivariateMotif in generation 0 of 10\n",
            "Model Number: 100 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 101 with model ConstantNaive in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer STLFilter failed on fit') in model 101: ConstantNaive\n",
            "Model Number: 102 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 102: VAR\n",
            "Model Number: 103 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 104 with model AverageValueNaive in generation 0 of 10\n",
            "Model Number: 105 with model SectionalMotif in generation 0 of 10\n",
            "Model Number: 106 with model MultivariateMotif in generation 0 of 10\n",
            "Template Eval Error: ValueError('Model MultivariateMotif returned NaN for one or more series. fail_on_forecast_nan=True') in model 106: MultivariateMotif\n",
            "Model Number: 107 with model UnobservedComponents in generation 0 of 10\n",
            "Model Number: 108 with model WindowRegression in generation 0 of 10\n",
            "Model Number: 109 with model Theta in generation 0 of 10\n",
            "Template Eval Error: ModuleNotFoundError(\"No module named 'statsmodels.tsa.forecasting'\") in model 109: Theta\n",
            "Model Number: 110 with model ConstantNaive in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:48: RuntimeWarning: invalid value encountered in reduce\n",
            "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 111 with model NVAR in generation 0 of 10\n",
            "Model Number: 112 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 113 with model FBProphet in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:19:13 - cmdstanpy - INFO - Chain [1] start processing\n",
            "05:19:14 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 114 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 115 with model DatepartRegression in generation 0 of 10\n",
            "Epoch 1/50\n",
            "3/3 [==============================] - 6s 14ms/step - loss: 121.6471\n",
            "Epoch 2/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 103.8118\n",
            "Epoch 3/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 100.3135\n",
            "Epoch 4/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 106.0209\n",
            "Epoch 5/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 100.8218\n",
            "Epoch 6/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 101.8651\n",
            "Epoch 7/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 102.9012\n",
            "Epoch 8/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 102.2464\n",
            "Epoch 9/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 101.5186\n",
            "Epoch 10/50\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 102.1201\n",
            "Epoch 11/50\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 100.4130\n",
            "Epoch 12/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 98.7207\n",
            "Epoch 13/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 99.8933\n",
            "Epoch 14/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 102.2771\n",
            "Epoch 15/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 100.4542\n",
            "Epoch 16/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 101.7186\n",
            "Epoch 17/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 100.6327\n",
            "Epoch 18/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 99.3649\n",
            "Epoch 19/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 101.2387\n",
            "Epoch 20/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 100.3010\n",
            "Epoch 21/50\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 101.4714\n",
            "Epoch 22/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 101.9582\n",
            "Epoch 23/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 99.8299\n",
            "Epoch 24/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 101.7971\n",
            "Epoch 25/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 100.4273\n",
            "Epoch 26/50\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 100.2412\n",
            "Epoch 27/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 100.1101\n",
            "Epoch 28/50\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 99.3804\n",
            "Epoch 29/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 98.9574\n",
            "Epoch 30/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 102.8002\n",
            "Epoch 31/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 98.5694\n",
            "Epoch 32/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 99.5706\n",
            "Epoch 33/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 100.5247\n",
            "Epoch 34/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 102.6320\n",
            "Epoch 35/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 100.3273\n",
            "Epoch 36/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 100.3260\n",
            "Epoch 37/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 100.0336\n",
            "Epoch 38/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 100.2597\n",
            "Epoch 39/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 100.7427\n",
            "Epoch 40/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 99.6823\n",
            "Epoch 41/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 101.2904\n",
            "Epoch 42/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 99.1621\n",
            "Epoch 43/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 100.3872\n",
            "Epoch 44/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 100.0010\n",
            "Epoch 45/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 99.0460\n",
            "Epoch 46/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 101.6057\n",
            "Epoch 47/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 99.8210\n",
            "Epoch 48/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 100.7661\n",
            "Epoch 49/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 100.6711\n",
            "Epoch 50/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 99.7542\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:19:26 - cmdstanpy - INFO - Chain [1] start processing\n",
            "05:19:26 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 116 with model FBProphet in generation 0 of 10\n",
            "Model Number: 117 with model ETS in generation 0 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 118 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 119 with model UnivariateMotif in generation 0 of 10\n",
            "Model Number: 120 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 121 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 122 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 123 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 123: VAR\n",
            "Model Number: 124 with model GLS in generation 0 of 10\n",
            "Model Number: 125 with model WindowRegression in generation 0 of 10\n",
            "Epoch 1/50\n",
            "12/12 [==============================] - 6s 6ms/step - loss: nan\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: nan\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: nan\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: nan\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: nan\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: nan\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: nan\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: nan\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: nan\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: nan\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: nan\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: nan\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: nan\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: nan\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: nan\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: nan\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: nan\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: nan\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: nan\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: nan\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: nan\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: nan\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: nan\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: nan\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: nan\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: nan\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 8ms/step - loss: nan\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: nan\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: nan\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 8ms/step - loss: nan\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: nan\n",
            "Model Number: 126 with model UnivariateMotif in generation 0 of 10\n",
            "Model Number: 127 with model WindowRegression in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 127: WindowRegression\n",
            "Model Number: 128 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 129 with model MultivariateMotif in generation 0 of 10\n",
            "Model Number: 130 with model ARDL in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 130: ARDL\n",
            "Model Number: 131 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 132 with model ETS in generation 0 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 133 with model UnobservedComponents in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 133: UnobservedComponents\n",
            "Model Number: 134 with model DatepartRegression in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 135 with model NVAR in generation 0 of 10\n",
            "Model Number: 136 with model SectionalMotif in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Done 300 out of 300 | elapsed:    0.3s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 137 with model NVAR in generation 0 of 10\n",
            "Model Number: 138 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 139 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 140 with model MultivariateMotif in generation 0 of 10\n",
            "Model Number: 141 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 142 with model ETS in generation 0 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "ETS failed on Close with ValueError('endog must be strictly positive when using multiplicative trend or seasonal components.')\n",
            "Model Number: 143 with model ARDL in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 143: ARDL\n",
            "Model Number: 144 with model DatepartRegression in generation 0 of 10\n",
            "Model Number: 145 with model NVAR in generation 0 of 10\n",
            "Model Number: 146 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 146: VAR\n",
            "Model Number: 147 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 148 with model GLS in generation 0 of 10\n",
            "Model Number: 149 with model AverageValueNaive in generation 0 of 10\n",
            "Model Number: 150 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 151 with model SectionalMotif in generation 0 of 10\n",
            "Model Number: 152 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 153 with model LastValueNaive in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:19:44 - cmdstanpy - INFO - Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 154 with model FBProphet in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:19:44 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 155 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer STLFilter failed on fit') in model 155: GluonTS\n",
            "Model Number: 156 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 156: VAR\n",
            "Model Number: 157 with model MultivariateMotif in generation 0 of 10\n",
            "Model Number: 158 with model GLS in generation 0 of 10\n",
            "Model Number: 159 with model GLM in generation 0 of 10\n",
            "Template Eval Error: ValueError('NaN, inf or invalid value detected in weights, estimation infeasible.') in model 159: GLM\n",
            "Model Number: 160 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 161 with model MultivariateMotif in generation 0 of 10\n",
            "Model Number: 162 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 162: VAR\n",
            "Model Number: 163 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 164 with model NVAR in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/genmod/families/family.py:428: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  endog_mu = self._clean(endog / mu)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/genmod/families/family.py:134: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 165 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 165: GluonTS\n",
            "Model Number: 166 with model MultivariateMotif in generation 0 of 10\n",
            "Model Number: 167 with model ARDL in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 167: ARDL\n",
            "Model Number: 168 with model SectionalMotif in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type=='User' but no future_regressor supplied\") in model 168: SectionalMotif\n",
            "Model Number: 169 with model AverageValueNaive in generation 0 of 10\n",
            "New Generation: 1 of 10\n",
            "Model Number: 170 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 171 with model GLS in generation 1 of 10\n",
            "Model Number: 172 with model GLS in generation 1 of 10\n",
            "Model Number: 173 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 174 with model MultivariateRegression in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/signal/signaltools.py:1611: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  res *= (1 - noise / lVar)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/signal/signaltools.py:1611: RuntimeWarning: invalid value encountered in multiply\n",
            "  res *= (1 - noise / lVar)\n",
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.3s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 175 with model GLS in generation 1 of 10\n",
            "Model Number: 176 with model SectionalMotif in generation 1 of 10\n",
            "Model Number: 177 with model DatepartRegression in generation 1 of 10\n",
            "Model Number: 178 with model DatepartRegression in generation 1 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 178: DatepartRegression\n",
            "Model Number: 179 with model MultivariateMotif in generation 1 of 10\n",
            "Model Number: 180 with model GLS in generation 1 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 180: GLS\n",
            "Model Number: 181 with model UnivariateRegression in generation 1 of 10\n",
            "Model Number: 182 with model UnobservedComponents in generation 1 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 182: UnobservedComponents\n",
            "Model Number: 183 with model ETS in generation 1 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 184 with model GLS in generation 1 of 10\n",
            "Model Number: 185 with model SectionalMotif in generation 1 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 185: SectionalMotif\n",
            "Model Number: 186 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 187 with model NVAR in generation 1 of 10\n",
            "Model Number: 188 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 189 with model WindowRegression in generation 1 of 10\n",
            "Model Number: 190 with model ConstantNaive in generation 1 of 10\n",
            "Model Number: 191 with model ETS in generation 1 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 192 with model ETS in generation 1 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 193 with model SeasonalNaive in generation 1 of 10\n",
            "Model Number: 194 with model NVAR in generation 1 of 10\n",
            "Model Number: 195 with model SectionalMotif in generation 1 of 10\n",
            "Model Number: 196 with model NVAR in generation 1 of 10\n",
            "Model Number: 197 with model SectionalMotif in generation 1 of 10\n",
            "Model Number: 198 with model NVAR in generation 1 of 10\n",
            "Model Number: 199 with model ETS in generation 1 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "ETS failed on Close with ValueError('endog must be strictly positive when using multiplicative trend or seasonal components.')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 200 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 201 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 202 with model UnivariateRegression in generation 1 of 10\n",
            "Model Number: 203 with model SeasonalNaive in generation 1 of 10\n",
            "Model Number: 204 with model SectionalMotif in generation 1 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 204: SectionalMotif\n",
            "Model Number: 205 with model SectionalMotif in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:331: RuntimeWarning: divide by zero encountered in power\n",
            "  + np.power(y_pred, 2 - p) / (2 - p)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 206 with model UnobservedComponents in generation 1 of 10\n",
            "Model Number: 207 with model MultivariateRegression in generation 1 of 10\n",
            "Model Number: 208 with model GLS in generation 1 of 10\n",
            "Model Number: 209 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 210 with model ConstantNaive in generation 1 of 10\n",
            "Model Number: 211 with model ETS in generation 1 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/signal/signaltools.py:1611: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  res *= (1 - noise / lVar)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/signal/signaltools.py:1611: RuntimeWarning: invalid value encountered in multiply\n",
            "  res *= (1 - noise / lVar)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 212 with model SeasonalNaive in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:19:52 - cmdstanpy - INFO - Chain [1] start processing\n",
            "05:19:52 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 213 with model FBProphet in generation 1 of 10\n",
            "Model Number: 214 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 215 with model SeasonalNaive in generation 1 of 10\n",
            "Model Number: 216 with model UnivariateMotif in generation 1 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 216: UnivariateMotif\n",
            "Model Number: 217 with model DatepartRegression in generation 1 of 10\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 5s 234ms/step - loss: nan - val_loss: nan\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 101ms/step - loss: nan - val_loss: nan\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 1s 104ms/step - loss: nan - val_loss: nan\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 1s 105ms/step - loss: nan - val_loss: nan\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 1s 103ms/step - loss: nan - val_loss: nan\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 1s 102ms/step - loss: nan - val_loss: nan\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 1s 102ms/step - loss: nan - val_loss: nan\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 1s 103ms/step - loss: nan - val_loss: nan\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 1s 137ms/step - loss: nan - val_loss: nan\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 1s 204ms/step - loss: nan - val_loss: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:20:06 - cmdstanpy - INFO - Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 217: DatepartRegression\n",
            "Model Number: 218 with model FBProphet in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:20:07 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 219 with model UnobservedComponents in generation 1 of 10\n",
            "Model Number: 220 with model DatepartRegression in generation 1 of 10\n",
            "Model Number: 221 with model SeasonalNaive in generation 1 of 10\n",
            "Model Number: 222 with model WindowRegression in generation 1 of 10\n",
            "Model Number: 223 with model NVAR in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 224 with model ConstantNaive in generation 1 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 224: ConstantNaive\n",
            "Model Number: 225 with model GLS in generation 1 of 10\n",
            "Model Number: 226 with model FBProphet in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:20:09 - cmdstanpy - INFO - Chain [1] start processing\n",
            "05:20:09 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 227 with model ConstantNaive in generation 1 of 10\n",
            "Model Number: 228 with model NVAR in generation 1 of 10\n",
            "Model Number: 229 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 230 with model SeasonalNaive in generation 1 of 10\n",
            "Model Number: 231 with model FBProphet in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
            "05:20:11 - cmdstanpy - INFO - Chain [1] start processing\n",
            "05:20:11 - cmdstanpy - INFO - Chain [1] done processing\n",
            "05:20:13 - cmdstanpy - INFO - Chain [1] start processing\n",
            "05:20:13 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 232 with model FBProphet in generation 1 of 10\n",
            "Model Number: 233 with model SeasonalNaive in generation 1 of 10\n",
            "Model Number: 234 with model SectionalMotif in generation 1 of 10\n",
            "Model Number: 235 with model ConstantNaive in generation 1 of 10\n",
            "Model Number: 236 with model UnivariateMotif in generation 1 of 10\n",
            "Model Number: 237 with model ConstantNaive in generation 1 of 10\n",
            "Model Number: 238 with model ETS in generation 1 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 239 with model MultivariateMotif in generation 1 of 10"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Number: 240 with model ETS in generation 1 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 241 with model UnivariateMotif in generation 1 of 10\n",
            "Model Number: 242 with model MultivariateMotif in generation 1 of 10\n",
            "Model Number: 243 with model FBProphet in generation 1 of 10\n",
            "Template Eval Error: Exception('Transformer STLFilter failed on fit') in model 243: FBProphet\n",
            "Model Number: 244 with model MultivariateMotif in generation 1 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 244: MultivariateMotif\n",
            "Model Number: 245 with model ConstantNaive in generation 1 of 10\n",
            "Model Number: 246 with model NVAR in generation 1 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 246: NVAR\n",
            "Model Number: 247 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 248 with model ConstantNaive in generation 1 of 10\n",
            "Model Number: 249 with model UnobservedComponents in generation 1 of 10\n",
            "Model Number: 250 with model ETS in generation 1 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 251 with model DatepartRegression in generation 1 of 10\n",
            "Model Number: 252 with model ETS in generation 1 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 253 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 254 with model NVAR in generation 1 of 10\n",
            "Model Number: 255 with model SectionalMotif in generation 1 of 10\n",
            "Model Number: 256 with model SectionalMotif in generation 1 of 10\n",
            "Model Number: 257 with model DatepartRegression in generation 1 of 10\n",
            "Epoch 1/50\n",
            "3/3 [==============================] - 6s 14ms/step - loss: 21637.3301\n",
            "Epoch 2/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 565625.8750\n",
            "Epoch 3/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 28682.7207\n",
            "Epoch 4/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 417720.8125\n",
            "Epoch 5/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 85118.2969\n",
            "Epoch 6/50\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 348994.5000\n",
            "Epoch 7/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 148036.1875\n",
            "Epoch 8/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 148541.0000\n",
            "Epoch 9/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 69106.8125\n",
            "Epoch 10/50\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 249846.7031\n",
            "Epoch 11/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 21341.9160\n",
            "Epoch 12/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 315921.8125\n",
            "Epoch 13/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 43531.1172\n",
            "Epoch 14/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 250603.5000\n",
            "Epoch 15/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 22780.9414\n",
            "Epoch 16/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 252487.1719\n",
            "Epoch 17/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 50512.5547\n",
            "Epoch 18/50\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 21036.9043\n",
            "Epoch 19/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 122336.9141\n",
            "Epoch 20/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 77701.8906\n",
            "Epoch 21/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 86428.7578\n",
            "Epoch 22/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 237186.1562\n",
            "Epoch 23/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 14213.6094\n",
            "Epoch 24/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 303011.2188\n",
            "Epoch 25/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 52606.2266\n",
            "Epoch 26/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 309065.6562\n",
            "Epoch 27/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 55229.6562\n",
            "Epoch 28/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 153330.1875\n",
            "Epoch 29/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 691.3381\n",
            "Epoch 30/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 152872.3750\n",
            "Epoch 31/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 19917.7910\n",
            "Epoch 32/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 191782.0312\n",
            "Epoch 33/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 68924.3047\n",
            "Epoch 34/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 56468.3438\n",
            "Epoch 35/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 86441.9375\n",
            "Epoch 36/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 44700.5781\n",
            "Epoch 37/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 17039.2559\n",
            "Epoch 38/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 126351.6172\n",
            "Epoch 39/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 188536.4375\n",
            "Epoch 40/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 183874.5781\n",
            "Epoch 41/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 19550.3730\n",
            "Epoch 42/50\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 63581.0430\n",
            "Epoch 43/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 57437.7852\n",
            "Epoch 44/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 179585.8125\n",
            "Epoch 45/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 81545.3047\n",
            "Epoch 46/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 132735.9062\n",
            "Epoch 47/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 89771.9766\n",
            "Epoch 48/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 37175.1523\n",
            "Epoch 49/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 214281.0625\n",
            "Epoch 50/50\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 101044.0078\n",
            "Model Number: 258 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 259 with model ConstantNaive in generation 1 of 10\n",
            "Model Number: 260 with model DatepartRegression in generation 1 of 10\n",
            "Model Number: 261 with model UnivariateMotif in generation 1 of 10\n",
            "Model Number: 262 with model ConstantNaive in generation 1 of 10\n",
            "Model Number: 263 with model SeasonalNaive in generation 1 of 10\n",
            "Model Number: 264 with model ETS in generation 1 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 265 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 266 with model GLM in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 267 with model WindowRegression in generation 1 of 10\n",
            "Model Number: 268 with model UnivariateRegression in generation 1 of 10\n",
            "Model Number: 269 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 270 with model ETS in generation 1 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "ETS failed on Close with ValueError('endog must be strictly positive when using multiplicative trend or seasonal components.')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 271 with model UnobservedComponents in generation 1 of 10\n",
            "Model Number: 272 with model SectionalMotif in generation 1 of 10\n",
            "Model Number: 273 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 274 with model AverageValueNaive in generation 1 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 274: AverageValueNaive\n",
            "Model Number: 275 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 276 with model NVAR in generation 1 of 10\n",
            "Model Number: 277 with model NVAR in generation 1 of 10\n",
            "Model Number: 278 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 279 with model SectionalMotif in generation 1 of 10\n",
            "New Generation: 2 of 10\n",
            "Model Number: 280 with model LastValueNaive in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:20:29 - cmdstanpy - INFO - Chain [1] start processing\n",
            "05:20:29 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 281 with model FBProphet in generation 2 of 10\n",
            "Model Number: 282 with model ETS in generation 2 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "ETS failed on Close with ValueError('Can only dampen the trend component')\n",
            "Model Number: 283 with model GLM in generation 2 of 10\n",
            "Template Eval Error: TypeError(\"ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''\") in model 283: GLM\n",
            "Model Number: 284 with model UnobservedComponents in generation 2 of 10\n",
            "Model Number: 285 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 286 with model ETS in generation 2 of 10\n",
            "Template Eval Error: Exception('Transformer STLFilter failed on fit') in model 286: ETS\n",
            "Model Number: 287 with model NVAR in generation 2 of 10\n",
            "Model Number: 288 with model ConstantNaive in generation 2 of 10\n",
            "Model Number: 289 with model UnobservedComponents in generation 2 of 10\n",
            "Model Number: 290 with model ETS in generation 2 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 291 with model AverageValueNaive in generation 2 of 10\n",
            "Model Number: 292 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 293 with model ETS in generation 2 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 294 with model AverageValueNaive in generation 2 of 10\n",
            "Model Number: 295 with model AverageValueNaive in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:331: RuntimeWarning: divide by zero encountered in power\n",
            "  + np.power(y_pred, 2 - p) / (2 - p)\n",
            "05:20:31 - cmdstanpy - INFO - Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 296 with model FBProphet in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:20:31 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 297 with model SectionalMotif in generation 2 of 10\n",
            "Model Number: 298 with model UnivariateMotif in generation 2 of 10\n",
            "Model Number: 299 with model MultivariateMotif in generation 2 of 10\n",
            "Model Number: 300 with model AverageValueNaive in generation 2 of 10\n",
            "Model Number: 301 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 302 with model GLS in generation 2 of 10\n",
            "Model Number: 303 with model ConstantNaive in generation 2 of 10\n",
            "Model Number: 304 with model ConstantNaive in generation 2 of 10\n",
            "Model Number: 305 with model SectionalMotif in generation 2 of 10\n",
            "Model Number: 306 with model NVAR in generation 2 of 10\n",
            "Model Number: 307 with model UnobservedComponents in generation 2 of 10\n",
            "Model Number: 308 with model ETS in generation 2 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 309 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 310 with model SeasonalNaive in generation 2 of 10\n",
            "Model Number: 311 with model UnivariateRegression in generation 2 of 10\n",
            "Model Number: 312 with model MultivariateRegression in generation 2 of 10\n",
            "Model Number: 313 with model SectionalMotif in generation 2 of 10\n",
            "Model Number: 314 with model SeasonalNaive in generation 2 of 10\n",
            "Model Number: 315 with model AverageValueNaive in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:20:34 - cmdstanpy - INFO - Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 316 with model FBProphet in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:20:34 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 317 with model NVAR in generation 2 of 10\n",
            "Model Number: 318 with model DatepartRegression in generation 2 of 10\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 5s 148ms/step - loss: 366519933376397312.0000 - val_loss: 301517596216262656.0000\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 84ms/step - loss: 273323730078269440.0000 - val_loss: 213880695506862080.0000\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 1s 180ms/step - loss: 210325802615570432.0000 - val_loss: 139830305363066880.0000\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 90ms/step - loss: 146041395008765952.0000 - val_loss: 85956615013924864.0000\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 132304216990416896.0000 - val_loss: 35937174629122048.0000\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 99741346910175232.0000 - val_loss: 18361064647294976.0000\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 109375473951178752.0000 - val_loss: 12404335849766912.0000\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 103916424489074688.0000 - val_loss: 11346532649402368.0000\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 105312984644976640.0000 - val_loss: 49707086774272.0000\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 101146058914004992.0000 - val_loss: 9083894485745664.0000\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 88983433086238720.0000 - val_loss: 12187077076582400.0000\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 62ms/step - loss: 99682076361490432.0000 - val_loss: 12730961670176768.0000\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 99265043626983424.0000 - val_loss: 13469525320138752.0000\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 63ms/step - loss: 85207083091230720.0000 - val_loss: 5756384142426112.0000\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 63ms/step - loss: 83257855133614080.0000 - val_loss: 8029062329008128.0000\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 54ms/step - loss: 89662527545278464.0000 - val_loss: 2101420392185856.0000\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 64ms/step - loss: 84983006057463808.0000 - val_loss: 10912061273931776.0000\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 79640496237969408.0000 - val_loss: 2926555550449664.0000\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 82453124291231744.0000 - val_loss: 1295082024075264.0000\n",
            "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 318: DatepartRegression\n",
            "Model Number: 319 with model SeasonalNaive in generation 2 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 319: SeasonalNaive\n",
            "Model Number: 320 with model SeasonalNaive in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_fastica.py:532: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  K = (u / d).T[:n_components]  # see (6.33) p.140\n",
            "05:20:51 - cmdstanpy - INFO - Chain [1] start processing\n",
            "05:20:51 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 321 with model MultivariateRegression in generation 2 of 10\n",
            "Template Eval Error: Exception('Transformer FastICA failed on fit') in model 321: MultivariateRegression\n",
            "Model Number: 322 with model NVAR in generation 2 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 322: NVAR\n",
            "Model Number: 323 with model FBProphet in generation 2 of 10\n",
            "Model Number: 324 with model AverageValueNaive in generation 2 of 10\n",
            "Model Number: 325 with model ConstantNaive in generation 2 of 10\n",
            "Model Number: 326 with model MultivariateMotif in generation 2 of 10\n",
            "Model Number: 327 with model UnivariateMotif in generation 2 of 10\n",
            "Model Number: 328 with model ETS in generation 2 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 329 with model NVAR in generation 2 of 10\n",
            "Model Number: 330 with model ConstantNaive in generation 2 of 10\n",
            "Model Number: 331 with model UnobservedComponents in generation 2 of 10\n",
            "Model Number: 332 with model DatepartRegression in generation 2 of 10\n",
            "Model Number: 333 with model NVAR in generation 2 of 10\n",
            "Model Number: 334 with model SectionalMotif in generation 2 of 10\n",
            "Model Number: 335 with model SeasonalNaive in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: divide by zero encountered in log\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: invalid value encountered in add\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 336 with model SeasonalNaive in generation 2 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 336: SeasonalNaive\n",
            "Model Number: 337 with model SectionalMotif in generation 2 of 10\n",
            "Model Number: 338 with model ETS in generation 2 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 339 with model SectionalMotif in generation 2 of 10\n",
            "Model Number: 340 with model SeasonalNaive in generation 2 of 10\n",
            "Model Number: 341 with model GLS in generation 2 of 10\n",
            "Model Number: 342 with model AverageValueNaive in generation 2 of 10\n",
            "Model Number: 343 with model ConstantNaive in generation 2 of 10\n",
            "Model Number: 344 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 345 with model SeasonalNaive in generation 2 of 10\n",
            "Model Number: 346 with model AverageValueNaive in generation 2 of 10\n",
            "Model Number: 347 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 348 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 349 with model AverageValueNaive in generation 2 of 10\n",
            "Model Number: 350 with model SeasonalNaive in generation 2 of 10\n",
            "Model Number: 351 with model MultivariateRegression in generation 2 of 10\n",
            "Template Eval Error: Exception('Transformer FastICA failed on fit') in model 351: MultivariateRegression\n",
            "Model Number: 352 with model NVAR in generation 2 of 10\n",
            "Model Number: 353 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 354 with model SectionalMotif in generation 2 of 10\n",
            "Model Number: 355 with model UnobservedComponents in generation 2 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 355: UnobservedComponents\n",
            "Model Number: 356 with model WindowRegression in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_fastica.py:532: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  K = (u / d).T[:n_components]  # see (6.33) p.140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 357 with model UnivariateRegression in generation 2 of 10\n",
            "Model Number: 358 with model NVAR in generation 2 of 10\n",
            "Model Number: 359 with model ConstantNaive in generation 2 of 10\n",
            "Model Number: 360 with model UnivariateMotif in generation 2 of 10\n",
            "Model Number: 361 with model UnivariateMotif in generation 2 of 10\n",
            "Model Number: 362 with model MultivariateRegression in generation 2 of 10\n",
            "Model Number: 363 with model ETS in generation 2 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 364 with model ConstantNaive in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 365 with model UnivariateRegression in generation 2 of 10\n",
            "Model Number: 366 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 367 with model ConstantNaive in generation 2 of 10\n",
            "Model Number: 368 with model ConstantNaive in generation 2 of 10\n",
            "Model Number: 369 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 370 with model GLS in generation 2 of 10\n",
            "Model Number: 371 with model DatepartRegression in generation 2 of 10\n",
            "Epoch 1/50\n",
            "3/3 [==============================] - 6s 15ms/step - loss: 53219172.0000\n",
            "Epoch 2/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 33411640.0000\n",
            "Epoch 3/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 20510060.0000\n",
            "Epoch 4/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 19985322.0000\n",
            "Epoch 5/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 15055390.0000\n",
            "Epoch 6/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 15794890.0000\n",
            "Epoch 7/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 16188448.0000\n",
            "Epoch 8/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 13514558.0000\n",
            "Epoch 9/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 10681483.0000\n",
            "Epoch 10/50\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 14917568.0000\n",
            "Epoch 11/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 10751089.0000\n",
            "Epoch 12/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 11205812.0000\n",
            "Epoch 13/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 7048052.0000\n",
            "Epoch 14/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 8521194.0000\n",
            "Epoch 15/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 13130038.0000\n",
            "Epoch 16/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 12596823.0000\n",
            "Epoch 17/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 10481954.0000\n",
            "Epoch 18/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 10078920.0000\n",
            "Epoch 19/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 9020538.0000\n",
            "Epoch 20/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 7674471.5000\n",
            "Epoch 21/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 8739442.0000\n",
            "Epoch 22/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 8426737.0000\n",
            "Epoch 23/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 6810124.0000\n",
            "Epoch 24/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 7148337.0000\n",
            "Epoch 25/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 7714968.5000\n",
            "Epoch 26/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 8671581.0000\n",
            "Epoch 27/50\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 6704575.0000\n",
            "Epoch 28/50\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 6503231.0000\n",
            "Epoch 29/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 6709955.0000\n",
            "Epoch 30/50\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 6685545.0000\n",
            "Epoch 31/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 6444987.5000\n",
            "Epoch 32/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 5892929.5000\n",
            "Epoch 33/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 4320256.5000\n",
            "Epoch 34/50\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 4988474.0000\n",
            "Epoch 35/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 5502801.5000\n",
            "Epoch 36/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 5548151.5000\n",
            "Epoch 37/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 5257086.5000\n",
            "Epoch 38/50\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 4827025.5000\n",
            "Epoch 39/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 4555320.0000\n",
            "Epoch 40/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 4876813.0000\n",
            "Epoch 41/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 4296862.0000\n",
            "Epoch 42/50\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 4531276.0000\n",
            "Epoch 43/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 4383829.5000\n",
            "Epoch 44/50\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3412779.0000\n",
            "Epoch 45/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 4040747.0000\n",
            "Epoch 46/50\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 4245369.5000\n",
            "Epoch 47/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 3028261.0000\n",
            "Epoch 48/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 4153787.0000\n",
            "Epoch 49/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 3711395.7500\n",
            "Epoch 50/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3977204.2500\n",
            "Model Number: 372 with model SectionalMotif in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n",
            "05:21:06 - cmdstanpy - INFO - Chain [1] start processing\n",
            "05:21:06 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 373 with model FBProphet in generation 2 of 10\n",
            "Model Number: 374 with model WindowRegression in generation 2 of 10\n",
            "Model Number: 375 with model UnivariateMotif in generation 2 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 375: UnivariateMotif\n",
            "Model Number: 376 with model AverageValueNaive in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (250) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 377 with model NVAR in generation 2 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 377: NVAR\n",
            "Model Number: 378 with model UnivariateRegression in generation 2 of 10\n",
            "Model Number: 379 with model SectionalMotif in generation 2 of 10\n",
            "Model Number: 380 with model ConstantNaive in generation 2 of 10\n",
            "Model Number: 381 with model MultivariateMotif in generation 2 of 10\n",
            "Model Number: 382 with model SectionalMotif in generation 2 of 10\n",
            "Template Eval Error: ValueError('kth(=15) out of bounds (15)') in model 382: SectionalMotif\n",
            "Model Number: 383 with model WindowRegression in generation 2 of 10\n",
            "Model Number: 384 with model ConstantNaive in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 385 with model WindowRegression in generation 2 of 10\n",
            "Model Number: 386 with model ETS in generation 2 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Template Eval Error: ValueError('Model ETS returned NaN for one or more series. fail_on_forecast_nan=True') in model 386: ETS\n",
            "Model Number: 387 with model DatepartRegression in generation 2 of 10\n",
            "Model Number: 388 with model NVAR in generation 2 of 10\n",
            "Model Number: 389 with model WindowRegression in generation 2 of 10\n",
            "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]New Generation: 3 of 10\n",
            "Model Number: 390 with model LastValueNaive in generation 3 of 10\n",
            "Model Number: 391 with model UnivariateMotif in generation 3 of 10\n",
            "Model Number: 392 with model ETS in generation 3 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 393 with model AverageValueNaive in generation 3 of 10\n",
            "Model Number: 394 with model WindowRegression in generation 3 of 10\n",
            "Model Number: 395 with model UnivariateRegression in generation 3 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 395: UnivariateRegression\n",
            "Model Number: 396 with model ETS in generation 3 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 397 with model SeasonalNaive in generation 3 of 10\n",
            "Model Number: 398 with model ETS in generation 3 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 399 with model NVAR in generation 3 of 10\n",
            "Model Number: 400 with model GLM in generation 3 of 10\n",
            "Template Eval Error: ValueError('regression_type=user and no future_regressor passed') in model 400: GLM\n",
            "Model Number: 401 with model LastValueNaive in generation 3 of 10\n",
            "Model Number: 402 with model WindowRegression in generation 3 of 10\n",
            "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]Model Number: 403 with model UnivariateMotif in generation 3 of 10\n",
            "Model Number: 404 with model SectionalMotif in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: divide by zero encountered in log\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: invalid value encountered in add\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 405 with model UnivariateRegression in generation 3 of 10\n",
            "Model Number: 406 with model FBProphet in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:21:12 - cmdstanpy - INFO - Chain [1] start processing\n",
            "05:21:12 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 407 with model UnivariateRegression in generation 3 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 407: UnivariateRegression\n",
            "Model Number: 408 with model UnobservedComponents in generation 3 of 10\n",
            "Model Number: 409 with model MultivariateRegression in generation 3 of 10\n",
            "Template Eval Error: LinAlgError('Singular matrix') in model 409: MultivariateRegression\n",
            "Model Number: 410 with model LastValueNaive in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:331: RuntimeWarning: divide by zero encountered in power\n",
            "  + np.power(y_pred, 2 - p) / (2 - p)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 411 with model NVAR in generation 3 of 10\n",
            "Model Number: 412 with model ConstantNaive in generation 3 of 10\n",
            "Model Number: 413 with model UnivariateRegression in generation 3 of 10\n",
            "Model Number: 414 with model WindowRegression in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: divide by zero encountered in log\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: invalid value encountered in add\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 415 with model SectionalMotif in generation 3 of 10\n",
            "Model Number: 416 with model UnivariateMotif in generation 3 of 10\n",
            "Model Number: 417 with model SeasonalNaive in generation 3 of 10\n",
            "Model Number: 418 with model ConstantNaive in generation 3 of 10\n",
            "Model Number: 419 with model GLS in generation 3 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 419: GLS\n",
            "Model Number: 420 with model ETS in generation 3 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 421 with model LastValueNaive in generation 3 of 10\n",
            "Model Number: 422 with model WindowRegression in generation 3 of 10\n",
            "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]Model Number: 423 with model UnivariateMotif in generation 3 of 10\n",
            "Model Number: 424 with model AverageValueNaive in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 425 with model SectionalMotif in generation 3 of 10\n",
            "Model Number: 426 with model SeasonalNaive in generation 3 of 10\n",
            "Model Number: 427 with model LastValueNaive in generation 3 of 10\n",
            "Model Number: 428 with model UnivariateRegression in generation 3 of 10\n",
            "Model Number: 429 with model GLS in generation 3 of 10\n",
            "Model Number: 430 with model SectionalMotif in generation 3 of 10\n",
            "Model Number: 431 with model UnivariateRegression in generation 3 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 431: UnivariateRegression\n",
            "Model Number: 432 with model NVAR in generation 3 of 10\n",
            "Model Number: 433 with model UnivariateRegression in generation 3 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 433: UnivariateRegression\n",
            "Model Number: 434 with model UnivariateMotif in generation 3 of 10\n",
            "Model Number: 435 with model GLS in generation 3 of 10\n",
            "Model Number: 436 with model SeasonalNaive in generation 3 of 10\n",
            "Model Number: 437 with model UnobservedComponents in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 438 with model AverageValueNaive in generation 3 of 10\n",
            "Model Number: 439 with model ConstantNaive in generation 3 of 10\n",
            "Model Number: 440 with model ETS in generation 3 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 441 with model SeasonalNaive in generation 3 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 441: SeasonalNaive\n",
            "Model Number: 442 with model MultivariateRegression in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:331: RuntimeWarning: divide by zero encountered in power\n",
            "  + np.power(y_pred, 2 - p) / (2 - p)\n",
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.3s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 443 with model ETS in generation 3 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 444 with model NVAR in generation 3 of 10\n",
            "Model Number: 445 with model NVAR in generation 3 of 10\n",
            "Model Number: 446 with model SectionalMotif in generation 3 of 10\n",
            "Model Number: 447 with model LastValueNaive in generation 3 of 10\n",
            "Model Number: 448 with model ConstantNaive in generation 3 of 10\n",
            "Model Number: 449 with model WindowRegression in generation 3 of 10\n",
            "Model Number: 450 with model FBProphet in generation 3 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 450: FBProphet\n",
            "Model Number: 451 with model FBProphet in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:21:17 - cmdstanpy - INFO - Chain [1] start processing\n",
            "05:21:17 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 452 with model ConstantNaive in generation 3 of 10\n",
            "Model Number: 453 with model FBProphet in generation 3 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 453: FBProphet\n",
            "Model Number: 454 with model ETS in generation 3 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 455 with model AverageValueNaive in generation 3 of 10\n",
            "Model Number: 456 with model SeasonalNaive in generation 3 of 10\n",
            "Model Number: 457 with model FBProphet in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:21:20 - cmdstanpy - INFO - Chain [1] start processing\n",
            "05:21:20 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 458 with model LastValueNaive in generation 3 of 10\n",
            "Model Number: 459 with model WindowRegression in generation 3 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 459: WindowRegression\n",
            "Model Number: 460 with model DatepartRegression in generation 3 of 10\n",
            "Epoch 1/100\n",
            "7/7 [==============================] - 6s 6ms/step - loss: 0.1154\n",
            "Epoch 2/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0871\n",
            "Epoch 3/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0571\n",
            "Epoch 4/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0260\n",
            "Epoch 5/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0102\n",
            "Epoch 6/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0132\n",
            "Epoch 7/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0086\n",
            "Epoch 8/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0081\n",
            "Epoch 9/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0089\n",
            "Epoch 10/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0080\n",
            "Epoch 11/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0081\n",
            "Epoch 12/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0081\n",
            "Epoch 13/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0080\n",
            "Epoch 14/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0089\n",
            "Epoch 15/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0076\n",
            "Epoch 16/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0082\n",
            "Epoch 17/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0083\n",
            "Epoch 18/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0077\n",
            "Epoch 19/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0071\n",
            "Epoch 20/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0067\n",
            "Epoch 21/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0089\n",
            "Epoch 22/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0067\n",
            "Epoch 23/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0065\n",
            "Epoch 24/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0074\n",
            "Epoch 25/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0071\n",
            "Epoch 26/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0083\n",
            "Epoch 27/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0068\n",
            "Epoch 28/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0074\n",
            "Epoch 29/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0065\n",
            "Epoch 30/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0071\n",
            "Epoch 31/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0065\n",
            "Epoch 32/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0070\n",
            "Epoch 33/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0058\n",
            "Epoch 34/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0064\n",
            "Epoch 35/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0067\n",
            "Epoch 36/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0071\n",
            "Epoch 37/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0068\n",
            "Epoch 38/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0071\n",
            "Epoch 39/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0062\n",
            "Epoch 40/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0055\n",
            "Epoch 41/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0065\n",
            "Epoch 42/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0067\n",
            "Epoch 43/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0070\n",
            "Epoch 44/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0064\n",
            "Epoch 45/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0068\n",
            "Epoch 46/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0058\n",
            "Epoch 47/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0063\n",
            "Epoch 48/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0064\n",
            "Epoch 49/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0065\n",
            "Epoch 50/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0068\n",
            "Epoch 51/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0061\n",
            "Epoch 52/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0057\n",
            "Epoch 53/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0062\n",
            "Epoch 54/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0065\n",
            "Epoch 55/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0057\n",
            "Epoch 56/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0064\n",
            "Epoch 57/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0059\n",
            "Epoch 58/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0059\n",
            "Epoch 59/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0064\n",
            "Epoch 60/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0067\n",
            "Epoch 61/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0061\n",
            "Epoch 62/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0064\n",
            "Epoch 63/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0062\n",
            "Epoch 64/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0063\n",
            "Epoch 65/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0063\n",
            "Epoch 66/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0060\n",
            "Epoch 67/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0060\n",
            "Epoch 68/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0068\n",
            "Epoch 69/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0057\n",
            "Epoch 70/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0061\n",
            "Epoch 71/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0058\n",
            "Epoch 72/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0061\n",
            "Epoch 73/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0059\n",
            "Epoch 74/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0061\n",
            "Epoch 75/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0059\n",
            "Epoch 76/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0059\n",
            "Epoch 77/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0061\n",
            "Epoch 78/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0065\n",
            "Epoch 79/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0061\n",
            "Epoch 80/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0059\n",
            "Epoch 81/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0061\n",
            "Epoch 82/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0056\n",
            "Epoch 83/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0060\n",
            "Epoch 84/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0058\n",
            "Epoch 85/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0060\n",
            "Epoch 86/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0056\n",
            "Epoch 87/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0055\n",
            "Epoch 88/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0059\n",
            "Epoch 89/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0057\n",
            "Epoch 90/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0060\n",
            "Epoch 91/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0063\n",
            "Epoch 92/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0054\n",
            "Epoch 93/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0060\n",
            "Epoch 94/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0062\n",
            "Epoch 95/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0059\n",
            "Epoch 96/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0060\n",
            "Epoch 97/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0060\n",
            "Epoch 98/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0061\n",
            "Epoch 99/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0058\n",
            "Epoch 100/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0059\n",
            "Model Number: 461 with model UnivariateRegression in generation 3 of 10\n",
            "Model Number: 462 with model UnobservedComponents in generation 3 of 10\n",
            "Template Eval Error: ValueError('Provided exogenous values are not of the appropriate shape. Required (5, 1), got (5,).') in model 462: UnobservedComponents\n",
            "Model Number: 463 with model AverageValueNaive in generation 3 of 10\n",
            "Model Number: 464 with model UnivariateMotif in generation 3 of 10\n",
            "Model Number: 465 with model SeasonalNaive in generation 3 of 10\n",
            "Model Number: 466 with model SeasonalNaive in generation 3 of 10\n",
            "Model Number: 467 with model SeasonalNaive in generation 3 of 10\n",
            "Model Number: 468 with model ConstantNaive in generation 3 of 10\n",
            "Model Number: 469 with model GLS in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 470 with model LastValueNaive in generation 3 of 10\n",
            "Model Number: 471 with model UnivariateMotif in generation 3 of 10\n",
            "Model Number: 472 with model DatepartRegression in generation 3 of 10\n",
            "Model Number: 473 with model UnobservedComponents in generation 3 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 473: UnobservedComponents\n",
            "Model Number: 474 with model UnobservedComponents in generation 3 of 10\n",
            "Model Number: 475 with model SectionalMotif in generation 3 of 10\n",
            "Model Number: 476 with model ConstantNaive in generation 3 of 10\n",
            "Model Number: 477 with model ETS in generation 3 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 478 with model MultivariateRegression in generation 3 of 10\n",
            "Template Eval Error: ValueError(\"loss='poisson' requires non-negative y and sum(y) > 0.\") in model 478: MultivariateRegression\n",
            "Model Number: 479 with model ConstantNaive in generation 3 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 479: ConstantNaive\n",
            "Model Number: 480 with model UnivariateMotif in generation 3 of 10\n",
            "Model Number: 481 with model UnobservedComponents in generation 3 of 10\n",
            "Model Number: 482 with model LastValueNaive in generation 3 of 10\n",
            "Model Number: 483 with model NVAR in generation 3 of 10\n",
            "Model Number: 484 with model SectionalMotif in generation 3 of 10\n",
            "Model Number: 485 with model NVAR in generation 3 of 10\n",
            "Model Number: 486 with model GLS in generation 3 of 10\n",
            "Model Number: 487 with model GLM in generation 3 of 10\n",
            "Template Eval Error: TypeError(\"ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''\") in model 487: GLM\n",
            "Model Number: 488 with model SectionalMotif in generation 3 of 10\n",
            "Model Number: 489 with model ETS in generation 3 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 490 with model FBProphet in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:21:38 - cmdstanpy - INFO - Chain [1] start processing\n",
            "05:21:38 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 491 with model WindowRegression in generation 3 of 10\n",
            "Model Number: 492 with model MultivariateMotif in generation 3 of 10\n",
            "Template Eval Error: ValueError('kth(=100) out of bounds (83)') in model 492: MultivariateMotif\n",
            "Model Number: 493 with model UnobservedComponents in generation 3 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 493: UnobservedComponents\n",
            "Model Number: 494 with model DatepartRegression in generation 3 of 10\n",
            "Model Number: 495 with model NVAR in generation 3 of 10\n",
            "Model Number: 496 with model GLS in generation 3 of 10\n",
            "Model Number: 497 with model ConstantNaive in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 498 with model MultivariateRegression in generation 3 of 10\n",
            "Model Number: 499 with model MultivariateMotif in generation 3 of 10\n",
            "New Generation: 4 of 10\n",
            "Model Number: 500 with model UnivariateMotif in generation 4 of 10\n",
            "Model Number: 501 with model MultivariateMotif in generation 4 of 10\n",
            "Model Number: 502 with model UnivariateMotif in generation 4 of 10\n",
            "Model Number: 503 with model ETS in generation 4 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 504 with model NVAR in generation 4 of 10\n",
            "Model Number: 505 with model UnivariateRegression in generation 4 of 10\n",
            "Model Number: 506 with model ETS in generation 4 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: divide by zero encountered in log\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: invalid value encountered in add\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 507 with model ETS in generation 4 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 508 with model MultivariateMotif in generation 4 of 10\n",
            "Model Number: 509 with model AverageValueNaive in generation 4 of 10\n",
            "Model Number: 510 with model MultivariateRegression in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.4s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 511 with model ConstantNaive in generation 4 of 10\n",
            "Model Number: 512 with model ConstantNaive in generation 4 of 10\n",
            "Model Number: 513 with model MultivariateRegression in generation 4 of 10\n",
            "Template Eval Error: Exception('Transformer STLFilter failed on fit') in model 513: MultivariateRegression\n",
            "Model Number: 514 with model MultivariateMotif in generation 4 of 10\n",
            "Model Number: 515 with model SeasonalNaive in generation 4 of 10\n",
            "Model Number: 516 with model SectionalMotif in generation 4 of 10\n",
            "Model Number: 517 with model UnivariateMotif in generation 4 of 10\n",
            "Model Number: 518 with model ConstantNaive in generation 4 of 10\n",
            "Model Number: 519 with model SectionalMotif in generation 4 of 10\n",
            "Model Number: 520 with model WindowRegression in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 521 with model DatepartRegression in generation 4 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 521: DatepartRegression\n",
            "Model Number: 522 with model FBProphet in generation 4 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 522: FBProphet\n",
            "Model Number: 523 with model SeasonalNaive in generation 4 of 10\n",
            "Model Number: 524 with model ConstantNaive in generation 4 of 10\n",
            "Model Number: 525 with model SectionalMotif in generation 4 of 10\n",
            "Model Number: 526 with model SectionalMotif in generation 4 of 10\n",
            "Model Number: 527 with model MultivariateRegression in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.3s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: divide by zero encountered in log\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: invalid value encountered in add\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
            "05:21:44 - cmdstanpy - INFO - Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 528 with model FBProphet in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:21:44 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 529 with model GLS in generation 4 of 10\n",
            "Model Number: 530 with model AverageValueNaive in generation 4 of 10\n",
            "Model Number: 531 with model ConstantNaive in generation 4 of 10\n",
            "Model Number: 532 with model AverageValueNaive in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 533 with model WindowRegression in generation 4 of 10\n",
            "Model Number: 534 with model ETS in generation 4 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:21:46 - cmdstanpy - INFO - Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 535 with model FBProphet in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:21:46 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 536 with model ConstantNaive in generation 4 of 10\n",
            "Model Number: 537 with model DatepartRegression in generation 4 of 10\n",
            "Model Number: 538 with model LastValueNaive in generation 4 of 10\n",
            "Model Number: 539 with model LastValueNaive in generation 4 of 10\n",
            "Model Number: 540 with model LastValueNaive in generation 4 of 10\n",
            "Model Number: 541 with model SectionalMotif in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.596e-03, tolerance: 2.144e-04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 542 with model ConstantNaive in generation 4 of 10\n",
            "Model Number: 543 with model ConstantNaive in generation 4 of 10\n",
            "Model Number: 544 with model UnobservedComponents in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 545 with model UnivariateMotif in generation 4 of 10\n",
            "Model Number: 546 with model ConstantNaive in generation 4 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 546: ConstantNaive\n",
            "Model Number: 547 with model SeasonalNaive in generation 4 of 10\n",
            "Template Eval Error: Exception('Transformer STLFilter failed on fit') in model 547: SeasonalNaive\n",
            "Model Number: 548 with model SeasonalNaive in generation 4 of 10\n",
            "Model Number: 549 with model LastValueNaive in generation 4 of 10\n",
            "Model Number: 550 with model AverageValueNaive in generation 4 of 10\n",
            "Model Number: 551 with model MultivariateMotif in generation 4 of 10\n",
            "Template Eval Error: Exception('Transformer STLFilter failed on fit') in model 551: MultivariateMotif\n",
            "Model Number: 552 with model AverageValueNaive in generation 4 of 10\n",
            "Model Number: 553 with model AverageValueNaive in generation 4 of 10\n",
            "Model Number: 554 with model NVAR in generation 4 of 10\n",
            "Model Number: 555 with model UnivariateRegression in generation 4 of 10\n",
            "Model Number: 556 with model SeasonalNaive in generation 4 of 10\n",
            "Model Number: 557 with model GLS in generation 4 of 10\n",
            "Model Number: 558 with model LastValueNaive in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 559 with model LastValueNaive in generation 4 of 10\n",
            "Model Number: 560 with model UnobservedComponents in generation 4 of 10\n",
            "Template Eval Error: ValueError('Provided exogenous values are not of the appropriate shape. Required (5, 1), got (5,).') in model 560: UnobservedComponents\n",
            "Model Number: 561 with model AverageValueNaive in generation 4 of 10\n",
            "Model Number: 562 with model UnivariateRegression in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:331: RuntimeWarning: divide by zero encountered in power\n",
            "  + np.power(y_pred, 2 - p) / (2 - p)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 563 with model NVAR in generation 4 of 10\n",
            "Model Number: 564 with model NVAR in generation 4 of 10\n",
            "Model Number: 565 with model FBProphet in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: divide by zero encountered in log\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: invalid value encountered in add\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
            "05:21:49 - cmdstanpy - INFO - Chain [1] start processing\n",
            "05:21:49 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 566 with model SectionalMotif in generation 4 of 10\n",
            "Model Number: 567 with model UnivariateMotif in generation 4 of 10\n",
            "Template Eval Error: Exception('Transformer STLFilter failed on fit') in model 567: UnivariateMotif\n",
            "Model Number: 568 with model ConstantNaive in generation 4 of 10\n",
            "Model Number: 569 with model ConstantNaive in generation 4 of 10\n",
            "Model Number: 570 with model GLS in generation 4 of 10\n",
            "Model Number: 571 with model GLS in generation 4 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 571: GLS\n",
            "Model Number: 572 with model UnivariateMotif in generation 4 of 10\n",
            "Model Number: 573 with model FBProphet in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: divide by zero encountered in log\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: invalid value encountered in add\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
            "05:21:51 - cmdstanpy - INFO - Chain [1] start processing\n",
            "05:21:52 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 574 with model FBProphet in generation 4 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 574: FBProphet\n",
            "Model Number: 575 with model SectionalMotif in generation 4 of 10\n",
            "Model Number: 576 with model NVAR in generation 4 of 10\n",
            "Model Number: 577 with model NVAR in generation 4 of 10\n",
            "Model Number: 578 with model UnivariateRegression in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2683: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Template Eval Error: ValueError(\"Input contains NaN, infinity or a value too large for dtype('float32').\") in model 578: UnivariateRegression\n",
            "Model Number: 579 with model ETS in generation 4 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 580 with model UnivariateRegression in generation 4 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 580: UnivariateRegression\n",
            "Model Number: 581 with model ETS in generation 4 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 582 with model UnobservedComponents in generation 4 of 10\n",
            "Model Number: 583 with model SectionalMotif in generation 4 of 10\n",
            "Model Number: 584 with model GLS in generation 4 of 10\n",
            "Model Number: 585 with model AverageValueNaive in generation 4 of 10\n",
            "Model Number: 586 with model MultivariateMotif in generation 4 of 10\n",
            "Model Number: 587 with model UnivariateMotif in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 588 with model LastValueNaive in generation 4 of 10\n",
            "Model Number: 589 with model WindowRegression in generation 4 of 10\n",
            "Model Number: 590 with model SectionalMotif in generation 4 of 10\n",
            "Model Number: 591 with model UnivariateRegression in generation 4 of 10\n",
            "Model Number: 592 with model LastValueNaive in generation 4 of 10\n",
            "Model Number: 593 with model NVAR in generation 4 of 10\n",
            "Model Number: 594 with model SeasonalNaive in generation 4 of 10\n",
            "Model Number: 595 with model UnivariateMotif in generation 4 of 10\n",
            "Model Number: 596 with model GLS in generation 4 of 10\n",
            "Model Number: 597 with model ETS in generation 4 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:21:55 - cmdstanpy - INFO - Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 598 with model FBProphet in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:21:55 - cmdstanpy - INFO - Chain [1] done processing\n",
            "05:21:55 - cmdstanpy - ERROR - Chain [1] error: error during processing Communication error on send\n",
            "Optimization terminated abnormally. Falling back to Newton.\n",
            "05:21:55 - cmdstanpy - INFO - Chain [1] start processing\n",
            "05:21:56 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 599 with model NVAR in generation 4 of 10\n",
            "Model Number: 600 with model LastValueNaive in generation 4 of 10\n",
            "Model Number: 601 with model ConstantNaive in generation 4 of 10\n",
            "Model Number: 602 with model NVAR in generation 4 of 10\n",
            "Model Number: 603 with model UnivariateRegression in generation 4 of 10\n",
            "Model Number: 604 with model UnobservedComponents in generation 4 of 10\n",
            "Model Number: 605 with model UnivariateRegression in generation 4 of 10\n",
            "Model Number: 606 with model WindowRegression in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 607 with model SeasonalNaive in generation 4 of 10\n",
            "Model Number: 608 with model NVAR in generation 4 of 10\n",
            "Model Number: 609 with model WindowRegression in generation 4 of 10\n",
            "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LibLinear][LibLinear][LibLinear][LibLinear]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Generation: 5 of 10\n",
            "Model Number: 610 with model GLM in generation 5 of 10\n",
            "Model Number: 611 with model SectionalMotif in generation 5 of 10\n",
            "Model Number: 612 with model NVAR in generation 5 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/genmod/families/family.py:1440: RuntimeWarning: invalid value encountered in log\n",
            "  endog * np.log(endog / mu) + (mu - endog))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 613 with model UnivariateRegression in generation 5 of 10\n",
            "Model Number: 614 with model MultivariateMotif in generation 5 of 10\n",
            "Model Number: 615 with model LastValueNaive in generation 5 of 10\n",
            "Model Number: 616 with model UnivariateMotif in generation 5 of 10\n",
            "Model Number: 617 with model SectionalMotif in generation 5 of 10\n",
            "Model Number: 618 with model LastValueNaive in generation 5 of 10\n",
            "Model Number: 619 with model NVAR in generation 5 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: divide by zero encountered in log\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: invalid value encountered in add\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 620 with model AverageValueNaive in generation 5 of 10\n",
            "Model Number: 621 with model LastValueNaive in generation 5 of 10\n",
            "Model Number: 622 with model AverageValueNaive in generation 5 of 10\n",
            "Model Number: 623 with model GLS in generation 5 of 10\n",
            "Model Number: 624 with model WindowRegression in generation 5 of 10\n",
            "Template Eval Error: Exception('Transformer STLFilter failed on fit') in model 624: WindowRegression\n",
            "Model Number: 625 with model ETS in generation 5 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 626 with model SectionalMotif in generation 5 of 10\n",
            "Model Number: 627 with model ETS in generation 5 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "ETS failed on Close with ValueError('endog must be strictly positive when using multiplicative trend or seasonal components.')\n",
            "Model Number: 628 with model ConstantNaive in generation 5 of 10\n",
            "Model Number: 629 with model ConstantNaive in generation 5 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 630 with model SeasonalNaive in generation 5 of 10\n",
            "Model Number: 631 with model SectionalMotif in generation 5 of 10\n",
            "Model Number: 632 with model WindowRegression in generation 5 of 10\n",
            "Model Number: 633 with model NVAR in generation 5 of 10\n",
            "Model Number: 634 with model LastValueNaive in generation 5 of 10\n",
            "Model Number: 635 with model GLS in generation 5 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (250) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 636 with model WindowRegression in generation 5 of 10\n",
            "Model Number: 637 with model NVAR in generation 5 of 10\n",
            "Model Number: 638 with model UnivariateMotif in generation 5 of 10\n",
            "Model Number: 639 with model FBProphet in generation 5 of 10\n",
            "Model Number: 640 with model UnobservedComponents in generation 5 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 640: UnobservedComponents\n",
            "Model Number: 641 with model MultivariateMotif in generation 5 of 10\n",
            "Model Number: 642 with model ConstantNaive in generation 5 of 10\n",
            "Model Number: 643 with model UnivariateRegression in generation 5 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 643: UnivariateRegression\n",
            "Model Number: 644 with model AverageValueNaive in generation 5 of 10\n",
            "Model Number: 645 with model LastValueNaive in generation 5 of 10\n",
            "Model Number: 646 with model LastValueNaive in generation 5 of 10\n",
            "Model Number: 647 with model AverageValueNaive in generation 5 of 10\n",
            "Model Number: 648 with model UnivariateMotif in generation 5 of 10\n",
            "Model Number: 649 with model UnivariateRegression in generation 5 of 10\n",
            "Model Number: 650 with model ETS in generation 5 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "ETS failed on Close with ValueError('endog must be strictly positive when using multiplicative trend or seasonal components.')\n",
            "Model Number: 651 with model MultivariateMotif in generation 5 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 651: MultivariateMotif\n",
            "Model Number: 652 with model ConstantNaive in generation 5 of 10\n",
            "Model Number: 653 with model NVAR in generation 5 of 10\n",
            "Model Number: 654 with model FBProphet in generation 5 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:22:03 - cmdstanpy - INFO - Chain [1] start processing\n",
            "05:22:04 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 655 with model SectionalMotif in generation 5 of 10\n",
            "Model Number: 656 with model NVAR in generation 5 of 10\n",
            "Model Number: 657 with model GLS in generation 5 of 10\n",
            "Model Number: 658 with model AverageValueNaive in generation 5 of 10\n",
            "Model Number: 659 with model WindowRegression in generation 5 of 10\n",
            "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]Model Number: 660 with model LastValueNaive in generation 5 of 10\n",
            "Model Number: 661 with model SeasonalNaive in generation 5 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 662 with model SectionalMotif in generation 5 of 10\n",
            "Model Number: 663 with model GLS in generation 5 of 10\n",
            "Model Number: 664 with model ConstantNaive in generation 5 of 10\n",
            "Model Number: 665 with model ETS in generation 5 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 666 with model SectionalMotif in generation 5 of 10\n",
            "Model Number: 667 with model UnivariateMotif in generation 5 of 10\n",
            "Model Number: 668 with model UnivariateRegression in generation 5 of 10\n",
            "Model Number: 669 with model WindowRegression in generation 5 of 10\n",
            "Template Eval Error: ValueError('Some value(s) of y are out of the valid range for family PoissonDistribution') in model 669: WindowRegression\n",
            "Model Number: 670 with model SectionalMotif in generation 5 of 10\n",
            "Model Number: 671 with model AverageValueNaive in generation 5 of 10\n",
            "Model Number: 672 with model AverageValueNaive in generation 5 of 10\n",
            "Model Number: 673 with model ETS in generation 5 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 674 with model MultivariateMotif in generation 5 of 10\n",
            "Model Number: 675 with model LastValueNaive in generation 5 of 10\n",
            "Model Number: 676 with model SectionalMotif in generation 5 of 10\n",
            "Model Number: 677 with model MultivariateMotif in generation 5 of 10\n",
            "Model Number: 678 with model UnivariateRegression in generation 5 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 678: UnivariateRegression\n",
            "Model Number: 679 with model ConstantNaive in generation 5 of 10\n",
            "Model Number: 680 with model UnobservedComponents in generation 5 of 10\n",
            "Model Number: 681 with model FBProphet in generation 5 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:331: RuntimeWarning: divide by zero encountered in power\n",
            "  + np.power(y_pred, 2 - p) / (2 - p)\n",
            "05:22:07 - cmdstanpy - INFO - Chain [1] start processing\n",
            "05:22:07 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 682 with model NVAR in generation 5 of 10\n",
            "Model Number: 683 with model LastValueNaive in generation 5 of 10\n",
            "Model Number: 684 with model UnivariateRegression in generation 5 of 10\n",
            "Model Number: 685 with model SeasonalNaive in generation 5 of 10\n",
            "Model Number: 686 with model ConstantNaive in generation 5 of 10\n",
            "Model Number: 687 with model MultivariateMotif in generation 5 of 10\n",
            "Model Number: 688 with model WindowRegression in generation 5 of 10\n",
            "Model Number: 689 with model NVAR in generation 5 of 10\n",
            "Model Number: 690 with model SeasonalNaive in generation 5 of 10\n",
            "Model Number: 691 with model UnivariateRegression in generation 5 of 10\n",
            "Model Number: 692 with model UnivariateMotif in generation 5 of 10\n",
            "Model Number: 693 with model UnivariateRegression in generation 5 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 693: UnivariateRegression\n",
            "Model Number: 694 with model NVAR in generation 5 of 10\n",
            "Model Number: 695 with model UnivariateRegression in generation 5 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 695: UnivariateRegression\n",
            "Model Number: 696 with model DatepartRegression in generation 5 of 10\n",
            "Model Number: 697 with model UnivariateMotif in generation 5 of 10\n",
            "New Generation: 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.529e+08, tolerance: 6.314e+04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 698 with model NVAR in generation 6 of 10\n",
            "Model Number: 699 with model SeasonalNaive in generation 6 of 10\n",
            "Model Number: 700 with model ETS in generation 6 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 700: ETS\n",
            "Model Number: 701 with model UnivariateMotif in generation 6 of 10\n",
            "Model Number: 702 with model UnivariateRegression in generation 6 of 10\n",
            "Model Number: 703 with model LastValueNaive in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 704 with model ETS in generation 6 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 705 with model UnivariateMotif in generation 6 of 10\n",
            "Model Number: 706 with model MultivariateRegression in generation 6 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 706: MultivariateRegression\n",
            "Model Number: 707 with model ETS in generation 6 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 708 with model UnivariateMotif in generation 6 of 10\n",
            "Model Number: 709 with model UnivariateMotif in generation 6 of 10\n",
            "Model Number: 710 with model AverageValueNaive in generation 6 of 10\n",
            "Model Number: 711 with model UnivariateMotif in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 712 with model AverageValueNaive in generation 6 of 10\n",
            "Model Number: 713 with model UnivariateMotif in generation 6 of 10\n",
            "Model Number: 714 with model SeasonalNaive in generation 6 of 10\n",
            "Model Number: 715 with model FBProphet in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: divide by zero encountered in log\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: invalid value encountered in add\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
            "05:22:11 - cmdstanpy - INFO - Chain [1] start processing\n",
            "05:22:11 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 716 with model SectionalMotif in generation 6 of 10\n",
            "Model Number: 717 with model SeasonalNaive in generation 6 of 10\n",
            "Model Number: 718 with model ETS in generation 6 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 719 with model UnivariateRegression in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:331: RuntimeWarning: divide by zero encountered in power\n",
            "  + np.power(y_pred, 2 - p) / (2 - p)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 720 with model WindowRegression in generation 6 of 10\n",
            "Template Eval Error: ValueError(\"Input contains NaN, infinity or a value too large for dtype('float64').\") in model 720: WindowRegression\n",
            "Model Number: 721 with model LastValueNaive in generation 6 of 10\n",
            "Model Number: 722 with model GLS in generation 6 of 10\n",
            "Model Number: 723 with model ConstantNaive in generation 6 of 10\n",
            "Model Number: 724 with model UnivariateRegression in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_regression.py:470: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
            "  warnings.warn(empty_warning_msg)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 725 with model MultivariateRegression in generation 6 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 725: MultivariateRegression\n",
            "Model Number: 726 with model UnivariateMotif in generation 6 of 10\n",
            "Model Number: 727 with model SectionalMotif in generation 6 of 10\n",
            "Model Number: 728 with model AverageValueNaive in generation 6 of 10\n",
            "Model Number: 729 with model ETS in generation 6 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 730 with model MultivariateMotif in generation 6 of 10\n",
            "Model Number: 731 with model NVAR in generation 6 of 10\n",
            "Model Number: 732 with model UnivariateMotif in generation 6 of 10\n",
            "Model Number: 733 with model AverageValueNaive in generation 6 of 10\n",
            "Model Number: 734 with model ETS in generation 6 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 735 with model LastValueNaive in generation 6 of 10\n",
            "Model Number: 736 with model UnobservedComponents in generation 6 of 10\n",
            "Model Number: 737 with model SectionalMotif in generation 6 of 10\n",
            "Model Number: 738 with model WindowRegression in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 739 with model ConstantNaive in generation 6 of 10\n",
            "Model Number: 740 with model SectionalMotif in generation 6 of 10\n",
            "Model Number: 741 with model UnivariateMotif in generation 6 of 10\n",
            "Model Number: 742 with model GLS in generation 6 of 10\n",
            "Model Number: 743 with model LastValueNaive in generation 6 of 10\n",
            "Model Number: 744 with model NVAR in generation 6 of 10\n",
            "Model Number: 745 with model GLS in generation 6 of 10\n",
            "Model Number: 746 with model WindowRegression in generation 6 of 10\n",
            "Model Number: 747 with model LastValueNaive in generation 6 of 10\n",
            "Model Number: 748 with model NVAR in generation 6 of 10\n",
            "Model Number: 749 with model AverageValueNaive in generation 6 of 10\n",
            "Model Number: 750 with model UnobservedComponents in generation 6 of 10\n",
            "Model Number: 751 with model UnivariateRegression in generation 6 of 10\n",
            "Model Number: 752 with model UnivariateRegression in generation 6 of 10\n",
            "Model Number: 753 with model SectionalMotif in generation 6 of 10\n",
            "Model Number: 754 with model NVAR in generation 6 of 10\n",
            "Model Number: 755 with model WindowRegression in generation 6 of 10\n",
            "Model Number: 756 with model UnivariateMotif in generation 6 of 10\n",
            "Model Number: 757 with model SectionalMotif in generation 6 of 10\n",
            "Model Number: 758 with model SectionalMotif in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 759 with model ETS in generation 6 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "ETS failed on 0 with ValueError('endog must be strictly positive when using multiplicative trend or seasonal components.')\n",
            "Model Number: 760 with model UnivariateRegression in generation 6 of 10\n",
            "Model Number: 761 with model AverageValueNaive in generation 6 of 10\n",
            "Model Number: 762 with model SectionalMotif in generation 6 of 10\n",
            "Model Number: 763 with model UnobservedComponents in generation 6 of 10\n",
            "Model Number: 764 with model ConstantNaive in generation 6 of 10\n",
            "Model Number: 765 with model ConstantNaive in generation 6 of 10\n",
            "Model Number: 766 with model FBProphet in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:331: RuntimeWarning: divide by zero encountered in power\n",
            "  + np.power(y_pred, 2 - p) / (2 - p)\n",
            "05:23:01 - cmdstanpy - INFO - Chain [1] start processing\n",
            "05:23:02 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 767 with model SeasonalNaive in generation 6 of 10\n",
            "Model Number: 768 with model SeasonalNaive in generation 6 of 10\n",
            "Model Number: 769 with model LastValueNaive in generation 6 of 10\n",
            "Model Number: 770 with model SectionalMotif in generation 6 of 10\n",
            "Model Number: 771 with model LastValueNaive in generation 6 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 771: LastValueNaive\n",
            "Model Number: 772 with model GLM in generation 6 of 10\n",
            "Template Eval Error: TypeError(\"ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''\") in model 772: GLM\n",
            "Model Number: 773 with model FBProphet in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:23:03 - cmdstanpy - INFO - Chain [1] start processing\n",
            "05:23:04 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 774 with model UnivariateRegression in generation 6 of 10\n",
            "Model Number: 775 with model LastValueNaive in generation 6 of 10\n",
            "Model Number: 776 with model UnobservedComponents in generation 6 of 10\n",
            "Model Number: 777 with model MultivariateMotif in generation 6 of 10\n",
            "Model Number: 778 with model FBProphet in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:23:06 - cmdstanpy - INFO - Chain [1] start processing\n",
            "05:23:06 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 779 with model AverageValueNaive in generation 6 of 10\n",
            "Model Number: 780 with model NVAR in generation 6 of 10\n",
            "Model Number: 781 with model SectionalMotif in generation 6 of 10\n",
            "Model Number: 782 with model DatepartRegression in generation 6 of 10\n",
            "Epoch 1/50\n",
            "3/3 [==============================] - 6s 16ms/step - loss: 417.1075\n",
            "Epoch 2/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 251.8081\n",
            "Epoch 3/50\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 205.7735\n",
            "Epoch 4/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 195.9001\n",
            "Epoch 5/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 191.2685\n",
            "Epoch 6/50\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 244.7058\n",
            "Epoch 7/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 239.1913\n",
            "Epoch 8/50\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 188.9794\n",
            "Epoch 9/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 225.3706\n",
            "Epoch 10/50\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 217.5177\n",
            "Epoch 11/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 134.8719\n",
            "Epoch 12/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 166.5382\n",
            "Epoch 13/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 146.8954\n",
            "Epoch 14/50\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 192.9810\n",
            "Epoch 15/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 166.8193\n",
            "Epoch 16/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 128.2815\n",
            "Epoch 17/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 269.4810\n",
            "Epoch 18/50\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 147.9375\n",
            "Epoch 19/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 177.8006\n",
            "Epoch 20/50\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 177.2493\n",
            "Epoch 21/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 166.5769\n",
            "Epoch 22/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 167.2582\n",
            "Epoch 23/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 139.4852\n",
            "Epoch 24/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 134.2939\n",
            "Epoch 25/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 140.5101\n",
            "Epoch 26/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 133.0561\n",
            "Epoch 27/50\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 120.7266\n",
            "Epoch 28/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 206.8244\n",
            "Epoch 29/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 131.8390\n",
            "Epoch 30/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 130.7319\n",
            "Epoch 31/50\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 165.4256\n",
            "Epoch 32/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 130.2653\n",
            "Epoch 33/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 114.2609\n",
            "Epoch 34/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 210.0548\n",
            "Epoch 35/50\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 120.0171\n",
            "Epoch 36/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 109.9453\n",
            "Epoch 37/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 157.4390\n",
            "Epoch 38/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 120.4753\n",
            "Epoch 39/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 126.4952\n",
            "Epoch 40/50\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 132.3333\n",
            "Epoch 41/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 136.2239\n",
            "Epoch 42/50\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 109.5518\n",
            "Epoch 43/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 146.3980\n",
            "Epoch 44/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 125.6707\n",
            "Epoch 45/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 135.5514\n",
            "Epoch 46/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 121.9742\n",
            "Epoch 47/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 146.9022\n",
            "Epoch 48/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 115.4426\n",
            "Epoch 49/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 120.1507\n",
            "Epoch 50/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 134.2391\n",
            "Model Number: 783 with model MultivariateMotif in generation 6 of 10\n",
            "Model Number: 784 with model SectionalMotif in generation 6 of 10\n",
            "Model Number: 785 with model MultivariateMotif in generation 6 of 10\n",
            "New Generation: 7 of 10\n",
            "Model Number: 786 with model ConstantNaive in generation 7 of 10\n",
            "Model Number: 787 with model MultivariateRegression in generation 7 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 787: MultivariateRegression\n",
            "Model Number: 788 with model UnivariateRegression in generation 7 of 10\n",
            "Model Number: 789 with model ETS in generation 7 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 790 with model SectionalMotif in generation 7 of 10\n",
            "Template Eval Error: Exception('Transformer STLFilter failed on fit') in model 790: SectionalMotif\n",
            "Model Number: 791 with model GLS in generation 7 of 10\n",
            "Model Number: 792 with model UnobservedComponents in generation 7 of 10\n",
            "Template Eval Error: LinAlgError('Non-positive-definite forecast error covariance matrix encountered at period 2') in model 792: UnobservedComponents\n",
            "Model Number: 793 with model UnivariateMotif in generation 7 of 10\n",
            "Model Number: 794 with model UnobservedComponents in generation 7 of 10\n",
            "Model Number: 795 with model LastValueNaive in generation 7 of 10\n",
            "Model Number: 796 with model LastValueNaive in generation 7 of 10\n",
            "Model Number: 797 with model UnivariateRegression in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:331: RuntimeWarning: divide by zero encountered in power\n",
            "  + np.power(y_pred, 2 - p) / (2 - p)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 798 with model NVAR in generation 7 of 10\n",
            "Model Number: 799 with model DatepartRegression in generation 7 of 10\n",
            "Epoch 1/100\n",
            "7/7 [==============================] - 6s 7ms/step - loss: 3.0582e-05\n",
            "Epoch 2/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 2.1482e-05\n",
            "Epoch 3/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 1.3453e-05\n",
            "Epoch 4/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 1.1930e-05\n",
            "Epoch 5/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 7.8655e-06\n",
            "Epoch 6/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 5.5219e-06\n",
            "Epoch 7/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 5.1761e-06\n",
            "Epoch 8/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 3.1469e-06\n",
            "Epoch 9/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 3.3707e-06\n",
            "Epoch 10/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 3.0244e-06\n",
            "Epoch 11/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 3.6302e-06\n",
            "Epoch 12/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 3.7783e-06\n",
            "Epoch 13/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 2.9580e-06\n",
            "Epoch 14/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 2.4813e-06\n",
            "Epoch 15/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 1.8689e-06\n",
            "Epoch 16/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 1.8189e-06\n",
            "Epoch 17/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 1.5044e-06\n",
            "Epoch 18/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 1.3196e-06\n",
            "Epoch 19/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 1.1771e-06\n",
            "Epoch 20/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 8.6518e-07\n",
            "Epoch 21/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 1.0987e-06\n",
            "Epoch 22/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 9.4245e-07\n",
            "Epoch 23/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 8.8032e-07\n",
            "Epoch 24/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 7.5318e-07\n",
            "Epoch 25/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 5.8373e-07\n",
            "Epoch 26/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 5.7949e-07\n",
            "Epoch 27/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 6.3979e-07\n",
            "Epoch 28/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 7.6166e-07\n",
            "Epoch 29/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 5.4072e-07\n",
            "Epoch 30/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 4.3457e-07\n",
            "Epoch 31/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 4.6027e-07\n",
            "Epoch 32/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 3.6095e-07\n",
            "Epoch 33/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 3.1647e-07\n",
            "Epoch 34/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 2.7069e-07\n",
            "Epoch 35/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 2.8080e-07\n",
            "Epoch 36/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 2.6573e-07\n",
            "Epoch 37/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 2.4891e-07\n",
            "Epoch 38/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 2.5766e-07\n",
            "Epoch 39/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 2.5199e-07\n",
            "Epoch 40/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 2.1597e-07\n",
            "Epoch 41/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 2.2372e-07\n",
            "Epoch 42/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 2.3201e-07\n",
            "Epoch 43/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 2.2187e-07\n",
            "Epoch 44/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 1.5241e-07\n",
            "Epoch 45/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 1.6140e-07\n",
            "Epoch 46/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 1.3937e-07\n",
            "Epoch 47/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 1.1512e-07\n",
            "Epoch 48/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 1.3357e-07\n",
            "Epoch 49/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 1.0147e-07\n",
            "Epoch 50/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 9.3337e-08\n",
            "Epoch 51/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 1.2569e-07\n",
            "Epoch 52/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 9.0251e-08\n",
            "Epoch 53/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 9.3708e-08\n",
            "Epoch 54/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 9.2298e-08\n",
            "Epoch 55/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 7.1345e-08\n",
            "Epoch 56/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 5.4309e-08\n",
            "Epoch 57/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 7.3848e-08\n",
            "Epoch 58/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 6.0108e-08\n",
            "Epoch 59/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 5.2783e-08\n",
            "Epoch 60/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 5.0328e-08\n",
            "Epoch 61/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 5.4605e-08\n",
            "Epoch 62/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 5.6565e-08\n",
            "Epoch 63/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 4.4897e-08\n",
            "Epoch 64/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 4.1866e-08\n",
            "Epoch 65/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 4.4936e-08\n",
            "Epoch 66/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 4.0957e-08\n",
            "Epoch 67/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 3.7023e-08\n",
            "Epoch 68/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 2.5803e-08\n",
            "Epoch 69/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 2.8481e-08\n",
            "Epoch 70/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 3.0360e-08\n",
            "Epoch 71/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 2.8208e-08\n",
            "Epoch 72/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 2.8475e-08\n",
            "Epoch 73/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 2.8943e-08\n",
            "Epoch 74/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 2.6589e-08\n",
            "Epoch 75/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 1.8322e-08\n",
            "Epoch 76/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 2.8538e-08\n",
            "Epoch 77/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 2.6761e-08\n",
            "Epoch 78/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 2.1367e-08\n",
            "Epoch 79/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 2.0307e-08\n",
            "Epoch 80/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 2.7065e-08\n",
            "Epoch 81/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 1.7770e-08\n",
            "Epoch 82/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 2.2467e-08\n",
            "Epoch 83/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 2.2402e-08\n",
            "Epoch 84/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 2.0431e-08\n",
            "Epoch 85/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 2.2327e-08\n",
            "Epoch 86/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 1.8625e-08\n",
            "Epoch 87/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 2.0664e-08\n",
            "Epoch 88/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 3.6155e-08\n",
            "Epoch 89/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 3.6790e-08\n",
            "Epoch 90/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 2.2830e-08\n",
            "Epoch 91/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 1.6671e-08\n",
            "Epoch 92/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 1.0720e-08\n",
            "Epoch 93/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 1.3689e-08\n",
            "Epoch 94/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 1.2627e-08\n",
            "Epoch 95/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 1.6215e-08\n",
            "Epoch 96/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 1.0544e-08\n",
            "Epoch 97/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 1.6707e-08\n",
            "Epoch 98/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 1.2469e-08\n",
            "Epoch 99/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 1.1092e-08\n",
            "Epoch 100/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 1.2558e-08\n",
            "Model Number: 800 with model LastValueNaive in generation 7 of 10\n",
            "Model Number: 801 with model MultivariateMotif in generation 7 of 10\n",
            "Model Number: 802 with model UnivariateRegression in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 803 with model MultivariateMotif in generation 7 of 10\n",
            "Model Number: 804 with model SeasonalNaive in generation 7 of 10\n",
            "Model Number: 805 with model LastValueNaive in generation 7 of 10\n",
            "Model Number: 806 with model WindowRegression in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 807 with model MultivariateMotif in generation 7 of 10\n",
            "Model Number: 808 with model NVAR in generation 7 of 10\n",
            "Model Number: 809 with model NVAR in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 810 with model UnobservedComponents in generation 7 of 10\n",
            "Model Number: 811 with model WindowRegression in generation 7 of 10\n",
            "Model Number: 812 with model WindowRegression in generation 7 of 10\n",
            "Model Number: 813 with model SectionalMotif in generation 7 of 10\n",
            "Model Number: 814 with model UnivariateMotif in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:331: RuntimeWarning: divide by zero encountered in power\n",
            "  + np.power(y_pred, 2 - p) / (2 - p)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 815 with model ConstantNaive in generation 7 of 10\n",
            "Model Number: 816 with model WindowRegression in generation 7 of 10\n",
            "Model Number: 817 with model LastValueNaive in generation 7 of 10\n",
            "Model Number: 818 with model LastValueNaive in generation 7 of 10\n",
            "Model Number: 819 with model WindowRegression in generation 7 of 10\n",
            "Model Number: 820 with model UnivariateMotif in generation 7 of 10\n",
            "Model Number: 821 with model SectionalMotif in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:331: RuntimeWarning: divide by zero encountered in power\n",
            "  + np.power(y_pred, 2 - p) / (2 - p)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 822 with model WindowRegression in generation 7 of 10\n",
            "Model Number: 823 with model FBProphet in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:23:36 - cmdstanpy - INFO - Chain [1] start processing\n",
            "05:23:36 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 824 with model UnivariateMotif in generation 7 of 10\n",
            "Model Number: 825 with model AverageValueNaive in generation 7 of 10\n",
            "Model Number: 826 with model WindowRegression in generation 7 of 10\n",
            "[LibLinear]Model Number: 827 with model SectionalMotif in generation 7 of 10\n",
            "Template Eval Error: Exception('Transformer STLFilter failed on fit') in model 827: SectionalMotif\n",
            "Model Number: 828 with model DatepartRegression in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 829 with model UnivariateMotif in generation 7 of 10\n",
            "Model Number: 830 with model SectionalMotif in generation 7 of 10\n",
            "Model Number: 831 with model UnivariateRegression in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Done 100 out of 100 | elapsed:    0.6s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 832 with model LastValueNaive in generation 7 of 10\n",
            "Model Number: 833 with model SectionalMotif in generation 7 of 10\n",
            "Template Eval Error: Exception('Transformer STLFilter failed on fit') in model 833: SectionalMotif\n",
            "Model Number: 834 with model LastValueNaive in generation 7 of 10\n",
            "Model Number: 835 with model NVAR in generation 7 of 10\n",
            "Model Number: 836 with model AverageValueNaive in generation 7 of 10\n",
            "Model Number: 837 with model UnivariateMotif in generation 7 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 837: UnivariateMotif\n",
            "Model Number: 838 with model FBProphet in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:23:39 - cmdstanpy - INFO - Chain [1] start processing\n",
            "05:23:39 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 839 with model SectionalMotif in generation 7 of 10\n",
            "Model Number: 840 with model UnivariateMotif in generation 7 of 10\n",
            "Model Number: 841 with model FBProphet in generation 7 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 841: FBProphet\n",
            "Model Number: 842 with model MultivariateRegression in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 300 out of 300 | elapsed:    0.4s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 843 with model UnobservedComponents in generation 7 of 10\n",
            "Model Number: 844 with model LastValueNaive in generation 7 of 10\n",
            "Model Number: 845 with model MultivariateMotif in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:331: RuntimeWarning: divide by zero encountered in power\n",
            "  + np.power(y_pred, 2 - p) / (2 - p)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 846 with model WindowRegression in generation 7 of 10\n",
            "Model Number: 847 with model UnivariateMotif in generation 7 of 10\n",
            "Model Number: 848 with model SeasonalNaive in generation 7 of 10\n",
            "Model Number: 849 with model AverageValueNaive in generation 7 of 10\n",
            "Model Number: 850 with model ConstantNaive in generation 7 of 10\n",
            "Model Number: 851 with model SectionalMotif in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:331: RuntimeWarning: divide by zero encountered in power\n",
            "  + np.power(y_pred, 2 - p) / (2 - p)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 852 with model NVAR in generation 7 of 10\n",
            "Model Number: 853 with model MultivariateMotif in generation 7 of 10\n",
            "Model Number: 854 with model NVAR in generation 7 of 10\n",
            "Model Number: 855 with model UnobservedComponents in generation 7 of 10\n",
            "Model Number: 856 with model WindowRegression in generation 7 of 10\n",
            "Model Number: 857 with model MultivariateRegression in generation 7 of 10\n",
            "Template Eval Error: Exception('Transformer STLFilter failed on fit') in model 857: MultivariateRegression\n",
            "Model Number: 858 with model UnivariateMotif in generation 7 of 10\n",
            "Model Number: 859 with model SectionalMotif in generation 7 of 10\n",
            "Model Number: 860 with model LastValueNaive in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 861 with model UnivariateMotif in generation 7 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 861: UnivariateMotif\n",
            "Model Number: 862 with model UnivariateRegression in generation 7 of 10\n",
            "Model Number: 863 with model FBProphet in generation 7 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 863: FBProphet\n",
            "Model Number: 864 with model UnivariateRegression in generation 7 of 10\n",
            "Model Number: 865 with model AverageValueNaive in generation 7 of 10\n",
            "Model Number: 866 with model AverageValueNaive in generation 7 of 10\n",
            "Model Number: 867 with model NVAR in generation 7 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 867: NVAR\n",
            "Model Number: 868 with model WindowRegression in generation 7 of 10\n",
            "Model Number: 869 with model ETS in generation 7 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 870 with model SeasonalNaive in generation 7 of 10\n",
            "Model Number: 871 with model UnivariateRegression in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 872 with model NVAR in generation 7 of 10\n",
            "Model Number: 873 with model DatepartRegression in generation 7 of 10\n",
            "Epoch 1/200\n",
            "7/7 [==============================] - 6s 27ms/step - loss: 0.1674\n",
            "Epoch 2/200\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.1740\n",
            "Epoch 3/200\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.1627\n",
            "Epoch 4/200\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.1639\n",
            "Epoch 5/200\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1653\n",
            "Epoch 6/200\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1643\n",
            "Epoch 7/200\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1702\n",
            "Epoch 8/200\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.1662\n",
            "Epoch 9/200\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.1630\n",
            "Epoch 10/200\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1640\n",
            "Epoch 11/200\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1635\n",
            "Epoch 12/200\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1650\n",
            "Epoch 13/200\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.1632\n",
            "Epoch 14/200\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1642\n",
            "Epoch 15/200\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.1637\n",
            "Epoch 16/200\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1622\n",
            "Epoch 17/200\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1640\n",
            "Epoch 18/200\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.1634\n",
            "Epoch 19/200\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1613\n",
            "Epoch 20/200\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1635\n",
            "Epoch 21/200\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1649\n",
            "Epoch 22/200\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1645\n",
            "Epoch 23/200\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1628\n",
            "Epoch 24/200\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.1629\n",
            "Epoch 25/200\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.1643\n",
            "Epoch 26/200\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1636\n",
            "Epoch 27/200\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.1626\n",
            "Epoch 28/200\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1633\n",
            "Epoch 29/200\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1651\n",
            "Epoch 30/200\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.1643\n",
            "Epoch 31/200\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1620\n",
            "Epoch 32/200\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1632\n",
            "Epoch 33/200\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.1622\n",
            "Epoch 34/200\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.1628\n",
            "Epoch 35/200\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.1630\n",
            "Epoch 36/200\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.1625\n",
            "Epoch 37/200\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1622\n",
            "Epoch 38/200\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1622\n",
            "Epoch 39/200\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1622\n",
            "Epoch 40/200\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1659\n",
            "Epoch 41/200\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.1659\n",
            "Epoch 42/200\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.1626\n",
            "Epoch 43/200\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1627\n",
            "Epoch 44/200\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1629\n",
            "Epoch 45/200\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1626\n",
            "Epoch 46/200\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1621\n",
            "Epoch 47/200\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1625\n",
            "Epoch 48/200\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1637\n",
            "Epoch 49/200\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.1629\n",
            "Epoch 50/200\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.1623\n",
            "Epoch 51/200\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1631\n",
            "Epoch 52/200\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.1638\n",
            "Epoch 53/200\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1640\n",
            "Epoch 54/200\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1630\n",
            "Epoch 55/200\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.1623\n",
            "Epoch 56/200\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1630\n",
            "Epoch 57/200\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1627\n",
            "Epoch 58/200\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.1647\n",
            "Epoch 59/200\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1628\n",
            "Epoch 60/200\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.1623\n",
            "Epoch 61/200\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 0.1622\n",
            "Epoch 62/200\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1637\n",
            "Epoch 63/200\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.1639\n",
            "Epoch 64/200\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1632\n",
            "Epoch 65/200\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.1616\n",
            "Epoch 66/200\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.1627\n",
            "Epoch 67/200\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1633\n",
            "Epoch 68/200\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.1634\n",
            "Epoch 69/200\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.1617\n",
            "Epoch 70/200\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.1619\n",
            "Epoch 71/200\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1627\n",
            "Epoch 72/200\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1629\n",
            "Epoch 73/200\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1623\n",
            "Epoch 74/200\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1635\n",
            "Epoch 75/200\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.1625\n",
            "Epoch 76/200\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1633\n",
            "Epoch 77/200\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1625\n",
            "Epoch 78/200\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1618\n",
            "Epoch 79/200\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1632\n",
            "Epoch 80/200\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1636\n",
            "Epoch 81/200\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1644\n",
            "Epoch 82/200\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.1635\n",
            "Epoch 83/200\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1624\n",
            "Epoch 84/200\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1619\n",
            "Epoch 85/200\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.1629\n",
            "Epoch 86/200\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1634\n",
            "Epoch 87/200\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1632\n",
            "Epoch 88/200\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1630\n",
            "Epoch 89/200\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1626\n",
            "Epoch 90/200\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.1635\n",
            "Epoch 91/200\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.1624\n",
            "Epoch 92/200\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1620\n",
            "Epoch 93/200\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.1622\n",
            "Epoch 94/200\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.1623\n",
            "Epoch 95/200\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.1622\n",
            "Epoch 96/200\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.1630\n",
            "Epoch 97/200\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.1625\n",
            "Epoch 98/200\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1627\n",
            "Epoch 99/200\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.1628\n",
            "Epoch 100/200\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.1629\n",
            "Epoch 101/200\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.1629\n",
            "Epoch 102/200\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1619\n",
            "Epoch 103/200\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1632\n",
            "Epoch 104/200\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.1647\n",
            "Epoch 105/200\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.1638\n",
            "Epoch 106/200\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1621\n",
            "Epoch 107/200\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.1627\n",
            "Epoch 108/200\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1624\n",
            "Epoch 109/200\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1634\n",
            "Epoch 110/200\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1628\n",
            "Epoch 111/200\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1627\n",
            "Epoch 112/200\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1630\n",
            "Epoch 113/200\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.1629\n",
            "Epoch 114/200\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1631\n",
            "Epoch 115/200\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1627\n",
            "Epoch 116/200\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1625\n",
            "Epoch 117/200\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1627\n",
            "Epoch 118/200\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1622\n",
            "Epoch 119/200\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1625\n",
            "Epoch 120/200\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1625\n",
            "Epoch 121/200\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.1622\n",
            "Epoch 122/200\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1632\n",
            "Epoch 123/200\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1624\n",
            "Epoch 124/200\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.1625\n",
            "Epoch 125/200\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.1621\n",
            "Epoch 126/200\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.1623\n",
            "Epoch 127/200\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1626\n",
            "Epoch 128/200\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1622\n",
            "Epoch 129/200\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.1620\n",
            "Epoch 130/200\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.1624\n",
            "Epoch 131/200\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1627\n",
            "Epoch 132/200\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.1629\n",
            "Epoch 133/200\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.1624\n",
            "Epoch 134/200\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1622\n",
            "Epoch 135/200\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.1623\n",
            "Epoch 136/200\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.1628\n",
            "Epoch 137/200\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.1622\n",
            "Epoch 138/200\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.1627\n",
            "Epoch 139/200\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.1623\n",
            "Epoch 140/200\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.1630\n",
            "Epoch 141/200\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1630\n",
            "Epoch 142/200\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.1633\n",
            "Epoch 143/200\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.1625\n",
            "Epoch 144/200\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1627\n",
            "Epoch 145/200\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.1628\n",
            "Epoch 146/200\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1628\n",
            "Epoch 147/200\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1623\n",
            "Epoch 148/200\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1620\n",
            "Epoch 149/200\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.1625\n",
            "Epoch 150/200\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.1622\n",
            "Epoch 151/200\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1622\n",
            "Epoch 152/200\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1628\n",
            "Epoch 153/200\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1627\n",
            "Epoch 154/200\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1624\n",
            "Epoch 155/200\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1627\n",
            "Epoch 156/200\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1622\n",
            "Epoch 157/200\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1623\n",
            "Epoch 158/200\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.1627\n",
            "Epoch 159/200\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.1629\n",
            "Epoch 160/200\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.1648\n",
            "Epoch 161/200\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.1641\n",
            "Epoch 162/200\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.1623\n",
            "Epoch 163/200\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.1621\n",
            "Epoch 164/200\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1624\n",
            "Epoch 165/200\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.1635\n",
            "Epoch 166/200\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1625\n",
            "Epoch 167/200\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1619\n",
            "Epoch 168/200\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.1623\n",
            "Epoch 169/200\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1615\n",
            "Epoch 170/200\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1622\n",
            "Epoch 171/200\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.1628\n",
            "Epoch 172/200\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1625\n",
            "Epoch 173/200\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.1620\n",
            "Epoch 174/200\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.1625\n",
            "Epoch 175/200\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.1619\n",
            "Epoch 176/200\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.1624\n",
            "Epoch 177/200\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1625\n",
            "Epoch 178/200\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1628\n",
            "Epoch 179/200\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.1627\n",
            "Epoch 180/200\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.1626\n",
            "Epoch 181/200\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.1616\n",
            "Epoch 182/200\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.1626\n",
            "Epoch 183/200\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1628\n",
            "Epoch 184/200\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1627\n",
            "Epoch 185/200\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.1623\n",
            "Epoch 186/200\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1620\n",
            "Epoch 187/200\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.1622\n",
            "Epoch 188/200\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.1624\n",
            "Epoch 189/200\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.1614\n",
            "Epoch 190/200\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.1614\n",
            "Epoch 191/200\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.1618\n",
            "Epoch 192/200\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1625\n",
            "Epoch 193/200\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1621\n",
            "Epoch 194/200\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.1621\n",
            "Epoch 195/200\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.1634\n",
            "Epoch 196/200\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1653\n",
            "Epoch 197/200\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.1664\n",
            "Epoch 198/200\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.1638\n",
            "Epoch 199/200\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.1637\n",
            "Epoch 200/200\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.1631\n",
            "New Generation: 8 of 10\n",
            "Model Number: 874 with model NVAR in generation 8 of 10\n",
            "Model Number: 875 with model ETS in generation 8 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 876 with model UnivariateMotif in generation 8 of 10\n",
            "Model Number: 877 with model ConstantNaive in generation 8 of 10\n",
            "Model Number: 878 with model WindowRegression in generation 8 of 10\n",
            "[LibLinear]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]Model Number: 879 with model SectionalMotif in generation 8 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 879: SectionalMotif\n",
            "Model Number: 880 with model AverageValueNaive in generation 8 of 10\n",
            "Model Number: 881 with model LastValueNaive in generation 8 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 882 with model WindowRegression in generation 8 of 10\n",
            "[LibLinear]Model Number: 883 with model UnivariateMotif in generation 8 of 10\n",
            "Model Number: 884 with model SeasonalNaive in generation 8 of 10\n",
            "Model Number: 885 with model UnivariateMotif in generation 8 of 10\n",
            "Model Number: 886 with model ConstantNaive in generation 8 of 10\n",
            "Model Number: 887 with model SectionalMotif in generation 8 of 10\n",
            "Model Number: 888 with model LastValueNaive in generation 8 of 10\n",
            "Model Number: 889 with model UnivariateRegression in generation 8 of 10\n",
            "Model Number: 890 with model UnivariateMotif in generation 8 of 10\n",
            "Model Number: 891 with model SeasonalNaive in generation 8 of 10\n",
            "Model Number: 892 with model UnivariateRegression in generation 8 of 10\n",
            "Model Number: 893 with model DatepartRegression in generation 8 of 10\n",
            "Model Number: 894 with model UnivariateMotif in generation 8 of 10\n",
            "Model Number: 895 with model WindowRegression in generation 8 of 10\n",
            "Model Number: 896 with model AverageValueNaive in generation 8 of 10\n",
            "Model Number: 897 with model SectionalMotif in generation 8 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 897: SectionalMotif\n",
            "Model Number: 898 with model NVAR in generation 8 of 10\n",
            "Model Number: 899 with model MultivariateMotif in generation 8 of 10\n",
            "Model Number: 900 with model MultivariateMotif in generation 8 of 10\n",
            "Model Number: 901 with model UnobservedComponents in generation 8 of 10\n",
            "Template Eval Error: ValueError('Provided exogenous values are not of the appropriate shape. Required (5, 1), got (5,).') in model 901: UnobservedComponents\n",
            "Model Number: 902 with model NVAR in generation 8 of 10\n",
            "Model Number: 903 with model GLS in generation 8 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:331: RuntimeWarning: divide by zero encountered in power\n",
            "  + np.power(y_pred, 2 - p) / (2 - p)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 904 with model UnivariateRegression in generation 8 of 10\n",
            "Model Number: 905 with model ETS in generation 8 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 906 with model NVAR in generation 8 of 10\n",
            "Model Number: 907 with model FBProphet in generation 8 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:25:16 - cmdstanpy - INFO - Chain [1] start processing\n",
            "05:25:16 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 908 with model AverageValueNaive in generation 8 of 10\n",
            "Model Number: 909 with model UnivariateMotif in generation 8 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: divide by zero encountered in log\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: invalid value encountered in add\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: divide by zero encountered in log\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: invalid value encountered in add\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
            "05:25:17 - cmdstanpy - INFO - Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 910 with model FBProphet in generation 8 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:25:18 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 911 with model SeasonalNaive in generation 8 of 10\n",
            "Model Number: 912 with model NVAR in generation 8 of 10\n",
            "Model Number: 913 with model AverageValueNaive in generation 8 of 10\n",
            "Template Eval Error: Exception('Transformer STLFilter failed on fit') in model 913: AverageValueNaive\n",
            "Model Number: 914 with model AverageValueNaive in generation 8 of 10\n",
            "Model Number: 915 with model NVAR in generation 8 of 10\n",
            "Model Number: 916 with model UnivariateRegression in generation 8 of 10\n",
            "Model Number: 917 with model AverageValueNaive in generation 8 of 10\n",
            "Model Number: 918 with model WindowRegression in generation 8 of 10\n",
            "Epoch 1/100\n",
            "5/5 [==============================] - 4s 162ms/step - loss: 204.9993 - val_loss: 96.9974\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 84ms/step - loss: 123.3827 - val_loss: 94.4477\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 90ms/step - loss: 170.4732 - val_loss: 95.5719\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 87ms/step - loss: 148.8777 - val_loss: 92.6520\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 88ms/step - loss: 129.2919 - val_loss: 94.4972\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 87ms/step - loss: 151.1107 - val_loss: 93.9148\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 86ms/step - loss: 146.6533 - val_loss: 92.0455\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 148.7419 - val_loss: 92.0674\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 89ms/step - loss: 134.3324 - val_loss: 88.3963\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 88ms/step - loss: 142.6625 - val_loss: 91.9206\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 134.1451 - val_loss: 88.1387\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 90ms/step - loss: 133.1104 - val_loss: 91.6074\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 119.7548 - val_loss: 92.7003\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 93ms/step - loss: 129.3787 - val_loss: 93.4724\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 99ms/step - loss: 113.1439 - val_loss: 93.3413\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 116.8221 - val_loss: 88.3006\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 112.7932 - val_loss: 85.2370\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 133.4003 - val_loss: 95.1639\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 92ms/step - loss: 127.0185 - val_loss: 92.6413\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 91ms/step - loss: 123.0845 - val_loss: 93.4685\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 75ms/step - loss: 119.4779 - val_loss: 92.3744\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 72ms/step - loss: 116.3995 - val_loss: 88.9814\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 113.7078 - val_loss: 90.8848\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 125.5742 - val_loss: 88.9580\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 73ms/step - loss: 123.8103 - val_loss: 90.6420\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 110.7481 - val_loss: 92.5684\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 120.0870 - val_loss: 91.0261\n",
            "Model Number: 919 with model WindowRegression in generation 8 of 10\n",
            "Model Number: 920 with model AverageValueNaive in generation 8 of 10\n",
            "Model Number: 921 with model UnivariateMotif in generation 8 of 10\n",
            "Model Number: 922 with model LastValueNaive in generation 8 of 10\n",
            "Model Number: 923 with model LastValueNaive in generation 8 of 10\n",
            "Model Number: 924 with model LastValueNaive in generation 8 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: divide by zero encountered in log\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: invalid value encountered in add\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 925 with model MultivariateRegression in generation 8 of 10\n",
            "Model Number: 926 with model UnivariateRegression in generation 8 of 10\n",
            "Model Number: 927 with model LastValueNaive in generation 8 of 10\n",
            "Model Number: 928 with model UnobservedComponents in generation 8 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:25:37 - cmdstanpy - INFO - Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 929 with model FBProphet in generation 8 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:25:37 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 930 with model GLS in generation 8 of 10\n",
            "Model Number: 931 with model FBProphet in generation 8 of 10\n",
            "Model Number: 932 with model NVAR in generation 8 of 10\n",
            "Model Number: 933 with model UnobservedComponents in generation 8 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 933: UnobservedComponents\n",
            "Model Number: 934 with model SectionalMotif in generation 8 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:25:41 - cmdstanpy - INFO - Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 935 with model FBProphet in generation 8 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:25:41 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 936 with model UnivariateRegression in generation 8 of 10\n",
            "Model Number: 937 with model LastValueNaive in generation 8 of 10\n",
            "Model Number: 938 with model SectionalMotif in generation 8 of 10\n",
            "Model Number: 939 with model SectionalMotif in generation 8 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: divide by zero encountered in log\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: invalid value encountered in add\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 940 with model SectionalMotif in generation 8 of 10\n",
            "Model Number: 941 with model ETS in generation 8 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 942 with model SeasonalNaive in generation 8 of 10\n",
            "Model Number: 943 with model FBProphet in generation 8 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:25:44 - cmdstanpy - INFO - Chain [1] start processing\n",
            "05:25:44 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 944 with model MultivariateRegression in generation 8 of 10\n",
            "Model Number: 945 with model AverageValueNaive in generation 8 of 10\n",
            "Model Number: 946 with model SeasonalNaive in generation 8 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 947 with model ConstantNaive in generation 8 of 10\n",
            "Model Number: 948 with model NVAR in generation 8 of 10\n",
            "Model Number: 949 with model NVAR in generation 8 of 10\n",
            "Model Number: 950 with model MultivariateMotif in generation 8 of 10\n",
            "Model Number: 951 with model UnivariateRegression in generation 8 of 10\n",
            "Model Number: 952 with model GLS in generation 8 of 10\n",
            "Model Number: 953 with model UnivariateRegression in generation 8 of 10\n",
            "Model Number: 954 with model MultivariateMotif in generation 8 of 10\n",
            "Model Number: 955 with model MultivariateMotif in generation 8 of 10\n",
            "Model Number: 956 with model AverageValueNaive in generation 8 of 10\n",
            "Model Number: 957 with model SectionalMotif in generation 8 of 10\n",
            "Model Number: 958 with model ConstantNaive in generation 8 of 10\n",
            "Model Number: 959 with model UnivariateMotif in generation 8 of 10\n",
            "Model Number: 960 with model ETS in generation 8 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 961 with model SectionalMotif in generation 8 of 10\n",
            "New Generation: 9 of 10\n",
            "Model Number: 962 with model UnivariateRegression in generation 9 of 10\n",
            "Model Number: 963 with model SeasonalNaive in generation 9 of 10\n",
            "Model Number: 964 with model LastValueNaive in generation 9 of 10\n",
            "Model Number: 965 with model LastValueNaive in generation 9 of 10\n",
            "Model Number: 966 with model UnivariateRegression in generation 9 of 10\n",
            "Model Number: 967 with model FBProphet in generation 9 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 967: FBProphet\n",
            "Model Number: 968 with model ETS in generation 9 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 969 with model SectionalMotif in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 970 with model FBProphet in generation 9 of 10\n",
            "Model Number: 971 with model MultivariateMotif in generation 9 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 971: MultivariateMotif\n",
            "Model Number: 972 with model UnobservedComponents in generation 9 of 10\n",
            "Template Eval Error: Exception('Transformer STLFilter failed on fit') in model 972: UnobservedComponents\n",
            "Model Number: 973 with model UnivariateMotif in generation 9 of 10\n",
            "Model Number: 974 with model WindowRegression in generation 9 of 10\n",
            "[LibLinear]Model Number: 975 with model LastValueNaive in generation 9 of 10\n",
            "Model Number: 976 with model LastValueNaive in generation 9 of 10\n",
            "Model Number: 977 with model ConstantNaive in generation 9 of 10\n",
            "Model Number: 978 with model FBProphet in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:331: RuntimeWarning: divide by zero encountered in power\n",
            "  + np.power(y_pred, 2 - p) / (2 - p)\n",
            "05:25:49 - cmdstanpy - INFO - Chain [1] start processing\n",
            "05:25:49 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 979 with model ETS in generation 9 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 980 with model ETS in generation 9 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 981 with model UnivariateMotif in generation 9 of 10\n",
            "Model Number: 982 with model UnivariateRegression in generation 9 of 10\n",
            "Model Number: 983 with model UnivariateRegression in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 984 with model SeasonalNaive in generation 9 of 10\n",
            "Model Number: 985 with model FBProphet in generation 9 of 10\n",
            "Model Number: 986 with model AverageValueNaive in generation 9 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 986: AverageValueNaive\n",
            "Model Number: 987 with model ConstantNaive in generation 9 of 10\n",
            "Model Number: 988 with model ConstantNaive in generation 9 of 10\n",
            "Model Number: 989 with model SectionalMotif in generation 9 of 10\n",
            "Model Number: 990 with model LastValueNaive in generation 9 of 10\n",
            "Model Number: 991 with model LastValueNaive in generation 9 of 10\n",
            "Model Number: 992 with model AverageValueNaive in generation 9 of 10\n",
            "Model Number: 993 with model ConstantNaive in generation 9 of 10\n",
            "Model Number: 994 with model LastValueNaive in generation 9 of 10\n",
            "Model Number: 995 with model NVAR in generation 9 of 10\n",
            "Model Number: 996 with model FBProphet in generation 9 of 10\n",
            "Model Number: 997 with model LastValueNaive in generation 9 of 10\n",
            "Model Number: 998 with model SectionalMotif in generation 9 of 10\n",
            "Model Number: 999 with model SectionalMotif in generation 9 of 10\n",
            "Model Number: 1000 with model ConstantNaive in generation 9 of 10\n",
            "Model Number: 1001 with model FBProphet in generation 9 of 10\n",
            "Model Number: 1002 with model UnivariateRegression in generation 9 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 1002: UnivariateRegression\n",
            "Model Number: 1003 with model UnobservedComponents in generation 9 of 10\n",
            "Template Eval Error: Exception('Transformer STLFilter failed on fit') in model 1003: UnobservedComponents\n",
            "Model Number: 1004 with model ConstantNaive in generation 9 of 10\n",
            "Model Number: 1005 with model UnobservedComponents in generation 9 of 10\n",
            "Model Number: 1006 with model LastValueNaive in generation 9 of 10\n",
            "Model Number: 1007 with model SeasonalNaive in generation 9 of 10\n",
            "Model Number: 1008 with model DatepartRegression in generation 9 of 10\n",
            "Model Number: 1009 with model AverageValueNaive in generation 9 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 1009: AverageValueNaive\n",
            "Model Number: 1010 with model NVAR in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1011 with model GLS in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n",
            "05:25:58 - cmdstanpy - INFO - Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1012 with model FBProphet in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:25:58 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1013 with model ConstantNaive in generation 9 of 10\n",
            "Model Number: 1014 with model SectionalMotif in generation 9 of 10\n",
            "Model Number: 1015 with model LastValueNaive in generation 9 of 10\n",
            "Model Number: 1016 with model SeasonalNaive in generation 9 of 10\n",
            "Model Number: 1017 with model NVAR in generation 9 of 10\n",
            "Model Number: 1018 with model WindowRegression in generation 9 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 1018: WindowRegression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:26:00 - cmdstanpy - INFO - Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1019 with model FBProphet in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:26:00 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1020 with model NVAR in generation 9 of 10\n",
            "Model Number: 1021 with model UnivariateMotif in generation 9 of 10\n",
            "Model Number: 1022 with model UnivariateMotif in generation 9 of 10\n",
            "Model Number: 1023 with model SeasonalNaive in generation 9 of 10\n",
            "Model Number: 1024 with model FBProphet in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n",
            "05:26:01 - cmdstanpy - INFO - Chain [1] start processing\n",
            "05:26:01 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1025 with model NVAR in generation 9 of 10\n",
            "Model Number: 1026 with model WindowRegression in generation 9 of 10\n",
            "Model Number: 1027 with model ConstantNaive in generation 9 of 10\n",
            "Model Number: 1028 with model WindowRegression in generation 9 of 10\n",
            "Model Number: 1029 with model WindowRegression in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: divide by zero encountered in log\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: invalid value encountered in add\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1030 with model ConstantNaive in generation 9 of 10\n",
            "Model Number: 1031 with model WindowRegression in generation 9 of 10\n",
            "Model Number: 1032 with model UnivariateRegression in generation 9 of 10\n",
            "Model Number: 1033 with model UnobservedComponents in generation 9 of 10\n",
            "Model Number: 1034 with model ETS in generation 9 of 10\n",
            "Template Eval Error: Exception('Transformer STLFilter failed on fit') in model 1034: ETS\n",
            "Model Number: 1035 with model LastValueNaive in generation 9 of 10\n",
            "Model Number: 1036 with model LastValueNaive in generation 9 of 10\n",
            "Model Number: 1037 with model UnivariateMotif in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1038 with model AverageValueNaive in generation 9 of 10\n",
            "Model Number: 1039 with model SectionalMotif in generation 9 of 10\n",
            "Model Number: 1040 with model GLS in generation 9 of 10\n",
            "Model Number: 1041 with model GLM in generation 9 of 10\n",
            "Template Eval Error: ValueError('NaN, inf or invalid value detected in weights, estimation infeasible.') in model 1041: GLM\n",
            "Model Number: 1042 with model UnivariateRegression in generation 9 of 10\n",
            "Model Number: 1043 with model WindowRegression in generation 9 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 1043: WindowRegression\n",
            "Model Number: 1044 with model WindowRegression in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/genmod/families/family.py:428: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  endog_mu = self._clean(endog / mu)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/genmod/families/family.py:134: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n",
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1045 with model UnivariateMotif in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1046 with model MultivariateMotif in generation 9 of 10\n",
            "Model Number: 1047 with model LastValueNaive in generation 9 of 10\n",
            "Model Number: 1048 with model UnivariateMotif in generation 9 of 10\n",
            "Model Number: 1049 with model SectionalMotif in generation 9 of 10\n",
            "New Generation: 10 of 10\n",
            "Model Number: 1050 with model LastValueNaive in generation 10 of 10\n",
            "Model Number: 1051 with model AverageValueNaive in generation 10 of 10\n",
            "Model Number: 1052 with model NVAR in generation 10 of 10\n",
            "Model Number: 1053 with model SectionalMotif in generation 10 of 10\n",
            "Model Number: 1054 with model GLS in generation 10 of 10\n",
            "Model Number: 1055 with model UnivariateMotif in generation 10 of 10\n",
            "Model Number: 1056 with model SectionalMotif in generation 10 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 1056: SectionalMotif\n",
            "Model Number: 1057 with model UnivariateMotif in generation 10 of 10\n",
            "Model Number: 1058 with model ConstantNaive in generation 10 of 10\n",
            "Model Number: 1059 with model AverageValueNaive in generation 10 of 10\n",
            "Model Number: 1060 with model UnivariateMotif in generation 10 of 10\n",
            "Model Number: 1061 with model WindowRegression in generation 10 of 10\n",
            "Model Number: 1062 with model UnivariateRegression in generation 10 of 10\n",
            "Model Number: 1063 with model UnivariateRegression in generation 10 of 10\n",
            "Model Number: 1064 with model SectionalMotif in generation 10 of 10\n",
            "Model Number: 1065 with model LastValueNaive in generation 10 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1066 with model UnivariateMotif in generation 10 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 1066: UnivariateMotif\n",
            "Model Number: 1067 with model AverageValueNaive in generation 10 of 10\n",
            "Model Number: 1068 with model FBProphet in generation 10 of 10\n",
            "Model Number: 1069 with model GLS in generation 10 of 10\n",
            "Model Number: 1070 with model WindowRegression in generation 10 of 10\n",
            "Model Number: 1071 with model SeasonalNaive in generation 10 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1072 with model FBProphet in generation 10 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 1072: FBProphet\n",
            "Model Number: 1073 with model FBProphet in generation 10 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:26:08 - cmdstanpy - INFO - Chain [1] start processing\n",
            "05:26:08 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1074 with model SectionalMotif in generation 10 of 10\n",
            "Template Eval Error: LinAlgError('Singular matrix') in model 1074: SectionalMotif\n",
            "Model Number: 1075 with model ConstantNaive in generation 10 of 10\n",
            "Model Number: 1076 with model ConstantNaive in generation 10 of 10\n",
            "Model Number: 1077 with model LastValueNaive in generation 10 of 10\n",
            "Model Number: 1078 with model ConstantNaive in generation 10 of 10\n",
            "Model Number: 1079 with model SectionalMotif in generation 10 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 1079: SectionalMotif\n",
            "Model Number: 1080 with model UnivariateMotif in generation 10 of 10\n",
            "Model Number: 1081 with model SectionalMotif in generation 10 of 10\n",
            "Model Number: 1082 with model SeasonalNaive in generation 10 of 10\n",
            "Model Number: 1083 with model AverageValueNaive in generation 10 of 10\n",
            "Model Number: 1084 with model UnivariateRegression in generation 10 of 10\n",
            "Model Number: 1085 with model MultivariateMotif in generation 10 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 1085: MultivariateMotif\n",
            "Model Number: 1086 with model SectionalMotif in generation 10 of 10\n",
            "Model Number: 1087 with model LastValueNaive in generation 10 of 10\n",
            "Model Number: 1088 with model ConstantNaive in generation 10 of 10\n",
            "Model Number: 1089 with model SectionalMotif in generation 10 of 10\n",
            "Model Number: 1090 with model UnivariateMotif in generation 10 of 10\n",
            "Model Number: 1091 with model LastValueNaive in generation 10 of 10\n",
            "Model Number: 1092 with model SectionalMotif in generation 10 of 10\n",
            "Model Number: 1093 with model AverageValueNaive in generation 10 of 10\n",
            "Model Number: 1094 with model ETS in generation 10 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 1095 with model WindowRegression in generation 10 of 10\n",
            "Model Number: 1096 with model UnobservedComponents in generation 10 of 10\n",
            "Model Number: 1097 with model LastValueNaive in generation 10 of 10\n",
            "Template Eval Error: Exception('Transformer STLFilter failed on fit') in model 1097: LastValueNaive\n",
            "Model Number: 1098 with model SeasonalNaive in generation 10 of 10\n",
            "Model Number: 1099 with model WindowRegression in generation 10 of 10\n",
            "Model Number: 1100 with model AverageValueNaive in generation 10 of 10\n",
            "Model Number: 1101 with model WindowRegression in generation 10 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1102 with model NVAR in generation 10 of 10\n",
            "Model Number: 1103 with model UnivariateRegression in generation 10 of 10\n",
            "Model Number: 1104 with model UnivariateRegression in generation 10 of 10\n",
            "Model Number: 1105 with model WindowRegression in generation 10 of 10\n",
            "Model Number: 1106 with model SectionalMotif in generation 10 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1107 with model ConstantNaive in generation 10 of 10\n",
            "Model Number: 1108 with model GLS in generation 10 of 10\n",
            "Model Number: 1109 with model AverageValueNaive in generation 10 of 10\n",
            "Model Number: 1110 with model WindowRegression in generation 10 of 10\n",
            "Model Number: 1111 with model NVAR in generation 10 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:26:12 - cmdstanpy - INFO - Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1112 with model SectionalMotif in generation 10 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 1112: SectionalMotif\n",
            "Model Number: 1113 with model FBProphet in generation 10 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:26:13 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1114 with model SectionalMotif in generation 10 of 10\n",
            "Model Number: 1115 with model SectionalMotif in generation 10 of 10\n",
            "Model Number: 1116 with model Ensemble in generation 11 of Ensembles\n",
            "Model Number: 1117 with model Ensemble in generation 11 of Ensembles\n",
            "Model Number: 1118 with model Ensemble in generation 11 of Ensembles\n",
            "Model Number: 1119 with model Ensemble in generation 11 of Ensembles\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1120 with model Ensemble in generation 11 of Ensembles\n",
            "Model Number: 1121 with model Ensemble in generation 11 of Ensembles\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1122 with model Ensemble in generation 11 of Ensembles\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1123 with model Ensemble in generation 11 of Ensembles\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Round: 1\n",
            "Model Number: 1 of 155 with model Ensemble for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📈 1 - Ensemble with avg smape 2.38: \n",
            "Model Number: 2 of 155 with model SectionalMotif for Validation 1\n",
            "2 - SectionalMotif with avg smape 2.55: \n",
            "Model Number: 3 of 155 with model LastValueNaive for Validation 1\n",
            "3 - LastValueNaive with avg smape 2.55: \n",
            "Model Number: 4 of 155 with model UnivariateMotif for Validation 1\n",
            "4 - UnivariateMotif with avg smape 2.55: \n",
            "Model Number: 5 of 155 with model UnivariateMotif for Validation 1\n",
            "5 - UnivariateMotif with avg smape 2.55: \n",
            "Model Number: 6 of 155 with model AverageValueNaive for Validation 1\n",
            "6 - AverageValueNaive with avg smape 2.55: \n",
            "Model Number: 7 of 155 with model ConstantNaive for Validation 1\n",
            "7 - ConstantNaive with avg smape 2.55: \n",
            "Model Number: 8 of 155 with model Ensemble for Validation 1\n",
            "8 - Ensemble with avg smape 2.55: \n",
            "Model Number: 9 of 155 with model UnivariateMotif for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9 - UnivariateMotif with avg smape 2.55: \n",
            "Model Number: 10 of 155 with model UnivariateRegression for Validation 1\n",
            "10 - UnivariateRegression with avg smape 2.55: \n",
            "Model Number: 11 of 155 with model SeasonalNaive for Validation 1\n",
            "11 - SeasonalNaive with avg smape 2.55: \n",
            "Model Number: 12 of 155 with model Ensemble for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12 - Ensemble with avg smape 2.55: \n",
            "Model Number: 13 of 155 with model Ensemble for Validation 1\n",
            "13 - Ensemble with avg smape 2.55: \n",
            "Model Number: 14 of 155 with model Ensemble for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14 - Ensemble with avg smape 2.55: \n",
            "Model Number: 15 of 155 with model SectionalMotif for Validation 1\n",
            "15 - SectionalMotif with avg smape 2.55: \n",
            "Model Number: 16 of 155 with model AverageValueNaive for Validation 1\n",
            "16 - AverageValueNaive with avg smape 2.55: \n",
            "Model Number: 17 of 155 with model UnivariateMotif for Validation 1\n",
            "17 - UnivariateMotif with avg smape 2.86: \n",
            "Model Number: 18 of 155 with model UnivariateMotif for Validation 1\n",
            "18 - UnivariateMotif with avg smape 2.54: \n",
            "Model Number: 19 of 155 with model LastValueNaive for Validation 1\n",
            "19 - LastValueNaive with avg smape 2.65: \n",
            "Model Number: 20 of 155 with model ETS for Validation 1\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "20 - ETS with avg smape 2.65: \n",
            "Model Number: 21 of 155 with model SectionalMotif for Validation 1\n",
            "21 - SectionalMotif with avg smape 2.65: \n",
            "Model Number: 22 of 155 with model LastValueNaive for Validation 1\n",
            "22 - LastValueNaive with avg smape 2.65: \n",
            "Model Number: 23 of 155 with model LastValueNaive for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23 - LastValueNaive with avg smape 2.65: \n",
            "Model Number: 24 of 155 with model LastValueNaive for Validation 1\n",
            "24 - LastValueNaive with avg smape 2.65: \n",
            "Model Number: 25 of 155 with model SectionalMotif for Validation 1\n",
            "25 - SectionalMotif with avg smape 2.65: \n",
            "Model Number: 26 of 155 with model SectionalMotif for Validation 1\n",
            "26 - SectionalMotif with avg smape 2.65: \n",
            "Model Number: 27 of 155 with model SectionalMotif for Validation 1\n",
            "27 - SectionalMotif with avg smape 2.65: \n",
            "Model Number: 28 of 155 with model SectionalMotif for Validation 1\n",
            "28 - SectionalMotif with avg smape 2.68: \n",
            "Model Number: 29 of 155 with model WindowRegression for Validation 1\n",
            "[LibLinear]29 - WindowRegression with avg smape 2.68: \n",
            "Model Number: 30 of 155 with model SectionalMotif for Validation 1\n",
            "30 - SectionalMotif with avg smape 2.68: \n",
            "Model Number: 31 of 155 with model LastValueNaive for Validation 1\n",
            "31 - LastValueNaive with avg smape 2.68: \n",
            "Model Number: 32 of 155 with model SectionalMotif for Validation 1\n",
            "32 - SectionalMotif with avg smape 2.68: \n",
            "Model Number: 33 of 155 with model NVAR for Validation 1\n",
            "33 - NVAR with avg smape 2.68: \n",
            "Model Number: 34 of 155 with model LastValueNaive for Validation 1\n",
            "34 - LastValueNaive with avg smape 2.68: \n",
            "Model Number: 35 of 155 with model ConstantNaive for Validation 1\n",
            "35 - ConstantNaive with avg smape 2.68: \n",
            "Model Number: 36 of 155 with model FBProphet for Validation 1\n",
            "36 - FBProphet with avg smape 2.52: \n",
            "Model Number: 37 of 155 with model LastValueNaive for Validation 1\n",
            "37 - LastValueNaive with avg smape 2.52: \n",
            "Model Number: 38 of 155 with model UnivariateRegression for Validation 1\n",
            "38 - UnivariateRegression with avg smape 2.52: \n",
            "Model Number: 39 of 155 with model UnivariateMotif for Validation 1\n",
            "39 - UnivariateMotif with avg smape 2.52: \n",
            "Model Number: 40 of 155 with model ETS for Validation 1\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "40 - ETS with avg smape 2.52: \n",
            "Model Number: 41 of 155 with model ETS for Validation 1\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41 - ETS with avg smape 2.52: \n",
            "Model Number: 42 of 155 with model LastValueNaive for Validation 1\n",
            "42 - LastValueNaive with avg smape 2.7: \n",
            "Model Number: 43 of 155 with model AverageValueNaive for Validation 1\n",
            "43 - AverageValueNaive with avg smape 2.48: \n",
            "Model Number: 44 of 155 with model Ensemble for Validation 1\n",
            "44 - Ensemble with avg smape 2.39: \n",
            "Model Number: 45 of 155 with model UnivariateMotif for Validation 1\n",
            "📈 45 - UnivariateMotif with avg smape 2.05: \n",
            "Model Number: 46 of 155 with model UnivariateMotif for Validation 1\n",
            "📈 46 - UnivariateMotif with avg smape 1.69: \n",
            "Model Number: 47 of 155 with model WindowRegression for Validation 1\n",
            "47 - WindowRegression with avg smape 2.96: \n",
            "Model Number: 48 of 155 with model UnivariateMotif for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48 - UnivariateMotif with avg smape 7.02: \n",
            "Model Number: 49 of 155 with model Ensemble for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "49 - Ensemble with avg smape 1.69: \n",
            "Model Number: 50 of 155 with model Ensemble for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50 - Ensemble with avg smape 1.81: \n",
            "Model Number: 51 of 155 with model ConstantNaive for Validation 1\n",
            "51 - ConstantNaive with avg smape 2.52: \n",
            "Model Number: 52 of 155 with model UnivariateRegression for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52 - UnivariateRegression with avg smape 5.39: \n",
            "Model Number: 53 of 155 with model UnivariateRegression for Validation 1\n",
            "53 - UnivariateRegression with avg smape 2.55: \n",
            "Model Number: 54 of 155 with model NVAR for Validation 1\n",
            "54 - NVAR with avg smape 86.18: \n",
            "Model Number: 55 of 155 with model AverageValueNaive for Validation 1\n",
            "55 - AverageValueNaive with avg smape 2.37: \n",
            "Model Number: 56 of 155 with model WindowRegression for Validation 1\n",
            "56 - WindowRegression with avg smape 3.2: \n",
            "Model Number: 57 of 155 with model NVAR for Validation 1\n",
            "57 - NVAR with avg smape 3.53: \n",
            "Model Number: 58 of 155 with model NVAR for Validation 1\n",
            "📈 58 - NVAR with avg smape 1.06: \n",
            "Model Number: 59 of 155 with model FBProphet for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:26:27 - cmdstanpy - INFO - Chain [1] start processing\n",
            "05:26:27 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59 - FBProphet with avg smape 1.31: \n",
            "Model Number: 60 of 155 with model NVAR for Validation 1\n",
            "📈 60 - NVAR with avg smape 0.84: \n",
            "Model Number: 61 of 155 with model UnivariateRegression for Validation 1\n",
            "61 - UnivariateRegression with avg smape 5.5: \n",
            "Model Number: 62 of 155 with model WindowRegression for Validation 1\n",
            "62 - WindowRegression with avg smape 3.11: \n",
            "Model Number: 63 of 155 with model UnivariateRegression for Validation 1\n",
            "63 - UnivariateRegression with avg smape 2.07: \n",
            "Model Number: 64 of 155 with model UnivariateRegression for Validation 1\n",
            "64 - UnivariateRegression with avg smape 0.9: \n",
            "Model Number: 65 of 155 with model AverageValueNaive for Validation 1\n",
            "65 - AverageValueNaive with avg smape 1.85: \n",
            "Model Number: 66 of 155 with model WindowRegression for Validation 1\n",
            "📈 66 - WindowRegression with avg smape 0.76: \n",
            "Model Number: 67 of 155 with model UnivariateRegression for Validation 1\n",
            "67 - UnivariateRegression with avg smape 1.77: \n",
            "Model Number: 68 of 155 with model UnivariateRegression for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "68 - UnivariateRegression with avg smape 1.77: \n",
            "Model Number: 69 of 155 with model AverageValueNaive for Validation 1\n",
            "69 - AverageValueNaive with avg smape 1.5: \n",
            "Model Number: 70 of 155 with model GLS for Validation 1\n",
            "70 - GLS with avg smape 0.82: \n",
            "Model Number: 71 of 155 with model ConstantNaive for Validation 1\n",
            "71 - ConstantNaive with avg smape 0.8: \n",
            "Model Number: 72 of 155 with model ConstantNaive for Validation 1\n",
            "72 - ConstantNaive with avg smape 0.8: \n",
            "Model Number: 73 of 155 with model WindowRegression for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73 - WindowRegression with avg smape 1.69: \n",
            "Model Number: 74 of 155 with model NVAR for Validation 1\n",
            "74 - NVAR with avg smape 0.89: \n",
            "Model Number: 75 of 155 with model UnobservedComponents for Validation 1\n",
            "75 - UnobservedComponents with avg smape 0.86: \n",
            "Model Number: 76 of 155 with model WindowRegression for Validation 1\n",
            "76 - WindowRegression with avg smape 1.18: \n",
            "Model Number: 77 of 155 with model ConstantNaive for Validation 1\n",
            "77 - ConstantNaive with avg smape 0.78: \n",
            "Model Number: 78 of 155 with model FBProphet for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "05:26:30 - cmdstanpy - INFO - Chain [1] start processing\n",
            "05:26:30 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "78 - FBProphet with avg smape 3.68: \n",
            "Model Number: 79 of 155 with model ConstantNaive for Validation 1\n",
            "79 - ConstantNaive with avg smape 0.79: \n",
            "Model Number: 80 of 155 with model ConstantNaive for Validation 1\n",
            "80 - ConstantNaive with avg smape 0.83: \n",
            "Model Number: 81 of 155 with model UnobservedComponents for Validation 1\n",
            "📈 81 - UnobservedComponents with avg smape 0.66: \n",
            "Model Number: 82 of 155 with model GLS for Validation 1\n",
            "82 - GLS with avg smape 0.93: \n",
            "Model Number: 83 of 155 with model AverageValueNaive for Validation 1\n",
            "83 - AverageValueNaive with avg smape 2.1: \n",
            "Model Number: 84 of 155 with model WindowRegression for Validation 1\n",
            "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]84 - WindowRegression with avg smape 2.12: \n",
            "Model Number: 85 of 155 with model ETS for Validation 1\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "85 - ETS with avg smape 1.23: \n",
            "Model Number: 86 of 155 with model ETS for Validation 1\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "86 - ETS with avg smape 1.23: \n",
            "Model Number: 87 of 155 with model ConstantNaive for Validation 1\n",
            "87 - ConstantNaive with avg smape 1.23: \n",
            "Model Number: 88 of 155 with model FBProphet for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:26:32 - cmdstanpy - INFO - Chain [1] start processing\n",
            "05:26:32 - cmdstanpy - INFO - Chain [1] done processing\n",
            "05:26:34 - cmdstanpy - INFO - Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "88 - FBProphet with avg smape 0.81: \n",
            "Model Number: 89 of 155 with model FBProphet for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:26:34 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "89 - FBProphet with avg smape 1.66: \n",
            "Model Number: 90 of 155 with model SeasonalNaive for Validation 1\n",
            "90 - SeasonalNaive with avg smape 0.68: \n",
            "Model Number: 91 of 155 with model AverageValueNaive for Validation 1\n",
            "91 - AverageValueNaive with avg smape 1.86: \n",
            "Model Number: 92 of 155 with model AverageValueNaive for Validation 1\n",
            "92 - AverageValueNaive with avg smape 1.85: \n",
            "Model Number: 93 of 155 with model UnobservedComponents for Validation 1\n",
            "93 - UnobservedComponents with avg smape 0.84: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "05:26:36 - cmdstanpy - INFO - Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 94 of 155 with model FBProphet for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:26:36 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94 - FBProphet with avg smape 0.76: \n",
            "Model Number: 95 of 155 with model WindowRegression for Validation 1\n",
            "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]95 - WindowRegression with avg smape 1.53: \n",
            "Model Number: 96 of 155 with model MultivariateMotif for Validation 1\n",
            "96 - MultivariateMotif with avg smape 1.62: \n",
            "Model Number: 97 of 155 with model ETS for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "97 - ETS with avg smape 0.79: \n",
            "Model Number: 98 of 155 with model GLS for Validation 1\n",
            "98 - GLS with avg smape 0.84: \n",
            "Model Number: 99 of 155 with model GLS for Validation 1\n",
            "99 - GLS with avg smape 0.82: \n",
            "Model Number: 100 of 155 with model UnobservedComponents for Validation 1\n",
            "100 - UnobservedComponents with avg smape 0.85: \n",
            "Model Number: 101 of 155 with model NVAR for Validation 1\n",
            "101 - NVAR with avg smape 1.97: \n",
            "Model Number: 102 of 155 with model MultivariateMotif for Validation 1\n",
            "102 - MultivariateMotif with avg smape 3.93: \n",
            "Model Number: 103 of 155 with model NVAR for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "103 - NVAR with avg smape 0.86: \n",
            "Model Number: 104 of 155 with model SeasonalNaive for Validation 1\n",
            "104 - SeasonalNaive with avg smape 2.53: \n",
            "Model Number: 105 of 155 with model SeasonalNaive for Validation 1\n",
            "105 - SeasonalNaive with avg smape 2.37: \n",
            "Model Number: 106 of 155 with model SeasonalNaive for Validation 1\n",
            "106 - SeasonalNaive with avg smape 2.98: \n",
            "Model Number: 107 of 155 with model ETS for Validation 1\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "107 - ETS with avg smape 1.6: \n",
            "Model Number: 108 of 155 with model ETS for Validation 1\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "108 - ETS with avg smape 1.44: \n",
            "Model Number: 109 of 155 with model MultivariateMotif for Validation 1\n",
            "109 - MultivariateMotif with avg smape 1.0: \n",
            "Model Number: 110 of 155 with model GLS for Validation 1\n",
            "110 - GLS with avg smape 0.86: \n",
            "Model Number: 111 of 155 with model ETS for Validation 1\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "111 - ETS with avg smape 1.24: \n",
            "Model Number: 112 of 155 with model SeasonalNaive for Validation 1\n",
            "112 - SeasonalNaive with avg smape 0.98: \n",
            "Model Number: 113 of 155 with model NVAR for Validation 1\n",
            "113 - NVAR with avg smape 1.72: \n",
            "Model Number: 114 of 155 with model GLS for Validation 1\n",
            "114 - GLS with avg smape 0.88: \n",
            "Model Number: 115 of 155 with model FBProphet for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "05:26:39 - cmdstanpy - INFO - Chain [1] start processing\n",
            "05:26:39 - cmdstanpy - INFO - Chain [1] done processing\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: divide by zero encountered in log\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: invalid value encountered in add\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
            "05:26:41 - cmdstanpy - INFO - Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "115 - FBProphet with avg smape 1.23: \n",
            "Model Number: 116 of 155 with model FBProphet for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:26:41 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "116 - FBProphet with avg smape 1.45: \n",
            "Model Number: 117 of 155 with model UnobservedComponents for Validation 1\n",
            "117 - UnobservedComponents with avg smape 1.23: \n",
            "Model Number: 118 of 155 with model SeasonalNaive for Validation 1\n",
            "118 - SeasonalNaive with avg smape 1.33: \n",
            "Model Number: 119 of 155 with model SeasonalNaive for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "119 - SeasonalNaive with avg smape 1.47: \n",
            "Model Number: 120 of 155 with model UnobservedComponents for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:26:43 - cmdstanpy - INFO - Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "120 - UnobservedComponents with avg smape 0.96: \n",
            "Model Number: 121 of 155 with model FBProphet for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:26:43 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "121 - FBProphet with avg smape 0.83: \n",
            "Model Number: 122 of 155 with model UnobservedComponents for Validation 1\n",
            "122 - UnobservedComponents with avg smape 0.96: \n",
            "Model Number: 123 of 155 with model GLS for Validation 1\n",
            "123 - GLS with avg smape 1.07: \n",
            "Model Number: 124 of 155 with model UnobservedComponents for Validation 1\n",
            "124 - UnobservedComponents with avg smape 1.04: \n",
            "Model Number: 125 of 155 with model SeasonalNaive for Validation 1\n",
            "125 - SeasonalNaive with avg smape 1.15: \n",
            "Model Number: 126 of 155 with model MultivariateMotif for Validation 1\n",
            "126 - MultivariateMotif with avg smape 3.23: \n",
            "Model Number: 127 of 155 with model MultivariateMotif for Validation 1\n",
            "127 - MultivariateMotif with avg smape 1.09: \n",
            "Model Number: 128 of 155 with model GLS for Validation 1\n",
            "128 - GLS with avg smape 1.41: \n",
            "Model Number: 129 of 155 with model GLS for Validation 1\n",
            "129 - GLS with avg smape 1.04: \n",
            "Model Number: 130 of 155 with model UnobservedComponents for Validation 1\n",
            "130 - UnobservedComponents with avg smape 1.42: \n",
            "Model Number: 131 of 155 with model MultivariateMotif for Validation 1\n",
            "131 - MultivariateMotif with avg smape 0.95: \n",
            "Model Number: 132 of 155 with model MultivariateMotif for Validation 1\n",
            "132 - MultivariateMotif with avg smape 1.11: \n",
            "Model Number: 133 of 155 with model MultivariateMotif for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "133 - MultivariateMotif with avg smape 1.33: \n",
            "Model Number: 134 of 155 with model MultivariateRegression for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.3s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "134 - MultivariateRegression with avg smape 3.39: \n",
            "Model Number: 135 of 155 with model MultivariateRegression for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Done 300 out of 300 | elapsed:    0.4s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "135 - MultivariateRegression with avg smape 3.52: \n",
            "Model Number: 136 of 155 with model MultivariateRegression for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.3s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📈 136 - MultivariateRegression with avg smape 0.44: \n",
            "Model Number: 137 of 155 with model MultivariateMotif for Validation 1\n",
            "137 - MultivariateMotif with avg smape 3.82: \n",
            "Model Number: 138 of 155 with model MultivariateRegression for Validation 1\n",
            "138 - MultivariateRegression with avg smape 5.48: \n",
            "Model Number: 139 of 155 with model MultivariateRegression for Validation 1\n",
            "139 - MultivariateRegression with avg smape 1.33: \n",
            "Model Number: 140 of 155 with model MultivariateRegression for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.3s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "140 - MultivariateRegression with avg smape 4.34: \n",
            "Model Number: 141 of 155 with model DatepartRegression for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "141 - DatepartRegression with avg smape 0.72: \n",
            "Model Number: 142 of 155 with model DatepartRegression for Validation 1\n",
            "Epoch 1/200\n",
            "6/6 [==============================] - 6s 29ms/step - loss: 0.1619\n",
            "Epoch 2/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1645\n",
            "Epoch 3/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1650\n",
            "Epoch 4/200\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.1665\n",
            "Epoch 5/200\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.1671\n",
            "Epoch 6/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1610\n",
            "Epoch 7/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1589\n",
            "Epoch 8/200\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.1629\n",
            "Epoch 9/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1626\n",
            "Epoch 10/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1614\n",
            "Epoch 11/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1625\n",
            "Epoch 12/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1630\n",
            "Epoch 13/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1610\n",
            "Epoch 14/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1611\n",
            "Epoch 15/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1610\n",
            "Epoch 16/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1623\n",
            "Epoch 17/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1621\n",
            "Epoch 18/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1611\n",
            "Epoch 19/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1638\n",
            "Epoch 20/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1629\n",
            "Epoch 21/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1626\n",
            "Epoch 22/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1615\n",
            "Epoch 23/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1602\n",
            "Epoch 24/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1628\n",
            "Epoch 25/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1627\n",
            "Epoch 26/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1617\n",
            "Epoch 27/200\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.1621\n",
            "Epoch 28/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1614\n",
            "Epoch 29/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1624\n",
            "Epoch 30/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1608\n",
            "Epoch 31/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1618\n",
            "Epoch 32/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1633\n",
            "Epoch 33/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1620\n",
            "Epoch 34/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1640\n",
            "Epoch 35/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1632\n",
            "Epoch 36/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1626\n",
            "Epoch 37/200\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.1627\n",
            "Epoch 38/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1601\n",
            "Epoch 39/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1621\n",
            "Epoch 40/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1623\n",
            "Epoch 41/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1616\n",
            "Epoch 42/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1610\n",
            "Epoch 43/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1614\n",
            "Epoch 44/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1603\n",
            "Epoch 45/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1620\n",
            "Epoch 46/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1620\n",
            "Epoch 47/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1622\n",
            "Epoch 48/200\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.1624\n",
            "Epoch 49/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1618\n",
            "Epoch 50/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1621\n",
            "Epoch 51/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1616\n",
            "Epoch 52/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1615\n",
            "Epoch 53/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1616\n",
            "Epoch 54/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1610\n",
            "Epoch 55/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1614\n",
            "Epoch 56/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1605\n",
            "Epoch 57/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1607\n",
            "Epoch 58/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1617\n",
            "Epoch 59/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1614\n",
            "Epoch 60/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1608\n",
            "Epoch 61/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1612\n",
            "Epoch 62/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1621\n",
            "Epoch 63/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1612\n",
            "Epoch 64/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1624\n",
            "Epoch 65/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1608\n",
            "Epoch 66/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1604\n",
            "Epoch 67/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1616\n",
            "Epoch 68/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1615\n",
            "Epoch 69/200\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.1614\n",
            "Epoch 70/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1622\n",
            "Epoch 71/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1614\n",
            "Epoch 72/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1620\n",
            "Epoch 73/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1608\n",
            "Epoch 74/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1615\n",
            "Epoch 75/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1612\n",
            "Epoch 76/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1619\n",
            "Epoch 77/200\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.1632\n",
            "Epoch 78/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1612\n",
            "Epoch 79/200\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.1623\n",
            "Epoch 80/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1606\n",
            "Epoch 81/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1612\n",
            "Epoch 82/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1613\n",
            "Epoch 83/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1609\n",
            "Epoch 84/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1619\n",
            "Epoch 85/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1613\n",
            "Epoch 86/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1611\n",
            "Epoch 87/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1616\n",
            "Epoch 88/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1614\n",
            "Epoch 89/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1623\n",
            "Epoch 90/200\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.1610\n",
            "Epoch 91/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1610\n",
            "Epoch 92/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1614\n",
            "Epoch 93/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1623\n",
            "Epoch 94/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1612\n",
            "Epoch 95/200\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.1617\n",
            "Epoch 96/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1623\n",
            "Epoch 97/200\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.1621\n",
            "Epoch 98/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1613\n",
            "Epoch 99/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1611\n",
            "Epoch 100/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1611\n",
            "Epoch 101/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1615\n",
            "Epoch 102/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1610\n",
            "Epoch 103/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1616\n",
            "Epoch 104/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1611\n",
            "Epoch 105/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1608\n",
            "Epoch 106/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1608\n",
            "Epoch 107/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1615\n",
            "Epoch 108/200\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.1615\n",
            "Epoch 109/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1606\n",
            "Epoch 110/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1613\n",
            "Epoch 111/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1616\n",
            "Epoch 112/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1604\n",
            "Epoch 113/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1611\n",
            "Epoch 114/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1612\n",
            "Epoch 115/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1616\n",
            "Epoch 116/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1613\n",
            "Epoch 117/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1618\n",
            "Epoch 118/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1608\n",
            "Epoch 119/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1611\n",
            "Epoch 120/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1610\n",
            "Epoch 121/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1606\n",
            "Epoch 122/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1616\n",
            "Epoch 123/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1614\n",
            "Epoch 124/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1612\n",
            "Epoch 125/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1615\n",
            "Epoch 126/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1607\n",
            "Epoch 127/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1617\n",
            "Epoch 128/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1614\n",
            "Epoch 129/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1616\n",
            "Epoch 130/200\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 0.1602\n",
            "Epoch 131/200\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.1612\n",
            "Epoch 132/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1612\n",
            "Epoch 133/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1611\n",
            "Epoch 134/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1611\n",
            "Epoch 135/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1608\n",
            "Epoch 136/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1624\n",
            "Epoch 137/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1611\n",
            "Epoch 138/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1611\n",
            "Epoch 139/200\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.1615\n",
            "Epoch 140/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1604\n",
            "Epoch 141/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1620\n",
            "Epoch 142/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1615\n",
            "Epoch 143/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1618\n",
            "Epoch 144/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1621\n",
            "Epoch 145/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1613\n",
            "Epoch 146/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1618\n",
            "Epoch 147/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1618\n",
            "Epoch 148/200\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.1611\n",
            "Epoch 149/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1610\n",
            "Epoch 150/200\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.1608\n",
            "Epoch 151/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1617\n",
            "Epoch 152/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1611\n",
            "Epoch 153/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1611\n",
            "Epoch 154/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1609\n",
            "Epoch 155/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1607\n",
            "Epoch 156/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1624\n",
            "Epoch 157/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1618\n",
            "Epoch 158/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1613\n",
            "Epoch 159/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1606\n",
            "Epoch 160/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1607\n",
            "Epoch 161/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1602\n",
            "Epoch 162/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1604\n",
            "Epoch 163/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1621\n",
            "Epoch 164/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1608\n",
            "Epoch 165/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1607\n",
            "Epoch 166/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1616\n",
            "Epoch 167/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1613\n",
            "Epoch 168/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1607\n",
            "Epoch 169/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1614\n",
            "Epoch 170/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1609\n",
            "Epoch 171/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1614\n",
            "Epoch 172/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1619\n",
            "Epoch 173/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1607\n",
            "Epoch 174/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1606\n",
            "Epoch 175/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1614\n",
            "Epoch 176/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1609\n",
            "Epoch 177/200\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.1606\n",
            "Epoch 178/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1604\n",
            "Epoch 179/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1611\n",
            "Epoch 180/200\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.1613\n",
            "Epoch 181/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1608\n",
            "Epoch 182/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1605\n",
            "Epoch 183/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1610\n",
            "Epoch 184/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1611\n",
            "Epoch 185/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1616\n",
            "Epoch 186/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1608\n",
            "Epoch 187/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1619\n",
            "Epoch 188/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1621\n",
            "Epoch 189/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1603\n",
            "Epoch 190/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1596\n",
            "Epoch 191/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1615\n",
            "Epoch 192/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1609\n",
            "Epoch 193/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1613\n",
            "Epoch 194/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1616\n",
            "Epoch 195/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1609\n",
            "Epoch 196/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1600\n",
            "Epoch 197/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1609\n",
            "Epoch 198/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1609\n",
            "Epoch 199/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1603\n",
            "Epoch 200/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1608\n",
            "142 - DatepartRegression with avg smape 2.51: \n",
            "Model Number: 143 of 155 with model MultivariateRegression for Validation 1\n",
            "143 - MultivariateRegression with avg smape 3.55: \n",
            "Model Number: 144 of 155 with model DatepartRegression for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "144 - DatepartRegression with avg smape 2.59: \n",
            "Model Number: 145 of 155 with model DatepartRegression for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "145 - DatepartRegression with avg smape 2.16: \n",
            "Model Number: 146 of 155 with model MultivariateRegression for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.3s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "146 - MultivariateRegression with avg smape 3.83: \n",
            "Model Number: 147 of 155 with model DatepartRegression for Validation 1\n",
            "Epoch 1/100\n",
            "6/6 [==============================] - 6s 7ms/step - loss: 0.1157\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0914\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0649\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0393\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0164\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0093\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0119\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0108\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0082\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0087\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0082\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0072\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0083\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0082\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0084\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0082\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0089\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0079\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0071\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0080\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0082\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0080\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0072\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0071\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0083\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0079\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0075\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0070\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0070\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0063\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0071\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0074\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0069\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0072\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0072\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0066\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0066\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0073\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0069\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0061\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0064\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0067\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0073\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0063\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0063\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0061\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0069\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0057\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0066\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0062\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0062\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0061\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0066\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0063\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0061\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0065\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0065\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0062\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0067\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0061\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0060\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0064\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0064\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0061\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0065\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0059\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0062\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0063\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0061\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0062\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0060\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0067\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0063\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0065\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0062\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0061\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0063\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0062\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0057\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0063\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0059\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0061\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0059\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0061\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0058\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0059\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0057\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0058\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0057\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0060\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0057\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0057\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0058\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0058\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0057\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0059\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0060\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0058\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0058\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0059\n",
            "147 - DatepartRegression with avg smape 1.58: \n",
            "Model Number: 148 of 155 with model DatepartRegression for Validation 1\n",
            "Epoch 1/50\n",
            "3/3 [==============================] - 7s 15ms/step - loss: 100.8542\n",
            "Epoch 2/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 101.5714\n",
            "Epoch 3/50\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 102.8246\n",
            "Epoch 4/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 102.3360\n",
            "Epoch 5/50\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 100.9102\n",
            "Epoch 6/50\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 102.4110\n",
            "Epoch 7/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 100.4816\n",
            "Epoch 8/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 104.9058\n",
            "Epoch 9/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 101.0341\n",
            "Epoch 10/50\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 101.1287\n",
            "Epoch 11/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 99.8079\n",
            "Epoch 12/50\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 98.3587\n",
            "Epoch 13/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 99.6430\n",
            "Epoch 14/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 102.3678\n",
            "Epoch 15/50\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 101.6817\n",
            "Epoch 16/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 99.4868\n",
            "Epoch 17/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 101.5678\n",
            "Epoch 18/50\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 103.0331\n",
            "Epoch 19/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 102.8119\n",
            "Epoch 20/50\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 100.1181\n",
            "Epoch 21/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 102.4652\n",
            "Epoch 22/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 101.0026\n",
            "Epoch 23/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 100.0614\n",
            "Epoch 24/50\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 99.1560\n",
            "Epoch 25/50\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 99.6943\n",
            "Epoch 26/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 102.2328\n",
            "Epoch 27/50\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 98.5394\n",
            "Epoch 28/50\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 101.5253\n",
            "Epoch 29/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 98.3315\n",
            "Epoch 30/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 103.6526\n",
            "Epoch 31/50\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 99.7364\n",
            "Epoch 32/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 99.0055\n",
            "Epoch 33/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 100.3051\n",
            "Epoch 34/50\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 99.4478\n",
            "Epoch 35/50\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 100.1637\n",
            "Epoch 36/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 99.9875\n",
            "Epoch 37/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 102.5305\n",
            "Epoch 38/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 99.9611\n",
            "Epoch 39/50\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 98.8424\n",
            "Epoch 40/50\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 99.7736\n",
            "Epoch 41/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 99.5631\n",
            "Epoch 42/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 99.9806\n",
            "Epoch 43/50\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 100.9240\n",
            "Epoch 44/50\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 98.8828\n",
            "Epoch 45/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 99.5601\n",
            "Epoch 46/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 102.1435\n",
            "Epoch 47/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 99.2227\n",
            "Epoch 48/50\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 99.2887\n",
            "Epoch 49/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 99.5714\n",
            "Epoch 50/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 99.3833\n",
            "148 - DatepartRegression with avg smape 1.8: \n",
            "Model Number: 149 of 155 with model DatepartRegression for Validation 1\n",
            "149 - DatepartRegression with avg smape 2.15: \n",
            "Model Number: 150 of 155 with model GLM for Validation 1\n",
            "150 - GLM with avg smape 2.23: \n",
            "Model Number: 151 of 155 with model DatepartRegression for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "151 - DatepartRegression with avg smape 2.38: \n",
            "Model Number: 152 of 155 with model DatepartRegression for Validation 1\n",
            "152 - DatepartRegression with avg smape 5.06: \n",
            "Model Number: 153 of 155 with model MultivariateRegression for Validation 1\n",
            "153 - MultivariateRegression with avg smape 5.07: \n",
            "Model Number: 154 of 155 with model GLM for Validation 1\n",
            "154 - GLM with avg smape 6.54: \n",
            "Model Number: 155 of 155 with model GLM for Validation 1\n",
            "155 - GLM with avg smape 42.17: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/genmod/families/family.py:1440: RuntimeWarning: invalid value encountered in log\n",
            "  endog * np.log(endog / mu) + (mu - endog))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Round: 2\n",
            "Model Number: 1 of 155 with model Ensemble for Validation 2\n",
            "📈 1 - Ensemble with avg smape 2.82: \n",
            "Model Number: 2 of 155 with model SectionalMotif for Validation 2\n",
            "2 - SectionalMotif with avg smape 5.25: \n",
            "Model Number: 3 of 155 with model LastValueNaive for Validation 2\n",
            "3 - LastValueNaive with avg smape 5.25: \n",
            "Model Number: 4 of 155 with model UnivariateMotif for Validation 2\n",
            "4 - UnivariateMotif with avg smape 5.25: \n",
            "Model Number: 5 of 155 with model UnivariateMotif for Validation 2\n",
            "5 - UnivariateMotif with avg smape 5.25: \n",
            "Model Number: 6 of 155 with model AverageValueNaive for Validation 2\n",
            "6 - AverageValueNaive with avg smape 5.25: \n",
            "Model Number: 7 of 155 with model ConstantNaive for Validation 2\n",
            "7 - ConstantNaive with avg smape 5.25: \n",
            "Model Number: 8 of 155 with model Ensemble for Validation 2\n",
            "8 - Ensemble with avg smape 5.25: \n",
            "Model Number: 9 of 155 with model UnivariateMotif for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9 - UnivariateMotif with avg smape 5.25: \n",
            "Model Number: 10 of 155 with model UnivariateRegression for Validation 2\n",
            "10 - UnivariateRegression with avg smape 5.25: \n",
            "Model Number: 11 of 155 with model SeasonalNaive for Validation 2\n",
            "11 - SeasonalNaive with avg smape 5.25: \n",
            "Model Number: 12 of 155 with model Ensemble for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12 - Ensemble with avg smape 5.25: \n",
            "Model Number: 13 of 155 with model Ensemble for Validation 2\n",
            "13 - Ensemble with avg smape 5.25: \n",
            "Model Number: 14 of 155 with model Ensemble for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14 - Ensemble with avg smape 5.25: \n",
            "Model Number: 15 of 155 with model SectionalMotif for Validation 2\n",
            "15 - SectionalMotif with avg smape 5.25: \n",
            "Model Number: 16 of 155 with model AverageValueNaive for Validation 2\n",
            "16 - AverageValueNaive with avg smape 5.25: \n",
            "Model Number: 17 of 155 with model UnivariateMotif for Validation 2\n",
            "17 - UnivariateMotif with avg smape 3.31: \n",
            "Model Number: 18 of 155 with model UnivariateMotif for Validation 2\n",
            "18 - UnivariateMotif with avg smape 5.24: \n",
            "Model Number: 19 of 155 with model LastValueNaive for Validation 2\n",
            "19 - LastValueNaive with avg smape 5.35: \n",
            "Model Number: 20 of 155 with model ETS for Validation 2\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "20 - ETS with avg smape 5.35: \n",
            "Model Number: 21 of 155 with model SectionalMotif for Validation 2\n",
            "21 - SectionalMotif with avg smape 5.35: \n",
            "Model Number: 22 of 155 with model LastValueNaive for Validation 2\n",
            "22 - LastValueNaive with avg smape 5.35: \n",
            "Model Number: 23 of 155 with model LastValueNaive for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23 - LastValueNaive with avg smape 5.35: \n",
            "Model Number: 24 of 155 with model LastValueNaive for Validation 2\n",
            "24 - LastValueNaive with avg smape 5.35: \n",
            "Model Number: 25 of 155 with model SectionalMotif for Validation 2\n",
            "25 - SectionalMotif with avg smape 5.36: \n",
            "Model Number: 26 of 155 with model SectionalMotif for Validation 2\n",
            "26 - SectionalMotif with avg smape 5.36: \n",
            "Model Number: 27 of 155 with model SectionalMotif for Validation 2\n",
            "27 - SectionalMotif with avg smape 5.36: \n",
            "Model Number: 28 of 155 with model SectionalMotif for Validation 2\n",
            "28 - SectionalMotif with avg smape 5.38: \n",
            "Model Number: 29 of 155 with model WindowRegression for Validation 2\n",
            "[LibLinear]29 - WindowRegression with avg smape 5.38: \n",
            "Model Number: 30 of 155 with model SectionalMotif for Validation 2\n",
            "30 - SectionalMotif with avg smape 5.38: \n",
            "Model Number: 31 of 155 with model LastValueNaive for Validation 2\n",
            "31 - LastValueNaive with avg smape 5.38: \n",
            "Model Number: 32 of 155 with model SectionalMotif for Validation 2\n",
            "32 - SectionalMotif with avg smape 5.38: \n",
            "Model Number: 33 of 155 with model NVAR for Validation 2\n",
            "33 - NVAR with avg smape 5.38: \n",
            "Model Number: 34 of 155 with model LastValueNaive for Validation 2\n",
            "34 - LastValueNaive with avg smape 5.38: \n",
            "Model Number: 35 of 155 with model ConstantNaive for Validation 2\n",
            "35 - ConstantNaive with avg smape 5.38: \n",
            "Model Number: 36 of 155 with model FBProphet for Validation 2\n",
            "36 - FBProphet with avg smape 5.21: \n",
            "Model Number: 37 of 155 with model LastValueNaive for Validation 2\n",
            "37 - LastValueNaive with avg smape 5.21: \n",
            "Model Number: 38 of 155 with model UnivariateRegression for Validation 2\n",
            "38 - UnivariateRegression with avg smape 5.21: \n",
            "Model Number: 39 of 155 with model UnivariateMotif for Validation 2\n",
            "39 - UnivariateMotif with avg smape 5.21: \n",
            "Model Number: 40 of 155 with model ETS for Validation 2\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "40 - ETS with avg smape 5.21: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 41 of 155 with model ETS for Validation 2\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "41 - ETS with avg smape 5.21: \n",
            "Model Number: 42 of 155 with model LastValueNaive for Validation 2\n",
            "42 - LastValueNaive with avg smape 5.41: \n",
            "Model Number: 43 of 155 with model AverageValueNaive for Validation 2\n",
            "43 - AverageValueNaive with avg smape 4.51: \n",
            "Model Number: 44 of 155 with model Ensemble for Validation 2\n",
            "📈 44 - Ensemble with avg smape 2.02: \n",
            "Model Number: 45 of 155 with model UnivariateMotif for Validation 2\n",
            "45 - UnivariateMotif with avg smape 2.44: \n",
            "Model Number: 46 of 155 with model UnivariateMotif for Validation 2\n",
            "46 - UnivariateMotif with avg smape 2.02: \n",
            "Model Number: 47 of 155 with model WindowRegression for Validation 2\n",
            "47 - WindowRegression with avg smape 2.3: \n",
            "Model Number: 48 of 155 with model UnivariateMotif for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📈 48 - UnivariateMotif with avg smape 1.83: \n",
            "Model Number: 49 of 155 with model Ensemble for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "49 - Ensemble with avg smape 2.35: \n",
            "Model Number: 50 of 155 with model Ensemble for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50 - Ensemble with avg smape 2.76: \n",
            "Model Number: 51 of 155 with model ConstantNaive for Validation 2\n",
            "51 - ConstantNaive with avg smape 5.17: \n",
            "Model Number: 52 of 155 with model UnivariateRegression for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52 - UnivariateRegression with avg smape 4.5: \n",
            "Model Number: 53 of 155 with model UnivariateRegression for Validation 2\n",
            "53 - UnivariateRegression with avg smape 4.5: \n",
            "Model Number: 54 of 155 with model NVAR for Validation 2\n",
            "54 - NVAR with avg smape 2.79: \n",
            "Model Number: 55 of 155 with model AverageValueNaive for Validation 2\n",
            "55 - AverageValueNaive with avg smape 4.1: \n",
            "Model Number: 56 of 155 with model WindowRegression for Validation 2\n",
            "56 - WindowRegression with avg smape 2.16: \n",
            "Model Number: 57 of 155 with model NVAR for Validation 2\n",
            "57 - NVAR with avg smape 2.69: \n",
            "Model Number: 58 of 155 with model NVAR for Validation 2\n",
            "58 - NVAR with avg smape 4.15: \n",
            "Model Number: 59 of 155 with model FBProphet for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:28:13 - cmdstanpy - INFO - Chain [1] start processing\n",
            "05:28:13 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59 - FBProphet with avg smape 3.4: \n",
            "Model Number: 60 of 155 with model NVAR for Validation 2\n",
            "60 - NVAR with avg smape 3.58: \n",
            "Model Number: 61 of 155 with model UnivariateRegression for Validation 2\n",
            "61 - UnivariateRegression with avg smape 2.78: \n",
            "Model Number: 62 of 155 with model WindowRegression for Validation 2\n",
            "📈 62 - WindowRegression with avg smape 1.58: \n",
            "Model Number: 63 of 155 with model UnivariateRegression for Validation 2\n",
            "63 - UnivariateRegression with avg smape 3.02: \n",
            "Model Number: 64 of 155 with model UnivariateRegression for Validation 2\n",
            "64 - UnivariateRegression with avg smape 2.51: \n",
            "Model Number: 65 of 155 with model AverageValueNaive for Validation 2\n",
            "65 - AverageValueNaive with avg smape 1.7: \n",
            "Model Number: 66 of 155 with model WindowRegression for Validation 2\n",
            "66 - WindowRegression with avg smape 4.19: \n",
            "Model Number: 67 of 155 with model UnivariateRegression for Validation 2\n",
            "67 - UnivariateRegression with avg smape 4.24: \n",
            "Model Number: 68 of 155 with model UnivariateRegression for Validation 2\n",
            "68 - UnivariateRegression with avg smape 4.24: \n",
            "Model Number: 69 of 155 with model AverageValueNaive for Validation 2\n",
            "📈 69 - AverageValueNaive with avg smape 1.42: \n",
            "Model Number: 70 of 155 with model GLS for Validation 2\n",
            "70 - GLS with avg smape 3.68: \n",
            "Model Number: 71 of 155 with model ConstantNaive for Validation 2\n",
            "71 - ConstantNaive with avg smape 1.52: \n",
            "Model Number: 72 of 155 with model ConstantNaive for Validation 2\n",
            "72 - ConstantNaive with avg smape 1.52: \n",
            "Model Number: 73 of 155 with model WindowRegression for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73 - WindowRegression with avg smape 4.53: \n",
            "Model Number: 74 of 155 with model NVAR for Validation 2\n",
            "74 - NVAR with avg smape 4.16: \n",
            "Model Number: 75 of 155 with model UnobservedComponents for Validation 2\n",
            "75 - UnobservedComponents with avg smape 3.72: \n",
            "Model Number: 76 of 155 with model WindowRegression for Validation 2\n",
            "76 - WindowRegression with avg smape 3.61: \n",
            "Model Number: 77 of 155 with model ConstantNaive for Validation 2\n",
            "77 - ConstantNaive with avg smape 3.13: \n",
            "Model Number: 78 of 155 with model FBProphet for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "05:28:16 - cmdstanpy - INFO - Chain [1] start processing\n",
            "05:28:16 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "78 - FBProphet with avg smape 4.85: \n",
            "Model Number: 79 of 155 with model ConstantNaive for Validation 2\n",
            "79 - ConstantNaive with avg smape 3.12: \n",
            "Model Number: 80 of 155 with model ConstantNaive for Validation 2\n",
            "80 - ConstantNaive with avg smape 3.68: \n",
            "Model Number: 81 of 155 with model UnobservedComponents for Validation 2\n",
            "81 - UnobservedComponents with avg smape 4.07: \n",
            "Model Number: 82 of 155 with model GLS for Validation 2\n",
            "82 - GLS with avg smape 3.61: \n",
            "Model Number: 83 of 155 with model AverageValueNaive for Validation 2\n",
            "83 - AverageValueNaive with avg smape 2.94: \n",
            "Model Number: 84 of 155 with model WindowRegression for Validation 2\n",
            "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]84 - WindowRegression with avg smape 4.98: \n",
            "Model Number: 85 of 155 with model ETS for Validation 2\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "85 - ETS with avg smape 3.47: \n",
            "Model Number: 86 of 155 with model ETS for Validation 2\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "86 - ETS with avg smape 3.47: \n",
            "Model Number: 87 of 155 with model ConstantNaive for Validation 2\n",
            "87 - ConstantNaive with avg smape 1.53: \n",
            "Model Number: 88 of 155 with model FBProphet for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:28:18 - cmdstanpy - INFO - Chain [1] start processing\n",
            "05:28:18 - cmdstanpy - INFO - Chain [1] done processing\n",
            "05:28:20 - cmdstanpy - INFO - Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "88 - FBProphet with avg smape 3.57: \n",
            "Model Number: 89 of 155 with model FBProphet for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:28:20 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "89 - FBProphet with avg smape 3.46: \n",
            "Model Number: 90 of 155 with model SeasonalNaive for Validation 2\n",
            "90 - SeasonalNaive with avg smape 2.77: \n",
            "Model Number: 91 of 155 with model AverageValueNaive for Validation 2\n",
            "91 - AverageValueNaive with avg smape 3.47: \n",
            "Model Number: 92 of 155 with model AverageValueNaive for Validation 2\n",
            "92 - AverageValueNaive with avg smape 2.91: \n",
            "Model Number: 93 of 155 with model UnobservedComponents for Validation 2\n",
            "93 - UnobservedComponents with avg smape 3.68: \n",
            "Model Number: 94 of 155 with model FBProphet for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:331: RuntimeWarning: divide by zero encountered in power\n",
            "  + np.power(y_pred, 2 - p) / (2 - p)\n",
            "05:28:22 - cmdstanpy - INFO - Chain [1] start processing\n",
            "05:28:22 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94 - FBProphet with avg smape 3.64: \n",
            "Model Number: 95 of 155 with model WindowRegression for Validation 2\n",
            "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]95 - WindowRegression with avg smape 4.37: \n",
            "Model Number: 96 of 155 with model MultivariateMotif for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "96 - MultivariateMotif with avg smape 2.25: \n",
            "Model Number: 97 of 155 with model ETS for Validation 2\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "97 - ETS with avg smape 3.41: \n",
            "Model Number: 98 of 155 with model GLS for Validation 2\n",
            "98 - GLS with avg smape 3.83: \n",
            "Model Number: 99 of 155 with model GLS for Validation 2\n",
            "99 - GLS with avg smape 3.72: \n",
            "Model Number: 100 of 155 with model UnobservedComponents for Validation 2\n",
            "100 - UnobservedComponents with avg smape 3.84: \n",
            "Model Number: 101 of 155 with model NVAR for Validation 2\n",
            "101 - NVAR with avg smape 3.1: \n",
            "Model Number: 102 of 155 with model MultivariateMotif for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "102 - MultivariateMotif with avg smape 2.52: \n",
            "Model Number: 103 of 155 with model NVAR for Validation 2\n",
            "103 - NVAR with avg smape 4.3: \n",
            "Model Number: 104 of 155 with model SeasonalNaive for Validation 2\n",
            "104 - SeasonalNaive with avg smape 4.99: \n",
            "Model Number: 105 of 155 with model SeasonalNaive for Validation 2\n",
            "105 - SeasonalNaive with avg smape 4.97: \n",
            "Model Number: 106 of 155 with model SeasonalNaive for Validation 2\n",
            "106 - SeasonalNaive with avg smape 5.51: \n",
            "Model Number: 107 of 155 with model ETS for Validation 2\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "107 - ETS with avg smape 3.37: \n",
            "Model Number: 108 of 155 with model ETS for Validation 2\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "108 - ETS with avg smape 3.77: \n",
            "Model Number: 109 of 155 with model MultivariateMotif for Validation 2\n",
            "109 - MultivariateMotif with avg smape 3.68: \n",
            "Model Number: 110 of 155 with model GLS for Validation 2\n",
            "110 - GLS with avg smape 3.83: \n",
            "Model Number: 111 of 155 with model ETS for Validation 2\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "111 - ETS with avg smape 4.02: \n",
            "Model Number: 112 of 155 with model SeasonalNaive for Validation 2\n",
            "112 - SeasonalNaive with avg smape 3.81: \n",
            "Model Number: 113 of 155 with model NVAR for Validation 2\n",
            "113 - NVAR with avg smape 2.58: \n",
            "Model Number: 114 of 155 with model GLS for Validation 2\n",
            "114 - GLS with avg smape 3.87: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "05:28:25 - cmdstanpy - INFO - Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 115 of 155 with model FBProphet for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:28:26 - cmdstanpy - INFO - Chain [1] done processing\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: divide by zero encountered in log\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: invalid value encountered in add\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
            "05:28:27 - cmdstanpy - INFO - Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "115 - FBProphet with avg smape 4.27: \n",
            "Model Number: 116 of 155 with model FBProphet for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:28:27 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📈 116 - FBProphet with avg smape 0.71: \n",
            "Model Number: 117 of 155 with model UnobservedComponents for Validation 2\n",
            "117 - UnobservedComponents with avg smape 1.89: \n",
            "Model Number: 118 of 155 with model SeasonalNaive for Validation 2\n",
            "118 - SeasonalNaive with avg smape 3.89: \n",
            "Model Number: 119 of 155 with model SeasonalNaive for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "119 - SeasonalNaive with avg smape 3.33: \n",
            "Model Number: 120 of 155 with model UnobservedComponents for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:28:29 - cmdstanpy - INFO - Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "120 - UnobservedComponents with avg smape 3.71: \n",
            "Model Number: 121 of 155 with model FBProphet for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:28:29 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "121 - FBProphet with avg smape 2.17: \n",
            "Model Number: 122 of 155 with model UnobservedComponents for Validation 2\n",
            "122 - UnobservedComponents with avg smape 3.71: \n",
            "Model Number: 123 of 155 with model GLS for Validation 2\n",
            "123 - GLS with avg smape 3.92: \n",
            "Model Number: 124 of 155 with model UnobservedComponents for Validation 2\n",
            "124 - UnobservedComponents with avg smape 3.94: \n",
            "Model Number: 125 of 155 with model SeasonalNaive for Validation 2\n",
            "125 - SeasonalNaive with avg smape 3.76: \n",
            "Model Number: 126 of 155 with model MultivariateMotif for Validation 2\n",
            "126 - MultivariateMotif with avg smape 3.72: \n",
            "Model Number: 127 of 155 with model MultivariateMotif for Validation 2\n",
            "127 - MultivariateMotif with avg smape 3.9: \n",
            "Model Number: 128 of 155 with model GLS for Validation 2\n",
            "128 - GLS with avg smape 3.6: \n",
            "Model Number: 129 of 155 with model GLS for Validation 2\n",
            "129 - GLS with avg smape 3.94: \n",
            "Model Number: 130 of 155 with model UnobservedComponents for Validation 2\n",
            "130 - UnobservedComponents with avg smape 4.2: \n",
            "Model Number: 131 of 155 with model MultivariateMotif for Validation 2\n",
            "131 - MultivariateMotif with avg smape 3.78: \n",
            "Model Number: 132 of 155 with model MultivariateMotif for Validation 2\n",
            "132 - MultivariateMotif with avg smape 4.25: \n",
            "Model Number: 133 of 155 with model MultivariateMotif for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "133 - MultivariateMotif with avg smape 4.41: \n",
            "Model Number: 134 of 155 with model MultivariateRegression for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.3s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "134 - MultivariateRegression with avg smape 4.3: \n",
            "Model Number: 135 of 155 with model MultivariateRegression for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 300 out of 300 | elapsed:    0.4s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "135 - MultivariateRegression with avg smape 2.71: \n",
            "Model Number: 136 of 155 with model MultivariateRegression for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "136 - MultivariateRegression with avg smape 4.61: \n",
            "Model Number: 137 of 155 with model MultivariateMotif for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.3s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "137 - MultivariateMotif with avg smape 2.78: \n",
            "Model Number: 138 of 155 with model MultivariateRegression for Validation 2\n",
            "138 - MultivariateRegression with avg smape 2.55: \n",
            "Model Number: 139 of 155 with model MultivariateRegression for Validation 2\n",
            "139 - MultivariateRegression with avg smape 3.64: \n",
            "Model Number: 140 of 155 with model MultivariateRegression for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.3s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "140 - MultivariateRegression with avg smape 3.01: \n",
            "Model Number: 141 of 155 with model DatepartRegression for Validation 2\n",
            "141 - DatepartRegression with avg smape 3.46: \n",
            "Model Number: 142 of 155 with model DatepartRegression for Validation 2\n",
            "Epoch 1/200\n",
            "6/6 [==============================] - 6s 29ms/step - loss: 0.1683\n",
            "Epoch 2/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1628\n",
            "Epoch 3/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1654\n",
            "Epoch 4/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1623\n",
            "Epoch 5/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1625\n",
            "Epoch 6/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1603\n",
            "Epoch 7/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1613\n",
            "Epoch 8/200\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.1633\n",
            "Epoch 9/200\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.1613\n",
            "Epoch 10/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1631\n",
            "Epoch 11/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1595\n",
            "Epoch 12/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1619\n",
            "Epoch 13/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1612\n",
            "Epoch 14/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1612\n",
            "Epoch 15/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1599\n",
            "Epoch 16/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1626\n",
            "Epoch 17/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1610\n",
            "Epoch 18/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1643\n",
            "Epoch 19/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1617\n",
            "Epoch 20/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1604\n",
            "Epoch 21/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1614\n",
            "Epoch 22/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1603\n",
            "Epoch 23/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1605\n",
            "Epoch 24/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1620\n",
            "Epoch 25/200\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.1602\n",
            "Epoch 26/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1609\n",
            "Epoch 27/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1615\n",
            "Epoch 28/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1603\n",
            "Epoch 29/200\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.1620\n",
            "Epoch 30/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1610\n",
            "Epoch 31/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1607\n",
            "Epoch 32/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1616\n",
            "Epoch 33/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1612\n",
            "Epoch 34/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1606\n",
            "Epoch 35/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1612\n",
            "Epoch 36/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1616\n",
            "Epoch 37/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1615\n",
            "Epoch 38/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1625\n",
            "Epoch 39/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1608\n",
            "Epoch 40/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1609\n",
            "Epoch 41/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1619\n",
            "Epoch 42/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1628\n",
            "Epoch 43/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1606\n",
            "Epoch 44/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1607\n",
            "Epoch 45/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1612\n",
            "Epoch 46/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1607\n",
            "Epoch 47/200\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.1605\n",
            "Epoch 48/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1617\n",
            "Epoch 49/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1602\n",
            "Epoch 50/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1602\n",
            "Epoch 51/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1608\n",
            "Epoch 52/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1619\n",
            "Epoch 53/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1618\n",
            "Epoch 54/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1609\n",
            "Epoch 55/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1607\n",
            "Epoch 56/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1607\n",
            "Epoch 57/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1601\n",
            "Epoch 58/200\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.1597\n",
            "Epoch 59/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1609\n",
            "Epoch 60/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1607\n",
            "Epoch 61/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1598\n",
            "Epoch 62/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1605\n",
            "Epoch 63/200\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.1598\n",
            "Epoch 64/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1606\n",
            "Epoch 65/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1599\n",
            "Epoch 66/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1601\n",
            "Epoch 67/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1613\n",
            "Epoch 68/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1608\n",
            "Epoch 69/200\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.1604\n",
            "Epoch 70/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1600\n",
            "Epoch 71/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1602\n",
            "Epoch 72/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1612\n",
            "Epoch 73/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1604\n",
            "Epoch 74/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1611\n",
            "Epoch 75/200\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.1611\n",
            "Epoch 76/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1605\n",
            "Epoch 77/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1611\n",
            "Epoch 78/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1616\n",
            "Epoch 79/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1603\n",
            "Epoch 80/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1608\n",
            "Epoch 81/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1601\n",
            "Epoch 82/200\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.1602\n",
            "Epoch 83/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1620\n",
            "Epoch 84/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1606\n",
            "Epoch 85/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1610\n",
            "Epoch 86/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1606\n",
            "Epoch 87/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1609\n",
            "Epoch 88/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1620\n",
            "Epoch 89/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1614\n",
            "Epoch 90/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1598\n",
            "Epoch 91/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1605\n",
            "Epoch 92/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1604\n",
            "Epoch 93/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1607\n",
            "Epoch 94/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1594\n",
            "Epoch 95/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1605\n",
            "Epoch 96/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1606\n",
            "Epoch 97/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1604\n",
            "Epoch 98/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1597\n",
            "Epoch 99/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1619\n",
            "Epoch 100/200\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.1602\n",
            "Epoch 101/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1616\n",
            "Epoch 102/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1598\n",
            "Epoch 103/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1614\n",
            "Epoch 104/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1611\n",
            "Epoch 105/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1617\n",
            "Epoch 106/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1606\n",
            "Epoch 107/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1620\n",
            "Epoch 108/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1610\n",
            "Epoch 109/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1606\n",
            "Epoch 110/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1613\n",
            "Epoch 111/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1597\n",
            "Epoch 112/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1605\n",
            "Epoch 113/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1604\n",
            "Epoch 114/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1602\n",
            "Epoch 115/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1610\n",
            "Epoch 116/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1624\n",
            "Epoch 117/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1611\n",
            "Epoch 118/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1601\n",
            "Epoch 119/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1610\n",
            "Epoch 120/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1609\n",
            "Epoch 121/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1598\n",
            "Epoch 122/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1603\n",
            "Epoch 123/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1608\n",
            "Epoch 124/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1610\n",
            "Epoch 125/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1606\n",
            "Epoch 126/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1603\n",
            "Epoch 127/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1599\n",
            "Epoch 128/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1614\n",
            "Epoch 129/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1602\n",
            "Epoch 130/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1609\n",
            "Epoch 131/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1607\n",
            "Epoch 132/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1602\n",
            "Epoch 133/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1609\n",
            "Epoch 134/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1605\n",
            "Epoch 135/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1605\n",
            "Epoch 136/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1595\n",
            "Epoch 137/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1607\n",
            "Epoch 138/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1603\n",
            "Epoch 139/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1600\n",
            "Epoch 140/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1608\n",
            "Epoch 141/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1601\n",
            "Epoch 142/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1608\n",
            "Epoch 143/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1600\n",
            "Epoch 144/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1606\n",
            "Epoch 145/200\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.1610\n",
            "Epoch 146/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1595\n",
            "Epoch 147/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1611\n",
            "Epoch 148/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1600\n",
            "Epoch 149/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1615\n",
            "Epoch 150/200\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.1614\n",
            "Epoch 151/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1618\n",
            "Epoch 152/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1600\n",
            "Epoch 153/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1614\n",
            "Epoch 154/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1605\n",
            "Epoch 155/200\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.1606\n",
            "Epoch 156/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1603\n",
            "Epoch 157/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1607\n",
            "Epoch 158/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1601\n",
            "Epoch 159/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1614\n",
            "Epoch 160/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1598\n",
            "Epoch 161/200\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.1599\n",
            "Epoch 162/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1597\n",
            "Epoch 163/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1599\n",
            "Epoch 164/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1610\n",
            "Epoch 165/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1601\n",
            "Epoch 166/200\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.1602\n",
            "Epoch 167/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1614\n",
            "Epoch 168/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1606\n",
            "Epoch 169/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1605\n",
            "Epoch 170/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1610\n",
            "Epoch 171/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1601\n",
            "Epoch 172/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1607\n",
            "Epoch 173/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1602\n",
            "Epoch 174/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1616\n",
            "Epoch 175/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1605\n",
            "Epoch 176/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1598\n",
            "Epoch 177/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1600\n",
            "Epoch 178/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1602\n",
            "Epoch 179/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1612\n",
            "Epoch 180/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1594\n",
            "Epoch 181/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1609\n",
            "Epoch 182/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1591\n",
            "Epoch 183/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1607\n",
            "Epoch 184/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1599\n",
            "Epoch 185/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1622\n",
            "Epoch 186/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1608\n",
            "Epoch 187/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1610\n",
            "Epoch 188/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1606\n",
            "Epoch 189/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1610\n",
            "Epoch 190/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1605\n",
            "Epoch 191/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1612\n",
            "Epoch 192/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1604\n",
            "Epoch 193/200\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 0.1593\n",
            "Epoch 194/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1606\n",
            "Epoch 195/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1602\n",
            "Epoch 196/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1609\n",
            "Epoch 197/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1600\n",
            "Epoch 198/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1604\n",
            "Epoch 199/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1603\n",
            "Epoch 200/200\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 0.1600\n",
            "142 - DatepartRegression with avg smape 1.47: \n",
            "Model Number: 143 of 155 with model MultivariateRegression for Validation 2\n",
            "143 - MultivariateRegression with avg smape 4.75: \n",
            "Model Number: 144 of 155 with model DatepartRegression for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "144 - DatepartRegression with avg smape 6.76: \n",
            "Model Number: 145 of 155 with model DatepartRegression for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "145 - DatepartRegression with avg smape 3.5: \n",
            "Model Number: 146 of 155 with model MultivariateRegression for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.3s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "146 - MultivariateRegression with avg smape 3.68: \n",
            "Model Number: 147 of 155 with model DatepartRegression for Validation 2\n",
            "Epoch 1/100\n",
            "6/6 [==============================] - 6s 8ms/step - loss: 0.1161\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0920\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0652\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0406\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0170\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0100\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0115\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0100\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0093\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0084\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0088\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0081\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0071\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0075\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0077\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0075\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0073\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0071\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0070\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0076\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0075\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0072\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0078\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0066\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0070\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0085\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0079\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0086\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0075\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0064\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0077\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0075\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0067\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0074\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0073\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0073\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0068\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0065\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0064\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0067\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0073\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0072\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0067\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0067\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0070\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0066\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0063\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0066\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0069\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0061\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0060\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0068\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0069\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0067\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0063\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0061\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0063\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0059\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0065\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0063\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0064\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0065\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0063\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0063\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0057\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0065\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0059\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0063\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0065\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0063\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0059\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0058\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0062\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0059\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0062\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0058\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0062\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0062\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0062\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0061\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0058\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0056\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0058\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0059\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0056\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0057\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0059\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0063\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0065\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0060\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0061\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0059\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0056\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0058\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0060\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0059\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0056\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0058\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0058\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0058\n",
            "147 - DatepartRegression with avg smape 1.32: \n",
            "Model Number: 148 of 155 with model DatepartRegression for Validation 2\n",
            "Epoch 1/50\n",
            "3/3 [==============================] - 6s 16ms/step - loss: 113.5226\n",
            "Epoch 2/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 104.5488\n",
            "Epoch 3/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 98.8757\n",
            "Epoch 4/50\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 104.1779\n",
            "Epoch 5/50\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 101.2769\n",
            "Epoch 6/50\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 103.8946\n",
            "Epoch 7/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 102.8406\n",
            "Epoch 8/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 102.4263\n",
            "Epoch 9/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 103.6857\n",
            "Epoch 10/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 102.6764\n",
            "Epoch 11/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 102.1259\n",
            "Epoch 12/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 101.5790\n",
            "Epoch 13/50\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 97.7488\n",
            "Epoch 14/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 102.4770\n",
            "Epoch 15/50\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 103.1983\n",
            "Epoch 16/50\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 99.3142\n",
            "Epoch 17/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 101.9587\n",
            "Epoch 18/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 103.2215\n",
            "Epoch 19/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 100.6303\n",
            "Epoch 20/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 101.5946\n",
            "Epoch 21/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 99.6086\n",
            "Epoch 22/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 104.3753\n",
            "Epoch 23/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 99.4459\n",
            "Epoch 24/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 105.0513\n",
            "Epoch 25/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 101.1699\n",
            "Epoch 26/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 99.5983\n",
            "Epoch 27/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 100.3623\n",
            "Epoch 28/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 102.6434\n",
            "Epoch 29/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 99.8280\n",
            "Epoch 30/50\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 102.6318\n",
            "Epoch 31/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 101.4565\n",
            "Epoch 32/50\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 103.0986\n",
            "Epoch 33/50\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 100.6010\n",
            "Epoch 34/50\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 98.4818\n",
            "Epoch 35/50\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 101.8763\n",
            "Epoch 36/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 99.2883\n",
            "Epoch 37/50\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 102.4298\n",
            "Epoch 38/50\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 101.0079\n",
            "Epoch 39/50\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 98.4861\n",
            "Epoch 40/50\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 100.6397\n",
            "Epoch 41/50\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 101.5882\n",
            "Epoch 42/50\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 99.5285\n",
            "Epoch 43/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 98.7506\n",
            "Epoch 44/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 101.8716\n",
            "Epoch 45/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 99.9680\n",
            "Epoch 46/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 101.7028\n",
            "Epoch 47/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 100.8638\n",
            "Epoch 48/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 100.5517\n",
            "Epoch 49/50\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 99.2961\n",
            "Epoch 50/50\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 99.0929\n",
            "148 - DatepartRegression with avg smape 1.49: \n",
            "Model Number: 149 of 155 with model DatepartRegression for Validation 2\n",
            "149 - DatepartRegression with avg smape 1.15: \n",
            "Model Number: 150 of 155 with model GLM for Validation 2\n",
            "150 - GLM with avg smape 1.13: \n",
            "Model Number: 151 of 155 with model DatepartRegression for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "151 - DatepartRegression with avg smape 3.13: \n",
            "Model Number: 152 of 155 with model DatepartRegression for Validation 2\n",
            "152 - DatepartRegression with avg smape 4.52: \n",
            "Model Number: 153 of 155 with model MultivariateRegression for Validation 2\n",
            "153 - MultivariateRegression with avg smape 2.96: \n",
            "Model Number: 154 of 155 with model GLM for Validation 2\n",
            "154 - GLM with avg smape 4.09: \n",
            "Model Number: 155 of 155 with model GLM for Validation 2\n",
            "155 - GLM with avg smape 40.27: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/genmod/families/family.py:1440: RuntimeWarning: invalid value encountered in log\n",
            "  endog * np.log(endog / mu) + (mu - endog))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Round: 3\n",
            "Model Number: 1 of 155 with model Ensemble for Validation 3\n",
            "📈 1 - Ensemble with avg smape 5.15: \n",
            "Model Number: 2 of 155 with model SectionalMotif for Validation 3\n",
            "2 - SectionalMotif with avg smape 8.31: \n",
            "Model Number: 3 of 155 with model LastValueNaive for Validation 3\n",
            "3 - LastValueNaive with avg smape 8.31: \n",
            "Model Number: 4 of 155 with model UnivariateMotif for Validation 3\n",
            "4 - UnivariateMotif with avg smape 8.31: \n",
            "Model Number: 5 of 155 with model UnivariateMotif for Validation 3\n",
            "5 - UnivariateMotif with avg smape 8.31: \n",
            "Model Number: 6 of 155 with model AverageValueNaive for Validation 3\n",
            "6 - AverageValueNaive with avg smape 8.31: \n",
            "Model Number: 7 of 155 with model ConstantNaive for Validation 3\n",
            "7 - ConstantNaive with avg smape 8.31: \n",
            "Model Number: 8 of 155 with model Ensemble for Validation 3\n",
            "8 - Ensemble with avg smape 8.31: \n",
            "Model Number: 9 of 155 with model UnivariateMotif for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9 - UnivariateMotif with avg smape 8.31: \n",
            "Model Number: 10 of 155 with model UnivariateRegression for Validation 3\n",
            "10 - UnivariateRegression with avg smape 8.31: \n",
            "Model Number: 11 of 155 with model SeasonalNaive for Validation 3\n",
            "11 - SeasonalNaive with avg smape 8.31: \n",
            "Model Number: 12 of 155 with model Ensemble for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12 - Ensemble with avg smape 8.31: \n",
            "Model Number: 13 of 155 with model Ensemble for Validation 3\n",
            "13 - Ensemble with avg smape 8.31: \n",
            "Model Number: 14 of 155 with model Ensemble for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14 - Ensemble with avg smape 8.31: \n",
            "Model Number: 15 of 155 with model SectionalMotif for Validation 3\n",
            "15 - SectionalMotif with avg smape 8.31: \n",
            "Model Number: 16 of 155 with model AverageValueNaive for Validation 3\n",
            "16 - AverageValueNaive with avg smape 8.31: \n",
            "Model Number: 17 of 155 with model UnivariateMotif for Validation 3\n",
            "📈 17 - UnivariateMotif with avg smape 1.5: \n",
            "Model Number: 18 of 155 with model UnivariateMotif for Validation 3\n",
            "18 - UnivariateMotif with avg smape 8.3: \n",
            "Model Number: 19 of 155 with model LastValueNaive for Validation 3\n",
            "19 - LastValueNaive with avg smape 8.41: \n",
            "Model Number: 20 of 155 with model ETS for Validation 3\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "20 - ETS with avg smape 8.41: \n",
            "Model Number: 21 of 155 with model SectionalMotif for Validation 3\n",
            "21 - SectionalMotif with avg smape 8.41: \n",
            "Model Number: 22 of 155 with model LastValueNaive for Validation 3\n",
            "22 - LastValueNaive with avg smape 8.41: \n",
            "Model Number: 23 of 155 with model LastValueNaive for Validation 3\n",
            "23 - LastValueNaive with avg smape 8.41: \n",
            "Model Number: 24 of 155 with model LastValueNaive for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24 - LastValueNaive with avg smape 8.41: \n",
            "Model Number: 25 of 155 with model SectionalMotif for Validation 3\n",
            "25 - SectionalMotif with avg smape 8.42: \n",
            "Model Number: 26 of 155 with model SectionalMotif for Validation 3\n",
            "26 - SectionalMotif with avg smape 8.42: \n",
            "Model Number: 27 of 155 with model SectionalMotif for Validation 3\n",
            "27 - SectionalMotif with avg smape 8.42: \n",
            "Model Number: 28 of 155 with model SectionalMotif for Validation 3\n",
            "28 - SectionalMotif with avg smape 8.44: \n",
            "Model Number: 29 of 155 with model WindowRegression for Validation 3\n",
            "[LibLinear]29 - WindowRegression with avg smape 8.44: \n",
            "Model Number: 30 of 155 with model SectionalMotif for Validation 3\n",
            "30 - SectionalMotif with avg smape 8.44: \n",
            "Model Number: 31 of 155 with model LastValueNaive for Validation 3\n",
            "31 - LastValueNaive with avg smape 8.44: \n",
            "Model Number: 32 of 155 with model SectionalMotif for Validation 3\n",
            "32 - SectionalMotif with avg smape 8.44: \n",
            "Model Number: 33 of 155 with model NVAR for Validation 3\n",
            "33 - NVAR with avg smape 8.44: \n",
            "Model Number: 34 of 155 with model LastValueNaive for Validation 3\n",
            "34 - LastValueNaive with avg smape 8.44: \n",
            "Model Number: 35 of 155 with model ConstantNaive for Validation 3\n",
            "35 - ConstantNaive with avg smape 8.44: \n",
            "Model Number: 36 of 155 with model FBProphet for Validation 3\n",
            "36 - FBProphet with avg smape 8.25: \n",
            "Model Number: 37 of 155 with model LastValueNaive for Validation 3\n",
            "37 - LastValueNaive with avg smape 8.25: \n",
            "Model Number: 38 of 155 with model UnivariateRegression for Validation 3\n",
            "38 - UnivariateRegression with avg smape 8.25: \n",
            "Model Number: 39 of 155 with model UnivariateMotif for Validation 3\n",
            "39 - UnivariateMotif with avg smape 8.25: \n",
            "Model Number: 40 of 155 with model ETS for Validation 3\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "40 - ETS with avg smape 8.25: \n",
            "Model Number: 41 of 155 with model ETS for Validation 3\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41 - ETS with avg smape 8.25: \n",
            "Model Number: 42 of 155 with model LastValueNaive for Validation 3\n",
            "42 - LastValueNaive with avg smape 8.47: \n",
            "Model Number: 43 of 155 with model AverageValueNaive for Validation 3\n",
            "43 - AverageValueNaive with avg smape 6.58: \n",
            "Model Number: 44 of 155 with model Ensemble for Validation 3\n",
            "44 - Ensemble with avg smape 6.54: \n",
            "Model Number: 45 of 155 with model UnivariateMotif for Validation 3\n",
            "45 - UnivariateMotif with avg smape 1.5: \n",
            "Model Number: 46 of 155 with model UnivariateMotif for Validation 3\n",
            "46 - UnivariateMotif with avg smape 1.51: \n",
            "Model Number: 47 of 155 with model WindowRegression for Validation 3\n",
            "📈 47 - WindowRegression with avg smape 1.12: \n",
            "Model Number: 48 of 155 with model UnivariateMotif for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48 - UnivariateMotif with avg smape 1.5: \n",
            "Model Number: 49 of 155 with model Ensemble for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "49 - Ensemble with avg smape 5.79: \n",
            "Model Number: 50 of 155 with model Ensemble for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50 - Ensemble with avg smape 6.15: \n",
            "Model Number: 51 of 155 with model ConstantNaive for Validation 3\n",
            "51 - ConstantNaive with avg smape 8.25: \n",
            "Model Number: 52 of 155 with model UnivariateRegression for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52 - UnivariateRegression with avg smape 1.5: \n",
            "Model Number: 53 of 155 with model UnivariateRegression for Validation 3\n",
            "53 - UnivariateRegression with avg smape 1.5: \n",
            "Model Number: 54 of 155 with model NVAR for Validation 3\n",
            "📈 54 - NVAR with avg smape 0.7: \n",
            "Model Number: 55 of 155 with model AverageValueNaive for Validation 3\n",
            "55 - AverageValueNaive with avg smape 1.29: \n",
            "Model Number: 56 of 155 with model WindowRegression for Validation 3\n",
            "56 - WindowRegression with avg smape 1.5: \n",
            "Model Number: 57 of 155 with model NVAR for Validation 3\n",
            "57 - NVAR with avg smape 5.31: \n",
            "Model Number: 58 of 155 with model NVAR for Validation 3\n",
            "58 - NVAR with avg smape 0.7: \n",
            "Model Number: 59 of 155 with model FBProphet for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:30:00 - cmdstanpy - INFO - Chain [1] start processing\n",
            "05:30:00 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59 - FBProphet with avg smape 1.08: \n",
            "Model Number: 60 of 155 with model NVAR for Validation 3\n",
            "60 - NVAR with avg smape 1.69: \n",
            "Model Number: 61 of 155 with model UnivariateRegression for Validation 3\n",
            "61 - UnivariateRegression with avg smape 1.02: \n",
            "Model Number: 62 of 155 with model WindowRegression for Validation 3\n",
            "📈 62 - WindowRegression with avg smape 0.52: \n",
            "Model Number: 63 of 155 with model UnivariateRegression for Validation 3\n",
            "63 - UnivariateRegression with avg smape 1.92: \n",
            "Model Number: 64 of 155 with model UnivariateRegression for Validation 3\n",
            "64 - UnivariateRegression with avg smape 1.31: \n",
            "Model Number: 65 of 155 with model AverageValueNaive for Validation 3\n",
            "65 - AverageValueNaive with avg smape 3.07: \n",
            "Model Number: 66 of 155 with model WindowRegression for Validation 3\n",
            "66 - WindowRegression with avg smape 1.82: \n",
            "Model Number: 67 of 155 with model UnivariateRegression for Validation 3\n",
            "67 - UnivariateRegression with avg smape 1.6: \n",
            "Model Number: 68 of 155 with model UnivariateRegression for Validation 3\n",
            "68 - UnivariateRegression with avg smape 1.11: \n",
            "Model Number: 69 of 155 with model AverageValueNaive for Validation 3\n",
            "69 - AverageValueNaive with avg smape 2.95: \n",
            "Model Number: 70 of 155 with model GLS for Validation 3\n",
            "70 - GLS with avg smape 0.99: \n",
            "Model Number: 71 of 155 with model ConstantNaive for Validation 3\n",
            "71 - ConstantNaive with avg smape 2.23: \n",
            "Model Number: 72 of 155 with model ConstantNaive for Validation 3\n",
            "72 - ConstantNaive with avg smape 2.23: \n",
            "Model Number: 73 of 155 with model WindowRegression for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73 - WindowRegression with avg smape 2.55: \n",
            "Model Number: 74 of 155 with model NVAR for Validation 3\n",
            "74 - NVAR with avg smape 0.62: \n",
            "Model Number: 75 of 155 with model UnobservedComponents for Validation 3\n",
            "75 - UnobservedComponents with avg smape 1.03: \n",
            "Model Number: 76 of 155 with model WindowRegression for Validation 3\n",
            "76 - WindowRegression with avg smape 0.59: \n",
            "Model Number: 77 of 155 with model ConstantNaive for Validation 3\n",
            "77 - ConstantNaive with avg smape 2.27: \n",
            "Model Number: 78 of 155 with model FBProphet for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "05:30:03 - cmdstanpy - INFO - Chain [1] start processing\n",
            "05:30:03 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "78 - FBProphet with avg smape 2.33: \n",
            "Model Number: 79 of 155 with model ConstantNaive for Validation 3\n",
            "79 - ConstantNaive with avg smape 2.26: \n",
            "Model Number: 80 of 155 with model ConstantNaive for Validation 3\n",
            "80 - ConstantNaive with avg smape 0.98: \n",
            "Model Number: 81 of 155 with model UnobservedComponents for Validation 3\n",
            "81 - UnobservedComponents with avg smape 0.86: \n",
            "Model Number: 82 of 155 with model GLS for Validation 3\n",
            "82 - GLS with avg smape 1.32: \n",
            "Model Number: 83 of 155 with model AverageValueNaive for Validation 3\n",
            "83 - AverageValueNaive with avg smape 1.12: \n",
            "Model Number: 84 of 155 with model WindowRegression for Validation 3\n",
            "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]84 - WindowRegression with avg smape 2.63: \n",
            "Model Number: 85 of 155 with model ETS for Validation 3\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "85 - ETS with avg smape 2.43: \n",
            "Model Number: 86 of 155 with model ETS for Validation 3\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "86 - ETS with avg smape 2.43: \n",
            "Model Number: 87 of 155 with model ConstantNaive for Validation 3\n",
            "87 - ConstantNaive with avg smape 1.91: \n",
            "Model Number: 88 of 155 with model FBProphet for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:30:06 - cmdstanpy - INFO - Chain [1] start processing\n",
            "05:30:06 - cmdstanpy - INFO - Chain [1] done processing\n",
            "05:30:08 - cmdstanpy - INFO - Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "88 - FBProphet with avg smape 1.3: \n",
            "Model Number: 89 of 155 with model FBProphet for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:30:08 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "89 - FBProphet with avg smape 1.02: \n",
            "Model Number: 90 of 155 with model SeasonalNaive for Validation 3\n",
            "90 - SeasonalNaive with avg smape 1.93: \n",
            "Model Number: 91 of 155 with model AverageValueNaive for Validation 3\n",
            "91 - AverageValueNaive with avg smape 0.74: \n",
            "Model Number: 92 of 155 with model AverageValueNaive for Validation 3\n",
            "92 - AverageValueNaive with avg smape 1.15: \n",
            "Model Number: 93 of 155 with model UnobservedComponents for Validation 3\n",
            "93 - UnobservedComponents with avg smape 0.99: \n",
            "Model Number: 94 of 155 with model FBProphet for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:331: RuntimeWarning: divide by zero encountered in power\n",
            "  + np.power(y_pred, 2 - p) / (2 - p)\n",
            "05:30:10 - cmdstanpy - INFO - Chain [1] start processing\n",
            "05:30:10 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94 - FBProphet with avg smape 1.25: \n",
            "Model Number: 95 of 155 with model WindowRegression for Validation 3\n",
            "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]95 - WindowRegression with avg smape 1.5: \n",
            "Model Number: 96 of 155 with model MultivariateMotif for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "96 - MultivariateMotif with avg smape 1.02: \n",
            "Model Number: 97 of 155 with model ETS for Validation 3\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "97 - ETS with avg smape 2.04: \n",
            "Model Number: 98 of 155 with model GLS for Validation 3\n",
            "98 - GLS with avg smape 0.89: \n",
            "Model Number: 99 of 155 with model GLS for Validation 3\n",
            "99 - GLS with avg smape 0.88: \n",
            "Model Number: 100 of 155 with model UnobservedComponents for Validation 3\n",
            "100 - UnobservedComponents with avg smape 0.86: \n",
            "Model Number: 101 of 155 with model NVAR for Validation 3\n",
            "101 - NVAR with avg smape 0.87: \n",
            "Model Number: 102 of 155 with model MultivariateMotif for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:331: RuntimeWarning: divide by zero encountered in power\n",
            "  + np.power(y_pred, 2 - p) / (2 - p)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "102 - MultivariateMotif with avg smape 1.11: \n",
            "Model Number: 103 of 155 with model NVAR for Validation 3\n",
            "103 - NVAR with avg smape 1.92: \n",
            "Model Number: 104 of 155 with model SeasonalNaive for Validation 3\n",
            "104 - SeasonalNaive with avg smape 8.31: \n",
            "Model Number: 105 of 155 with model SeasonalNaive for Validation 3\n",
            "105 - SeasonalNaive with avg smape 8.22: \n",
            "Model Number: 106 of 155 with model SeasonalNaive for Validation 3\n",
            "106 - SeasonalNaive with avg smape 8.8: \n",
            "Model Number: 107 of 155 with model ETS for Validation 3\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "107 - ETS with avg smape 1.61: \n",
            "Model Number: 108 of 155 with model ETS for Validation 3\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "108 - ETS with avg smape 0.94: \n",
            "Model Number: 109 of 155 with model MultivariateMotif for Validation 3\n",
            "109 - MultivariateMotif with avg smape 0.91: \n",
            "Model Number: 110 of 155 with model GLS for Validation 3\n",
            "110 - GLS with avg smape 0.87: \n",
            "Model Number: 111 of 155 with model ETS for Validation 3\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "111 - ETS with avg smape 2.04: \n",
            "Model Number: 112 of 155 with model SeasonalNaive for Validation 3\n",
            "112 - SeasonalNaive with avg smape 0.82: \n",
            "Model Number: 113 of 155 with model NVAR for Validation 3\n",
            "113 - NVAR with avg smape 2.54: \n",
            "Model Number: 114 of 155 with model GLS for Validation 3\n",
            "114 - GLS with avg smape 0.77: \n",
            "Model Number: 115 of 155 with model FBProphet for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "05:30:13 - cmdstanpy - INFO - Chain [1] start processing\n",
            "05:30:13 - cmdstanpy - INFO - Chain [1] done processing\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: divide by zero encountered in log\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: invalid value encountered in add\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
            "05:30:15 - cmdstanpy - INFO - Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "115 - FBProphet with avg smape 1.67: \n",
            "Model Number: 116 of 155 with model FBProphet for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:30:15 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "116 - FBProphet with avg smape 1.15: \n",
            "Model Number: 117 of 155 with model UnobservedComponents for Validation 3\n",
            "117 - UnobservedComponents with avg smape 0.69: \n",
            "Model Number: 118 of 155 with model SeasonalNaive for Validation 3\n",
            "118 - SeasonalNaive with avg smape 1.81: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 119 of 155 with model SeasonalNaive for Validation 3\n",
            "119 - SeasonalNaive with avg smape 0.73: \n",
            "Model Number: 120 of 155 with model UnobservedComponents for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:30:17 - cmdstanpy - INFO - Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "120 - UnobservedComponents with avg smape 0.89: \n",
            "Model Number: 121 of 155 with model FBProphet for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "05:30:17 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "121 - FBProphet with avg smape 1.1: \n",
            "Model Number: 122 of 155 with model UnobservedComponents for Validation 3\n",
            "122 - UnobservedComponents with avg smape 0.89: \n",
            "Model Number: 123 of 155 with model GLS for Validation 3\n",
            "123 - GLS with avg smape 0.74: \n",
            "Model Number: 124 of 155 with model UnobservedComponents for Validation 3\n",
            "124 - UnobservedComponents with avg smape 0.77: \n",
            "Model Number: 125 of 155 with model SeasonalNaive for Validation 3\n",
            "125 - SeasonalNaive with avg smape 1.47: \n",
            "Model Number: 126 of 155 with model MultivariateMotif for Validation 3\n",
            "126 - MultivariateMotif with avg smape 2.23: \n",
            "Model Number: 127 of 155 with model MultivariateMotif for Validation 3\n",
            "127 - MultivariateMotif with avg smape 0.75: \n",
            "Model Number: 128 of 155 with model GLS for Validation 3\n",
            "128 - GLS with avg smape 0.73: \n",
            "Model Number: 129 of 155 with model GLS for Validation 3\n",
            "129 - GLS with avg smape 0.76: \n",
            "Model Number: 130 of 155 with model UnobservedComponents for Validation 3\n",
            "130 - UnobservedComponents with avg smape 0.73: \n",
            "Model Number: 131 of 155 with model MultivariateMotif for Validation 3\n",
            "131 - MultivariateMotif with avg smape 0.89: \n",
            "Model Number: 132 of 155 with model MultivariateMotif for Validation 3\n",
            "132 - MultivariateMotif with avg smape 1.45: \n",
            "Model Number: 133 of 155 with model MultivariateMotif for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "133 - MultivariateMotif with avg smape 1.21: \n",
            "Model Number: 134 of 155 with model MultivariateRegression for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.3s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "134 - MultivariateRegression with avg smape 1.34: \n",
            "Model Number: 135 of 155 with model MultivariateRegression for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Done 300 out of 300 | elapsed:    0.4s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "135 - MultivariateRegression with avg smape 2.53: \n",
            "Model Number: 136 of 155 with model MultivariateRegression for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.3s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "136 - MultivariateRegression with avg smape 1.15: \n",
            "Model Number: 137 of 155 with model MultivariateMotif for Validation 3\n",
            "137 - MultivariateMotif with avg smape 2.23: \n",
            "Model Number: 138 of 155 with model MultivariateRegression for Validation 3\n",
            "138 - MultivariateRegression with avg smape 2.65: \n",
            "Model Number: 139 of 155 with model MultivariateRegression for Validation 3\n",
            "📈 139 - MultivariateRegression with avg smape 0.51: \n",
            "Model Number: 140 of 155 with model MultivariateRegression for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.3s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "140 - MultivariateRegression with avg smape 3.64: \n",
            "Model Number: 141 of 155 with model DatepartRegression for Validation 3\n",
            "141 - DatepartRegression with avg smape 2.04: \n",
            "Model Number: 142 of 155 with model DatepartRegression for Validation 3\n",
            "Epoch 1/200\n",
            "6/6 [==============================] - 6s 29ms/step - loss: 0.1649\n",
            "Epoch 2/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1654\n",
            "Epoch 3/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1632\n",
            "Epoch 4/200\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 0.1634\n",
            "Epoch 5/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1625\n",
            "Epoch 6/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1646\n",
            "Epoch 7/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1647\n",
            "Epoch 8/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1618\n",
            "Epoch 9/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1614\n",
            "Epoch 10/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1621\n",
            "Epoch 11/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1635\n",
            "Epoch 12/200\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 0.1612\n",
            "Epoch 13/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1613\n",
            "Epoch 14/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1622\n",
            "Epoch 15/200\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.1643\n",
            "Epoch 16/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1659\n",
            "Epoch 17/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1650\n",
            "Epoch 18/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1650\n",
            "Epoch 19/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1625\n",
            "Epoch 20/200\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.1622\n",
            "Epoch 21/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1642\n",
            "Epoch 22/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1615\n",
            "Epoch 23/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1644\n",
            "Epoch 24/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1654\n",
            "Epoch 25/200\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 0.1628\n",
            "Epoch 26/200\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.1639\n",
            "Epoch 27/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1615\n",
            "Epoch 28/200\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.1625\n",
            "Epoch 29/200\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 0.1624\n",
            "Epoch 30/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1632\n",
            "Epoch 31/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1636\n",
            "Epoch 32/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1646\n",
            "Epoch 33/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1616\n",
            "Epoch 34/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1622\n",
            "Epoch 35/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1633\n",
            "Epoch 36/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1633\n",
            "Epoch 37/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1622\n",
            "Epoch 38/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1631\n",
            "Epoch 39/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1634\n",
            "Epoch 40/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1621\n",
            "Epoch 41/200\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.1625\n",
            "Epoch 42/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1623\n",
            "Epoch 43/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1622\n",
            "Epoch 44/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1619\n",
            "Epoch 45/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1615\n",
            "Epoch 46/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1632\n",
            "Epoch 47/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1629\n",
            "Epoch 48/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1642\n",
            "Epoch 49/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1620\n",
            "Epoch 50/200\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.1638\n",
            "Epoch 51/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1642\n",
            "Epoch 52/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1617\n",
            "Epoch 53/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1618\n",
            "Epoch 54/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1622\n",
            "Epoch 55/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1630\n",
            "Epoch 56/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1627\n",
            "Epoch 57/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1627\n",
            "Epoch 58/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1611\n",
            "Epoch 59/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1624\n",
            "Epoch 60/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1628\n",
            "Epoch 61/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1626\n",
            "Epoch 62/200\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 0.1631\n",
            "Epoch 63/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1627\n",
            "Epoch 64/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1628\n",
            "Epoch 65/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1622\n",
            "Epoch 66/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1623\n",
            "Epoch 67/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1626\n",
            "Epoch 68/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1623\n",
            "Epoch 69/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1620\n",
            "Epoch 70/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1632\n",
            "Epoch 71/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1621\n",
            "Epoch 72/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1621\n",
            "Epoch 73/200\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.1620\n",
            "Epoch 74/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1620\n",
            "Epoch 75/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1624\n",
            "Epoch 76/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1628\n",
            "Epoch 77/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1623\n",
            "Epoch 78/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1626\n",
            "Epoch 79/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1627\n",
            "Epoch 80/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1654\n",
            "Epoch 81/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1636\n",
            "Epoch 82/200\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.1617\n",
            "Epoch 83/200\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.1621\n",
            "Epoch 84/200\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 0.1614\n",
            "Epoch 85/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1630\n",
            "Epoch 86/200\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.1629\n",
            "Epoch 87/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1629\n",
            "Epoch 88/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1643\n",
            "Epoch 89/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1629\n",
            "Epoch 90/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1633\n",
            "Epoch 91/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1615\n",
            "Epoch 92/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1625\n",
            "Epoch 93/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1625\n",
            "Epoch 94/200\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.1627\n",
            "Epoch 95/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1621\n",
            "Epoch 96/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1628\n",
            "Epoch 97/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1625\n",
            "Epoch 98/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1622\n",
            "Epoch 99/200\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 0.1622\n",
            "Epoch 100/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1623\n",
            "Epoch 101/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1614\n",
            "Epoch 102/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1619\n",
            "Epoch 103/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1620\n",
            "Epoch 104/200\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.1624\n",
            "Epoch 105/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1625\n",
            "Epoch 106/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1631\n",
            "Epoch 107/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1625\n",
            "Epoch 108/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1624\n",
            "Epoch 109/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1626\n",
            "Epoch 110/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1623\n",
            "Epoch 111/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1620\n",
            "Epoch 112/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1622\n",
            "Epoch 113/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1616\n",
            "Epoch 114/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1620\n",
            "Epoch 115/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1621\n",
            "Epoch 116/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1627\n",
            "Epoch 117/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1628\n",
            "Epoch 118/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1613\n",
            "Epoch 119/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1615\n",
            "Epoch 120/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1626\n",
            "Epoch 121/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1628\n",
            "Epoch 122/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1621\n",
            "Epoch 123/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1626\n",
            "Epoch 124/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1621\n",
            "Epoch 125/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1629\n",
            "Epoch 126/200\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 0.1625\n",
            "Epoch 127/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1622\n",
            "Epoch 128/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1623\n",
            "Epoch 129/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1627\n",
            "Epoch 130/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1617\n",
            "Epoch 131/200\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.1615\n",
            "Epoch 132/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1625\n",
            "Epoch 133/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1624\n",
            "Epoch 134/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1617\n",
            "Epoch 135/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1622\n",
            "Epoch 136/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1615\n",
            "Epoch 137/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1623\n",
            "Epoch 138/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1615\n",
            "Epoch 139/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1620\n",
            "Epoch 140/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1622\n",
            "Epoch 141/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1620\n",
            "Epoch 142/200\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 0.1628\n",
            "Epoch 143/200\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.1622\n",
            "Epoch 144/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1618\n",
            "Epoch 145/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1622\n",
            "Epoch 146/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1623\n",
            "Epoch 147/200\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 0.1624\n",
            "Epoch 148/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1616\n",
            "Epoch 149/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1625\n",
            "Epoch 150/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1624\n",
            "Epoch 151/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1626\n",
            "Epoch 152/200\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.1616\n",
            "Epoch 153/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1621\n",
            "Epoch 154/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1620\n",
            "Epoch 155/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1625\n",
            "Epoch 156/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1620\n",
            "Epoch 157/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1624\n",
            "Epoch 158/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1625\n",
            "Epoch 159/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1625\n",
            "Epoch 160/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1615\n",
            "Epoch 161/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1621\n",
            "Epoch 162/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1628\n",
            "Epoch 163/200\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 0.1626\n",
            "Epoch 164/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1616\n",
            "Epoch 165/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1622\n",
            "Epoch 166/200\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 0.1629\n",
            "Epoch 167/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1633\n",
            "Epoch 168/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1618\n",
            "Epoch 169/200\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.1620\n",
            "Epoch 170/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1622\n",
            "Epoch 171/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1621\n",
            "Epoch 172/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1626\n",
            "Epoch 173/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1613\n",
            "Epoch 174/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1617\n",
            "Epoch 175/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1613\n",
            "Epoch 176/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1620\n",
            "Epoch 177/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1621\n",
            "Epoch 178/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1618\n",
            "Epoch 179/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1621\n",
            "Epoch 180/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1623\n",
            "Epoch 181/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1613\n",
            "Epoch 182/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1615\n",
            "Epoch 183/200\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.1627\n",
            "Epoch 184/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1620\n",
            "Epoch 185/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1616\n",
            "Epoch 186/200\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1629\n",
            "Epoch 187/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1631\n",
            "Epoch 188/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1623\n",
            "Epoch 189/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1629\n",
            "Epoch 190/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1614\n",
            "Epoch 191/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1618\n",
            "Epoch 192/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1620\n",
            "Epoch 193/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1621\n",
            "Epoch 194/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1629\n",
            "Epoch 195/200\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.1616\n",
            "Epoch 196/200\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1626\n",
            "Epoch 197/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1622\n",
            "Epoch 198/200\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1622\n",
            "Epoch 199/200\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1613\n",
            "Epoch 200/200\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.1617\n",
            "142 - DatepartRegression with avg smape 5.57: \n",
            "Model Number: 143 of 155 with model MultivariateRegression for Validation 3\n",
            "143 - MultivariateRegression with avg smape 1.43: \n",
            "Model Number: 144 of 155 with model DatepartRegression for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "144 - DatepartRegression with avg smape 5.07: \n",
            "Model Number: 145 of 155 with model DatepartRegression for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "145 - DatepartRegression with avg smape 2.15: \n",
            "Model Number: 146 of 155 with model MultivariateRegression for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.3s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "146 - MultivariateRegression with avg smape 1.7: \n",
            "Model Number: 147 of 155 with model DatepartRegression for Validation 3\n",
            "Epoch 1/100\n",
            "6/6 [==============================] - 6s 8ms/step - loss: 0.1164\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0924\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0676\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0408\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0174\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0077\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0139\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0096\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0081\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0076\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0084\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0087\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0082\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0079\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0082\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0083\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0071\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0081\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0072\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0081\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0086\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0077\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0070\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0076\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0076\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0068\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0068\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0076\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0074\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0078\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0066\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0064\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0077\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0071\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0068\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0067\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0068\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0071\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0068\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0071\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0066\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0067\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0068\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0067\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0064\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0070\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0066\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0070\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0069\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0064\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0069\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0065\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0066\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0070\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0059\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0065\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0063\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0063\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0058\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0060\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0058\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0063\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0056\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0059\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0060\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0058\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0063\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0061\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0061\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0062\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0063\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0062\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0058\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0060\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0061\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0060\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0060\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0063\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0063\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0058\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0060\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0060\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0061\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0058\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0058\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0058\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0056\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0060\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0064\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0058\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0059\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0059\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0057\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0057\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0058\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0061\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0062\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0059\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0058\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0059\n",
            "147 - DatepartRegression with avg smape 4.21: \n",
            "Model Number: 148 of 155 with model DatepartRegression for Validation 3\n",
            "Epoch 1/50\n",
            "3/3 [==============================] - 7s 18ms/step - loss: 125.3537\n",
            "Epoch 2/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 106.9353\n",
            "Epoch 3/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 107.2947\n",
            "Epoch 4/50\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 105.3984\n",
            "Epoch 5/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 103.3312\n",
            "Epoch 6/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 124.7973\n",
            "Epoch 7/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 108.9083\n",
            "Epoch 8/50\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 102.8704\n",
            "Epoch 9/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 107.6924\n",
            "Epoch 10/50\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 102.6551\n",
            "Epoch 11/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 107.5556\n",
            "Epoch 12/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 102.8691\n",
            "Epoch 13/50\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 103.9360\n",
            "Epoch 14/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 101.1239\n",
            "Epoch 15/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 110.8121\n",
            "Epoch 16/50\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 104.7832\n",
            "Epoch 17/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 115.5817\n",
            "Epoch 18/50\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 105.4654\n",
            "Epoch 19/50\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 104.0157\n",
            "Epoch 20/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 102.4044\n",
            "Epoch 21/50\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 103.0989\n",
            "Epoch 22/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 102.1145\n",
            "Epoch 23/50\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 108.2314\n",
            "Epoch 24/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 100.4132\n",
            "Epoch 25/50\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 101.0101\n",
            "Epoch 26/50\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 106.2764\n",
            "Epoch 27/50\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 99.7615\n",
            "Epoch 28/50\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 102.9066\n",
            "Epoch 29/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 110.6483\n",
            "Epoch 30/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 101.0573\n",
            "Epoch 31/50\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 102.0211\n",
            "Epoch 32/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 103.2400\n",
            "Epoch 33/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 102.2482\n",
            "Epoch 34/50\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 106.2031\n",
            "Epoch 35/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 100.4702\n",
            "Epoch 36/50\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 103.0652\n",
            "Epoch 37/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 104.3360\n",
            "Epoch 38/50\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 101.8730\n",
            "Epoch 39/50\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 102.1612\n",
            "Epoch 40/50\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 102.4012\n",
            "Epoch 41/50\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 105.4737\n",
            "Epoch 42/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 100.9500\n",
            "Epoch 43/50\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 103.6004\n",
            "Epoch 44/50\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 102.0426\n",
            "Epoch 45/50\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 99.1673\n",
            "Epoch 46/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 100.4352\n",
            "Epoch 47/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 103.6317\n",
            "Epoch 48/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 102.6428\n",
            "Epoch 49/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 101.3846\n",
            "Epoch 50/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 101.0560\n",
            "148 - DatepartRegression with avg smape 3.64: \n",
            "Model Number: 149 of 155 with model DatepartRegression for Validation 3\n",
            "149 - DatepartRegression with avg smape 3.66: \n",
            "Model Number: 150 of 155 with model GLM for Validation 3\n",
            "150 - GLM with avg smape 3.46: \n",
            "Model Number: 151 of 155 with model DatepartRegression for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "151 - DatepartRegression with avg smape 2.62: \n",
            "Model Number: 152 of 155 with model DatepartRegression for Validation 3\n",
            "152 - DatepartRegression with avg smape 1.85: \n",
            "Model Number: 153 of 155 with model MultivariateRegression for Validation 3\n",
            "153 - MultivariateRegression with avg smape 2.38: \n",
            "Model Number: 154 of 155 with model GLM for Validation 3\n",
            "154 - GLM with avg smape 0.98: \n",
            "Model Number: 155 of 155 with model GLM for Validation 3\n",
            "155 - GLM with avg smape 37.08: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/genmod/families/family.py:1440: RuntimeWarning: invalid value encountered in log\n",
            "  endog * np.log(endog / mu) + (mu - endog))\n"
          ]
        }
      ],
      "source": [
        "mod = model.fit(df, date_col = 'Date', value_col = 'Close', id_col = None)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c7bde3b",
      "metadata": {
        "id": "9c7bde3b"
      },
      "source": [
        "## Best Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "7b0b3852",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b0b3852",
        "outputId": "5a18ac3f-63b8-40a8-81b8-7e281dc291b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initiated AutoTS object with best model: \n",
            "FBProphet\n",
            "{'fillna': 'ffill_mean_biased', 'transformations': {'0': 'Detrend', '1': 'QuantileTransformer'}, 'transformation_params': {'0': {'model': 'Gamma', 'phi': 1, 'window': None}, '1': {'output_distribution': 'normal', 'n_quantiles': 65}}}\n",
            "{'holiday': False, 'regression_type': None, 'growth': 'linear', 'n_changepoints': 25, 'changepoint_prior_scale': 10, 'seasonality_mode': 'multiplicative', 'changepoint_range': 0.9, 'seasonality_prior_scale': 0.01, 'holidays_prior_scale': 10.0}\n",
            "SMAPE: 1.0525175940408553, 1.451761948728635, 0.7124887500951615, 1.1503007093010602\n",
            "MAE: 396.9036340216888, 534.5602698341215, 256.615021010091, 402.78227994970075\n",
            "SPL: 0.6989475879169356, 0.7472624589287438, 0.7611906715422957, 0.7243374354774694\n"
          ]
        }
      ],
      "source": [
        "print(mod)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccf1793b",
      "metadata": {
        "id": "ccf1793b"
      },
      "source": [
        "## Prediction and Forecasting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "544df789",
      "metadata": {
        "id": "544df789",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e07e0c0-7aff-4bc8-ec15-3f3700736999"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: divide by zero encountered in log\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: invalid value encountered in add\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
            "05:36:01 - cmdstanpy - INFO - Chain [1] start processing\n",
            "05:36:01 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        }
      ],
      "source": [
        "pred = model.predict()\n",
        "forecast = pred.forecast\n",
        "model_results = model.results()\n",
        "validation = model.results('validation')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7710b60",
      "metadata": {
        "id": "d7710b60"
      },
      "source": [
        "Let’s print the forecast of the dataset for the future stock price. Also, we will see the validation of the model results. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "e4cc48a0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4cc48a0",
        "outputId": "8d8bb18e-fa1f-47fb-e212-da7369f056d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   Close\n",
            "2022-08-08  38023.484437\n",
            "2022-08-09  38055.657137\n",
            "2022-08-10  38200.650321\n",
            "2022-08-11  38351.652381\n",
            "2022-08-12  38426.708992\n"
          ]
        }
      ],
      "source": [
        "# Forecast\n",
        "print(forecast)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "037d8398",
      "metadata": {
        "id": "037d8398"
      },
      "outputs": [],
      "source": [
        "fcast = forecast.astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "5ea81c89",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ea81c89",
        "outputId": "a0928f0a-0473-4566-8b22-6da3c4d44248"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^NSEBANK\n",
            "            Close\n",
            "2022-08-08  38023\n",
            "2022-08-09  38055\n",
            "2022-08-10  38200\n",
            "2022-08-11  38351\n",
            "2022-08-12  38426\n"
          ]
        }
      ],
      "source": [
        "print(ticker)\n",
        "print(fcast)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86e25040",
      "metadata": {
        "id": "86e25040"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "newdf = pd.DataFrame(fcast)\n",
        "newdf['ticker'] = ticker\n",
        "newdf['timestamp'] = datetime.now()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76d9e9ff",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "76d9e9ff",
        "outputId": "c694e30e-2ec5-4b20-cdc4-a3f3ad2263ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Close      ticker                  timestamp\n",
              "2022-06-06    863  IPCALAB.NS 2022-06-04 09:23:46.563474\n",
              "2022-06-07    849  IPCALAB.NS 2022-06-04 09:23:46.563474\n",
              "2022-06-08    843  IPCALAB.NS 2022-06-04 09:23:46.563474"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b15aa33b-62b8-4284-9b18-3d2ccb163f06\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Close</th>\n",
              "      <th>ticker</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2022-06-06</th>\n",
              "      <td>863</td>\n",
              "      <td>IPCALAB.NS</td>\n",
              "      <td>2022-06-04 09:23:46.563474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-06-07</th>\n",
              "      <td>849</td>\n",
              "      <td>IPCALAB.NS</td>\n",
              "      <td>2022-06-04 09:23:46.563474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-06-08</th>\n",
              "      <td>843</td>\n",
              "      <td>IPCALAB.NS</td>\n",
              "      <td>2022-06-04 09:23:46.563474</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b15aa33b-62b8-4284-9b18-3d2ccb163f06')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b15aa33b-62b8-4284-9b18-3d2ccb163f06 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b15aa33b-62b8-4284-9b18-3d2ccb163f06');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "newdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd7f8d0f",
      "metadata": {
        "id": "fd7f8d0f"
      },
      "outputs": [],
      "source": [
        "newdf.reset_index(inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b6fac87",
      "metadata": {
        "id": "8b6fac87"
      },
      "outputs": [],
      "source": [
        "newdf.rename(columns = {'index':'Date'}, inplace = True)\n",
        "# newdf['Date'] = pd.to_datetime(newdf['Date'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77322c9f",
      "metadata": {
        "id": "77322c9f",
        "outputId": "191a40bf-9e1e-4c38-885e-08c9b951c53e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Close</th>\n",
              "      <th>ticker</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2022-05-31</td>\n",
              "      <td>35441</td>\n",
              "      <td>^NSEBANK</td>\n",
              "      <td>2022-05-30 20:17:03.368617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022-06-01</td>\n",
              "      <td>35744</td>\n",
              "      <td>^NSEBANK</td>\n",
              "      <td>2022-05-30 20:17:03.368617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022-06-02</td>\n",
              "      <td>35735</td>\n",
              "      <td>^NSEBANK</td>\n",
              "      <td>2022-05-30 20:17:03.368617</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Date  Close    ticker                  timestamp\n",
              "0 2022-05-31  35441  ^NSEBANK 2022-05-30 20:17:03.368617\n",
              "1 2022-06-01  35744  ^NSEBANK 2022-05-30 20:17:03.368617\n",
              "2 2022-06-02  35735  ^NSEBANK 2022-05-30 20:17:03.368617"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "newdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc6de0bb",
      "metadata": {
        "id": "cc6de0bb"
      },
      "outputs": [],
      "source": [
        "# finaldf = pd.DataFrame()\n",
        "# finaldf = pd.read_csv('predictions.csv')\n",
        "finaldf = finaldf.append(newdf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa42ce89",
      "metadata": {
        "id": "aa42ce89",
        "outputId": "b2a5a0ac-914e-4ed5-fa40-0462f50dd40d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Close</th>\n",
              "      <th>ticker</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2022-05-30</td>\n",
              "      <td>16090</td>\n",
              "      <td>^NSEI</td>\n",
              "      <td>2022-05-28 11:17:41.393578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022-05-30</td>\n",
              "      <td>34838</td>\n",
              "      <td>^NSEBANK</td>\n",
              "      <td>2022-05-28 21:54:40.944595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022-05-30</td>\n",
              "      <td>54334</td>\n",
              "      <td>^BSESN</td>\n",
              "      <td>2022-05-28 21:58:47.604539</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2022-05-31</td>\n",
              "      <td>16103</td>\n",
              "      <td>^NSEI</td>\n",
              "      <td>2022-05-28 11:17:41.393578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2022-05-31</td>\n",
              "      <td>35056</td>\n",
              "      <td>^NSEBANK</td>\n",
              "      <td>2022-05-28 21:54:40.944595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2022-05-31</td>\n",
              "      <td>54221</td>\n",
              "      <td>^BSESN</td>\n",
              "      <td>2022-05-28 21:58:47.604539</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2022-05-31</td>\n",
              "      <td>16586</td>\n",
              "      <td>^NSEI</td>\n",
              "      <td>2022-05-30 19:27:57.532132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2022-06-01</td>\n",
              "      <td>16105</td>\n",
              "      <td>^NSEI</td>\n",
              "      <td>2022-05-28 11:17:41.393578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2022-06-01</td>\n",
              "      <td>35216</td>\n",
              "      <td>^NSEBANK</td>\n",
              "      <td>2022-05-28 21:54:40.944595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2022-06-01</td>\n",
              "      <td>54123</td>\n",
              "      <td>^BSESN</td>\n",
              "      <td>2022-05-28 21:58:47.604539</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022-06-01</td>\n",
              "      <td>16585</td>\n",
              "      <td>^NSEI</td>\n",
              "      <td>2022-05-30 19:27:57.532132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022-06-02</td>\n",
              "      <td>16577</td>\n",
              "      <td>^NSEI</td>\n",
              "      <td>2022-05-30 19:27:57.532132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2022-05-31</td>\n",
              "      <td>35441</td>\n",
              "      <td>^NSEBANK</td>\n",
              "      <td>2022-05-30 20:17:03.368617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022-06-01</td>\n",
              "      <td>35744</td>\n",
              "      <td>^NSEBANK</td>\n",
              "      <td>2022-05-30 20:17:03.368617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022-06-02</td>\n",
              "      <td>35735</td>\n",
              "      <td>^NSEBANK</td>\n",
              "      <td>2022-05-30 20:17:03.368617</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Date  Close    ticker                   timestamp\n",
              "0 2022-05-30  16090     ^NSEI  2022-05-28 11:17:41.393578\n",
              "1 2022-05-30  34838  ^NSEBANK  2022-05-28 21:54:40.944595\n",
              "2 2022-05-30  54334    ^BSESN  2022-05-28 21:58:47.604539\n",
              "3 2022-05-31  16103     ^NSEI  2022-05-28 11:17:41.393578\n",
              "4 2022-05-31  35056  ^NSEBANK  2022-05-28 21:54:40.944595\n",
              "5 2022-05-31  54221    ^BSESN  2022-05-28 21:58:47.604539\n",
              "0 2022-05-31  16586     ^NSEI  2022-05-30 19:27:57.532132\n",
              "6 2022-06-01  16105     ^NSEI  2022-05-28 11:17:41.393578\n",
              "7 2022-06-01  35216  ^NSEBANK  2022-05-28 21:54:40.944595\n",
              "8 2022-06-01  54123    ^BSESN  2022-05-28 21:58:47.604539\n",
              "1 2022-06-01  16585     ^NSEI  2022-05-30 19:27:57.532132\n",
              "2 2022-06-02  16577     ^NSEI  2022-05-30 19:27:57.532132\n",
              "0 2022-05-31  35441  ^NSEBANK  2022-05-30 20:17:03.368617\n",
              "1 2022-06-01  35744  ^NSEBANK  2022-05-30 20:17:03.368617\n",
              "2 2022-06-02  35735  ^NSEBANK  2022-05-30 20:17:03.368617"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "finaldf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "887913aa",
      "metadata": {
        "id": "887913aa"
      },
      "outputs": [],
      "source": [
        "finaldf['Date'] = pd.to_datetime(finaldf['Date'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4faf9920",
      "metadata": {
        "id": "4faf9920"
      },
      "outputs": [],
      "source": [
        "finaldf.sort_values('Date', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "263126d5",
      "metadata": {
        "id": "263126d5",
        "outputId": "9c046f63-a1df-48be-b88f-1b3dc3eab43e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Close</th>\n",
              "      <th>ticker</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2022-05-30</td>\n",
              "      <td>16090</td>\n",
              "      <td>^NSEI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022-05-30</td>\n",
              "      <td>34838</td>\n",
              "      <td>^NSEBANK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022-05-30</td>\n",
              "      <td>54334</td>\n",
              "      <td>^BSESN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2022-05-31</td>\n",
              "      <td>16103</td>\n",
              "      <td>^NSEI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2022-05-31</td>\n",
              "      <td>35056</td>\n",
              "      <td>^NSEBANK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2022-05-31</td>\n",
              "      <td>54221</td>\n",
              "      <td>^BSESN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2022-05-31</td>\n",
              "      <td>16586</td>\n",
              "      <td>^NSEI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2022-05-31</td>\n",
              "      <td>35441</td>\n",
              "      <td>^NSEBANK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2022-06-01</td>\n",
              "      <td>16105</td>\n",
              "      <td>^NSEI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2022-06-01</td>\n",
              "      <td>35216</td>\n",
              "      <td>^NSEBANK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2022-06-01</td>\n",
              "      <td>54123</td>\n",
              "      <td>^BSESN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022-06-01</td>\n",
              "      <td>16585</td>\n",
              "      <td>^NSEI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022-06-01</td>\n",
              "      <td>35744</td>\n",
              "      <td>^NSEBANK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022-06-02</td>\n",
              "      <td>16577</td>\n",
              "      <td>^NSEI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022-06-02</td>\n",
              "      <td>35735</td>\n",
              "      <td>^NSEBANK</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Date  Close    ticker\n",
              "0 2022-05-30  16090     ^NSEI\n",
              "1 2022-05-30  34838  ^NSEBANK\n",
              "2 2022-05-30  54334    ^BSESN\n",
              "3 2022-05-31  16103     ^NSEI\n",
              "4 2022-05-31  35056  ^NSEBANK\n",
              "5 2022-05-31  54221    ^BSESN\n",
              "0 2022-05-31  16586     ^NSEI\n",
              "0 2022-05-31  35441  ^NSEBANK\n",
              "6 2022-06-01  16105     ^NSEI\n",
              "7 2022-06-01  35216  ^NSEBANK\n",
              "8 2022-06-01  54123    ^BSESN\n",
              "1 2022-06-01  16585     ^NSEI\n",
              "1 2022-06-01  35744  ^NSEBANK\n",
              "2 2022-06-02  16577     ^NSEI\n",
              "2 2022-06-02  35735  ^NSEBANK"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# finaldf['Close'] = (round(finaldf['Close'],0)).astype(int)\n",
        "finaldf[['Date','Close','ticker']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a028dad0",
      "metadata": {
        "id": "a028dad0"
      },
      "outputs": [],
      "source": [
        "finaldf['timestamp'] = pd.to_datetime(finaldf['timestamp'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "792fec87",
      "metadata": {
        "scrolled": true,
        "id": "792fec87",
        "outputId": "84ba2097-2185-4e19-89e5-888f687bcf4e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Close</th>\n",
              "      <th>ticker</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2022-05-31</td>\n",
              "      <td>16586</td>\n",
              "      <td>^NSEI</td>\n",
              "      <td>2022-05-30 19:27:57.532132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022-06-01</td>\n",
              "      <td>16585</td>\n",
              "      <td>^NSEI</td>\n",
              "      <td>2022-05-30 19:27:57.532132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022-06-02</td>\n",
              "      <td>16577</td>\n",
              "      <td>^NSEI</td>\n",
              "      <td>2022-05-30 19:27:57.532132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2022-05-30</td>\n",
              "      <td>16090</td>\n",
              "      <td>^NSEI</td>\n",
              "      <td>2022-05-28 11:17:41.393578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2022-05-31</td>\n",
              "      <td>16103</td>\n",
              "      <td>^NSEI</td>\n",
              "      <td>2022-05-28 11:17:41.393578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2022-06-01</td>\n",
              "      <td>16105</td>\n",
              "      <td>^NSEI</td>\n",
              "      <td>2022-05-28 11:17:41.393578</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Date  Close ticker                  timestamp\n",
              "0 2022-05-31  16586  ^NSEI 2022-05-30 19:27:57.532132\n",
              "1 2022-06-01  16585  ^NSEI 2022-05-30 19:27:57.532132\n",
              "2 2022-06-02  16577  ^NSEI 2022-05-30 19:27:57.532132\n",
              "0 2022-05-30  16090  ^NSEI 2022-05-28 11:17:41.393578\n",
              "3 2022-05-31  16103  ^NSEI 2022-05-28 11:17:41.393578\n",
              "6 2022-06-01  16105  ^NSEI 2022-05-28 11:17:41.393578"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "finaldf[finaldf['ticker']=='^NSEI'].sort_values('timestamp', ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ea905fb",
      "metadata": {
        "id": "0ea905fb"
      },
      "outputs": [],
      "source": [
        "finaldf.to_csv('predictions.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b48a3ff4",
      "metadata": {
        "id": "b48a3ff4"
      },
      "outputs": [],
      "source": [
        "#Validation Results\n",
        "# print(validation)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "AutoTS_Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}